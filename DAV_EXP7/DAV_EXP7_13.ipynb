{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnDH86w84cosK6LCGMGe7M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manasdeshpande/DAV_Lab/blob/main/DAV_EXP7/DAV_EXP7_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manas Deshpande\n",
        "\n",
        "D11AD-13"
      ],
      "metadata": {
        "id": "c3fP2cv6U2HW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment - 7: Perform the steps involved in Text Analytics in Python & R\n",
        "\n",
        "## Lab Outcomes (LO):\n",
        "* Design Text Analytics Application on a given data set. (LO4)\n",
        "\n",
        "## Task to be performed :\n",
        "1. Explore Top-5 Text Analytics Libraries in Python (w.r.t Features & Applications)\n",
        "2. Explore Top-5 Text Analytics Libraries in R (w.r.t Features & Applications)\n",
        "3. Perform the following experiments using Python & R\n",
        "- Tokenization (Sentence & Word)\n",
        "- Frequency Distribution\n",
        "- Remove stopwords & punctuations\n",
        "- Lexicon Normalization (Stemming, Lemmatization)\n",
        "- Part of Speech tagging\n",
        "- Named Entity Recognization\n",
        "- Scrape data from a website\n",
        "4. Prepare a document with the Aim, Tasks performed, Program, Output, and Conclusion.\n",
        "\n",
        "## Tools & Libraries to be explored\n",
        "* Python Libraries: nltk, scattertext, SpaCy, TextBlob, sklearn, pandas, numpy\n",
        "\n",
        "* R Libraries: shiny, tm, quanteda"
      ],
      "metadata": {
        "id": "3j-bWR2oUxyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize, FreqDist, pos_tag, ne_chunk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP2AC65dZ7wU",
        "outputId": "27068e69-93a8-47d1-f56f-f7ab1c569691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize, FreqDist, pos_tag, ne_chunk\n",
        "def tokenize_sentences(text):\n",
        "    return sent_tokenize(text)\n",
        "sample_text = \"\"\"Data analysis is the process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making.[1] Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, and is used in different business, science, and social science domains.[2] In today's business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively.[3]\n",
        "\n",
        "Data mining is a particular data analysis technique that focuses on statistical modeling and knowledge discovery for predictive rather than purely descriptive purposes, while business intelligence covers data analysis that relies heavily on aggregation, focusing mainly on business information.[4] In statistical applications, data analysis can be divided into descriptive statistics, exploratory data analysis (EDA), and confirmatory data analysis (CDA).[5] EDA focuses on discovering new features in the data while CDA focuses on confirming or falsifying existing hypotheses.[6][7] Predictive analytics focuses on the application of statistical models for predictive forecasting or classification, while text analytics applies statistical, linguistic, and structural techniques to extract and classify information from textual sources, a species of unstructured data. All of the above are varieties of data analysis.[8]\n",
        "\n",
        "Data integration is a precursor to data analysis, and data analysis is closely linked to data visualization and data dissemination.The process of data analysis\n",
        "\n",
        "Data science process flowchart from Doing Data Science, by Schutt & O'Neil (2013)\n",
        "Analysis refers to dividing a whole into its separate components for individual examination.[10] Data analysis is a process for obtaining raw data, and subsequently converting it into information useful for decision-making by users.[1] Data is collected and analyzed to answer questions, test hypotheses, or disprove theories.[11]\n",
        "\n",
        "Statistician John Tukey, defined data analysis in 1961, as:\n",
        "\n",
        "\"Procedures for analyzing data, techniques for interpreting the results of such procedures, ways of planning the gathering of data to make its analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data.\"[12]\n",
        "\n",
        "There are several phases that can be distinguished, described below. The phases are iterative, in that feedback from later phases may result in additional work in earlier phases.[13] The CRISP framework, used in data mining, has similar steps.\n",
        "\n",
        "Data requirements\n",
        "The data is necessary as inputs to the analysis, which is specified based upon the requirements of those directing the analytics (or customers, who will use the finished product of the analysis).[14][15] The general type of entity upon which the data will be collected is referred to as an experimental unit (e.g., a person or population of people). Specific variables regarding a population (e.g., age and income) may be specified and obtained. Data may be numerical or categorical (i.e., a text label for numbers).[13]\n",
        "\n",
        "Data collection\n",
        "Data is collected from a variety of sources.[16][17] A list of data sources are available for study & research. The requirements may be communicated by analysts to custodians of the data; such as, Information Technology personnel within an organization.[18] Data collection or data gathering is the process of gathering and measuring information on targeted variables in an established system, which then enables one to answer relevant questions and evaluate outcomes. The data may also be collected from sensors in the environment, including traffic cameras, satellites, recording devices, etc. It may also be obtained through interviews, downloads from online sources, or reading documentation.[13]\n",
        "\n",
        "Data processing\n",
        "\n",
        "The phases of the intelligence cycle used to convert raw information into actionable intelligence or knowledge are conceptually similar to the phases in data analysis.\n",
        "Data, when initially obtained, must be processed or organized for analysis.[19][20] For instance, these may involve placing data into rows and columns in a table format (known as structured data) for further analysis, often through the use of spreadsheet or statistical software.[13]\n",
        "\n",
        "Data cleaning\n",
        "Main article: Data cleansing\n",
        "Once processed and organized, the data may be incomplete, contain duplicates, or contain errors.[21][22] The need for data cleaning will arise from problems in the way that the datum are entered and stored.[21] Data cleaning is the process of preventing and correcting these errors. Common tasks include record matching, identifying inaccuracy of data, overall quality of existing data, deduplication, and column segmentation.[23] Such data problems can also be identified through a variety of analytical techniques. For example; with financial information, the totals for particular variables may be compared against separately published numbers that are believed to be reliable.[24][25] Unusual amounts, above or below predetermined thresholds, may also be reviewed. There are several types of data cleaning, that are dependent upon the type of data in the set; this could be phone numbers, email addresses, employers, or other values.[26][27] Quantitative data methods for outlier detection, can be used to get rid of data that appears to have a higher likelihood of being input incorrectly.[28] Textual data spell checkers can be used to lessen the amount of mistyped words. However, it is harder to tell if the words themselves are correct.[29]\n",
        "\n",
        "Exploratory data analysis\n",
        "Once the datasets are cleaned, they can then be analyzed. Analysts may apply a variety of techniques, referred to as exploratory data analysis, to begin understanding the messages contained within the obtained data.[30] The process of data exploration may result in additional data cleaning or additional requests for data; thus, the initialization of the iterative phases mentioned in the lead paragraph of this section.[31] Descriptive statistics, such as, the average or median, can be generated to aid in understanding the data.[32][33] Data visualization is also a technique used, in which the analyst is able to examine the data in a graphical format in order to obtain additional insights, regarding the messages within the data.[13]\n",
        "\n",
        "Modeling and algorithms\n",
        "Mathematical formulas or models (also known as algorithms), may be applied to the data in order to identify relationships among the variables; for example, using correlation or causation.[34][35] In general terms, models may be developed to evaluate a specific variable based on other variable(s) contained within the dataset, with some residual error depending on the implemented model's accuracy (e.g., Data = Model + Error).[36][11]\n",
        "\n",
        "Inferential statistics includes utilizing techniques that measure the relationships between particular variables.[37] For example, regression analysis may be used to model whether a change in advertising (independent variable X), provides an explanation for the variation in sales (dependent variable Y).[38] In mathematical terms, Y (sales) is a function of X (advertising).[39] It may be described as (Y = aX + b + error), where the model is designed such that (a) and (b) minimize the error when the model predicts Y for a given range of values of X.[40] Analysts may also attempt to build models that are descriptive of the data, in an aim to simplify analysis and communicate results.[11]\n",
        "\n",
        "Data product\n",
        "A data product is a computer application that takes data inputs and generates outputs, feeding them back into the environment.[41] It may be based on a model or algorithm. For instance, an application that analyzes data about customer purchase history, and uses the results to recommend other purchases the customer might enjoy.[42][13]\n",
        "\n",
        "Communication\n",
        "\n",
        "Data visualization is used to help understand the results after data is analyzed.[43]\n",
        "Main article: Data and information visualization\n",
        "Once data is analyzed, it may be reported in many formats to the users of the analysis to support their requirements.[44] The users may have feedback, which results in additional analysis. As such, much of the analytical cycle is iterative.[13]\n",
        "\n",
        "When determining how to communicate the results, the analyst may consider implementing a variety of data visualization techniques to help communicate the message more clearly and efficiently to the audience.[45] Data visualization uses information displays (graphics such as, tables and charts) to help communicate key messages contained in the data.[46] Tables are a valuable tool by enabling the ability of a user to query and focus on specific numbers; while charts (e.g., bar charts or line charts), may help explain the quantitative messages contained in the data.[47]\n",
        "\n",
        "Quantitative messages\n",
        "Main article: Data and information visualization\n",
        "\n",
        "A time series illustrated with a line chart demonstrating trends in U.S. federal spending and revenue over time.\n",
        "\n",
        "A scatterplot illustrating the correlation between two variables (inflation and unemployment) measured at points in time.\n",
        "Stephen Few described eight types of quantitative messages that users may attempt to understand or communicate from a set of data and the associated graphs used to help communicate the message.[48] Customers specifying requirements and analysts performing the data analysis may consider these messages during the course of the process.[49]\n",
        "\n",
        "Time-series: A single variable is captured over a period of time, such as the unemployment rate over a 10-year period. A line chart may be used to demonstrate the trend.[50]\n",
        "Ranking: Categorical subdivisions are ranked in ascending or descending order, such as a ranking of sales performance (the measure) by salespersons (the category, with each salesperson a categorical subdivision) during a single period.[51] A bar chart may be used to show the comparison across the salespersons.[52]\n",
        "Part-to-whole: Categorical subdivisions are measured as a ratio to the whole (i.e., a percentage out of 100%). A pie chart or bar chart can show the comparison of ratios, such as the market share represented by competitors in a market.[53]\n",
        "Deviation: Categorical subdivisions are compared against a reference, such as a comparison of actual vs. budget expenses for several departments of a business for a given time period. A bar chart can show the comparison of the actual versus the reference amount.[54]\n",
        "Frequency distribution: Shows the number of observations of a particular variable for a given interval, such as the number of years in which the stock market return is between intervals such as 0–10%, 11–20%, etc. A histogram, a type of bar chart, may be used for this analysis.[55]\n",
        "Correlation: Comparison between observations represented by two variables (X,Y) to determine if they tend to move in the same or opposite directions. For example, plotting unemployment (X) and inflation (Y) for a sample of months. A scatter plot is typically used for this message.[56]\n",
        "Nominal comparison: Comparing categorical subdivisions in no particular order, such as the sales volume by product code. A bar chart may be used for this comparison.[57]\n",
        "Geographic or geospatial: Comparison of a variable across a map or layout, such as the unemployment rate by state or the number of persons on the various floors of a building. A cartogram is a typical graphic used.[58][59]\n",
        "Techniques for analyzing quantitative data\n",
        "See also: Problem solving\n",
        "Author Jonathan Koomey has recommended a series of best practices for understanding quantitative data.[60] These include:\n",
        "\n",
        "Check raw data for anomalies prior to performing an analysis;\n",
        "Re-perform important calculations, such as verifying columns of data that are formula driven;\n",
        "Confirm main totals are the sum of subtotals;\n",
        "Check relationships between numbers that should be related in a predictable way, such as ratios over time;\n",
        "Normalize numbers to make comparisons easier, such as analyzing amounts per person or relative to GDP or as an index value relative to a base year;\n",
        "Break problems into component parts by analyzing factors that led to the results, such as DuPont analysis of return on equity.[25]\n",
        "For the variables under examination, analysts typically obtain descriptive statistics for them, such as the mean (average), median, and standard deviation.[61] They may also analyze the distribution of the key variables to see how the individual values cluster around the mean.[62]\n",
        "\n",
        "\n",
        "An illustration of the MECE principle used for data analysis.\n",
        "The consultants at McKinsey and Company named a technique for breaking a quantitative problem down into its component parts called the MECE principle.[63] Each layer can be broken down into its components; each of the sub-components must be mutually exclusive of each other and collectively add up to the layer above them.[64] The relationship is referred to as \"Mutually Exclusive and Collectively Exhaustive\" or MECE. For example, profit by definition can be broken down into total revenue and total cost.[65] In turn, total revenue can be analyzed by its components, such as the revenue of divisions A, B, and C (which are mutually exclusive of each other) and should add to the total revenue (collectively exhaustive).[66]\n",
        "\n",
        "Analysts may use robust statistical measurements to solve certain analytical problems.[67] Hypothesis testing is used when a particular hypothesis about the true state of affairs is made by the analyst and data is gathered to determine whether that state of affairs is true or false.[68][69] For example, the hypothesis might be that \"Unemployment has no effect on inflation\", which relates to an economics concept called the Phillips Curve.[70] Hypothesis testing involves considering the likelihood of Type I and type II errors, which relate to whether the data supports accepting or rejecting the hypothesis.[71][72]\n",
        "\n",
        "Regression analysis may be used when the analyst is trying to determine the extent to which independent variable X affects dependent variable Y (e.g., \"To what extent do changes in the unemployment rate (X) affect the inflation rate (Y)?\").[73] This is an attempt to model or fit an equation line or curve to the data, such that Y is a function of X.[74][75]\n",
        "\n",
        "Necessary condition analysis (NCA) may be used when the analyst is trying to determine the extent to which independent variable X allows variable Y (e.g., \"To what extent is a certain unemployment rate (X) necessary for a certain inflation rate (Y)?\").[73] Whereas (multiple) regression analysis uses additive logic where each X-variable can produce the outcome and the X's can compensate for each other (they are sufficient but not necessary),[76] necessary condition analysis (NCA) uses necessity logic, where one or more X-variables allow the outcome to exist, but may not produce it (they are necessary but not sufficient). Each single necessary condition must be present and compensation is not possible.\"\"\"\n",
        "sentences = tokenize_sentences(sample_text)\n",
        "print(\"Sentences:\", sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZYPZwv4X8Od",
        "outputId": "6b7ca7eb-bdfe-4a19-a01f-e2d4cbb3cecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences: ['Data analysis is the process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making.', '[1] Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, and is used in different business, science, and social science domains.', \"[2] In today's business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively.\", '[3]\\n\\nData mining is a particular data analysis technique that focuses on statistical modeling and knowledge discovery for predictive rather than purely descriptive purposes, while business intelligence covers data analysis that relies heavily on aggregation, focusing mainly on business information.', '[4] In statistical applications, data analysis can be divided into descriptive statistics, exploratory data analysis (EDA), and confirmatory data analysis (CDA).', '[5] EDA focuses on discovering new features in the data while CDA focuses on confirming or falsifying existing hypotheses.', '[6][7] Predictive analytics focuses on the application of statistical models for predictive forecasting or classification, while text analytics applies statistical, linguistic, and structural techniques to extract and classify information from textual sources, a species of unstructured data.', 'All of the above are varieties of data analysis.', \"[8]\\n\\nData integration is a precursor to data analysis, and data analysis is closely linked to data visualization and data dissemination.The process of data analysis\\n\\nData science process flowchart from Doing Data Science, by Schutt & O'Neil (2013)\\nAnalysis refers to dividing a whole into its separate components for individual examination.\", '[10] Data analysis is a process for obtaining raw data, and subsequently converting it into information useful for decision-making by users.', '[1] Data is collected and analyzed to answer questions, test hypotheses, or disprove theories.', '[11]\\n\\nStatistician John Tukey, defined data analysis in 1961, as:\\n\\n\"Procedures for analyzing data, techniques for interpreting the results of such procedures, ways of planning the gathering of data to make its analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data.', '\"[12]\\n\\nThere are several phases that can be distinguished, described below.', 'The phases are iterative, in that feedback from later phases may result in additional work in earlier phases.', '[13] The CRISP framework, used in data mining, has similar steps.', 'Data requirements\\nThe data is necessary as inputs to the analysis, which is specified based upon the requirements of those directing the analytics (or customers, who will use the finished product of the analysis).', '[14][15] The general type of entity upon which the data will be collected is referred to as an experimental unit (e.g., a person or population of people).', 'Specific variables regarding a population (e.g., age and income) may be specified and obtained.', 'Data may be numerical or categorical (i.e., a text label for numbers).', '[13]\\n\\nData collection\\nData is collected from a variety of sources.', '[16][17] A list of data sources are available for study & research.', 'The requirements may be communicated by analysts to custodians of the data; such as, Information Technology personnel within an organization.', '[18] Data collection or data gathering is the process of gathering and measuring information on targeted variables in an established system, which then enables one to answer relevant questions and evaluate outcomes.', 'The data may also be collected from sensors in the environment, including traffic cameras, satellites, recording devices, etc.', 'It may also be obtained through interviews, downloads from online sources, or reading documentation.', '[13]\\n\\nData processing\\n\\nThe phases of the intelligence cycle used to convert raw information into actionable intelligence or knowledge are conceptually similar to the phases in data analysis.', 'Data, when initially obtained, must be processed or organized for analysis.', '[19][20] For instance, these may involve placing data into rows and columns in a table format (known as structured data) for further analysis, often through the use of spreadsheet or statistical software.', '[13]\\n\\nData cleaning\\nMain article: Data cleansing\\nOnce processed and organized, the data may be incomplete, contain duplicates, or contain errors.', '[21][22] The need for data cleaning will arise from problems in the way that the datum are entered and stored.', '[21] Data cleaning is the process of preventing and correcting these errors.', 'Common tasks include record matching, identifying inaccuracy of data, overall quality of existing data, deduplication, and column segmentation.', '[23] Such data problems can also be identified through a variety of analytical techniques.', 'For example; with financial information, the totals for particular variables may be compared against separately published numbers that are believed to be reliable.', '[24][25] Unusual amounts, above or below predetermined thresholds, may also be reviewed.', 'There are several types of data cleaning, that are dependent upon the type of data in the set; this could be phone numbers, email addresses, employers, or other values.', '[26][27] Quantitative data methods for outlier detection, can be used to get rid of data that appears to have a higher likelihood of being input incorrectly.', '[28] Textual data spell checkers can be used to lessen the amount of mistyped words.', 'However, it is harder to tell if the words themselves are correct.', '[29]\\n\\nExploratory data analysis\\nOnce the datasets are cleaned, they can then be analyzed.', 'Analysts may apply a variety of techniques, referred to as exploratory data analysis, to begin understanding the messages contained within the obtained data.', '[30] The process of data exploration may result in additional data cleaning or additional requests for data; thus, the initialization of the iterative phases mentioned in the lead paragraph of this section.', '[31] Descriptive statistics, such as, the average or median, can be generated to aid in understanding the data.', '[32][33] Data visualization is also a technique used, in which the analyst is able to examine the data in a graphical format in order to obtain additional insights, regarding the messages within the data.', '[13]\\n\\nModeling and algorithms\\nMathematical formulas or models (also known as algorithms), may be applied to the data in order to identify relationships among the variables; for example, using correlation or causation.', \"[34][35] In general terms, models may be developed to evaluate a specific variable based on other variable(s) contained within the dataset, with some residual error depending on the implemented model's accuracy (e.g., Data = Model + Error).\", '[36][11]\\n\\nInferential statistics includes utilizing techniques that measure the relationships between particular variables.', '[37] For example, regression analysis may be used to model whether a change in advertising (independent variable X), provides an explanation for the variation in sales (dependent variable Y).', '[38] In mathematical terms, Y (sales) is a function of X (advertising).', '[39] It may be described as (Y = aX + b + error), where the model is designed such that (a) and (b) minimize the error when the model predicts Y for a given range of values of X.', '[40] Analysts may also attempt to build models that are descriptive of the data, in an aim to simplify analysis and communicate results.', '[11]\\n\\nData product\\nA data product is a computer application that takes data inputs and generates outputs, feeding them back into the environment.', '[41] It may be based on a model or algorithm.', 'For instance, an application that analyzes data about customer purchase history, and uses the results to recommend other purchases the customer might enjoy.', '[42][13]\\n\\nCommunication\\n\\nData visualization is used to help understand the results after data is analyzed.', '[43]\\nMain article: Data and information visualization\\nOnce data is analyzed, it may be reported in many formats to the users of the analysis to support their requirements.', '[44] The users may have feedback, which results in additional analysis.', 'As such, much of the analytical cycle is iterative.', '[13]\\n\\nWhen determining how to communicate the results, the analyst may consider implementing a variety of data visualization techniques to help communicate the message more clearly and efficiently to the audience.', '[45] Data visualization uses information displays (graphics such as, tables and charts) to help communicate key messages contained in the data.', '[46] Tables are a valuable tool by enabling the ability of a user to query and focus on specific numbers; while charts (e.g., bar charts or line charts), may help explain the quantitative messages contained in the data.', '[47]\\n\\nQuantitative messages\\nMain article: Data and information visualization\\n\\nA time series illustrated with a line chart demonstrating trends in U.S. federal spending and revenue over time.', 'A scatterplot illustrating the correlation between two variables (inflation and unemployment) measured at points in time.', 'Stephen Few described eight types of quantitative messages that users may attempt to understand or communicate from a set of data and the associated graphs used to help communicate the message.', '[48] Customers specifying requirements and analysts performing the data analysis may consider these messages during the course of the process.', '[49]\\n\\nTime-series: A single variable is captured over a period of time, such as the unemployment rate over a 10-year period.', 'A line chart may be used to demonstrate the trend.', '[50]\\nRanking: Categorical subdivisions are ranked in ascending or descending order, such as a ranking of sales performance (the measure) by salespersons (the category, with each salesperson a categorical subdivision) during a single period.', '[51] A bar chart may be used to show the comparison across the salespersons.', '[52]\\nPart-to-whole: Categorical subdivisions are measured as a ratio to the whole (i.e., a percentage out of 100%).', 'A pie chart or bar chart can show the comparison of ratios, such as the market share represented by competitors in a market.', '[53]\\nDeviation: Categorical subdivisions are compared against a reference, such as a comparison of actual vs. budget expenses for several departments of a business for a given time period.', 'A bar chart can show the comparison of the actual versus the reference amount.', '[54]\\nFrequency distribution: Shows the number of observations of a particular variable for a given interval, such as the number of years in which the stock market return is between intervals such as 0–10%, 11–20%, etc.', 'A histogram, a type of bar chart, may be used for this analysis.', '[55]\\nCorrelation: Comparison between observations represented by two variables (X,Y) to determine if they tend to move in the same or opposite directions.', 'For example, plotting unemployment (X) and inflation (Y) for a sample of months.', 'A scatter plot is typically used for this message.', '[56]\\nNominal comparison: Comparing categorical subdivisions in no particular order, such as the sales volume by product code.', 'A bar chart may be used for this comparison.', '[57]\\nGeographic or geospatial: Comparison of a variable across a map or layout, such as the unemployment rate by state or the number of persons on the various floors of a building.', 'A cartogram is a typical graphic used.', '[58][59]\\nTechniques for analyzing quantitative data\\nSee also: Problem solving\\nAuthor Jonathan Koomey has recommended a series of best practices for understanding quantitative data.', '[60] These include:\\n\\nCheck raw data for anomalies prior to performing an analysis;\\nRe-perform important calculations, such as verifying columns of data that are formula driven;\\nConfirm main totals are the sum of subtotals;\\nCheck relationships between numbers that should be related in a predictable way, such as ratios over time;\\nNormalize numbers to make comparisons easier, such as analyzing amounts per person or relative to GDP or as an index value relative to a base year;\\nBreak problems into component parts by analyzing factors that led to the results, such as DuPont analysis of return on equity.', '[25]\\nFor the variables under examination, analysts typically obtain descriptive statistics for them, such as the mean (average), median, and standard deviation.', '[61] They may also analyze the distribution of the key variables to see how the individual values cluster around the mean.', '[62]\\n\\n\\nAn illustration of the MECE principle used for data analysis.', 'The consultants at McKinsey and Company named a technique for breaking a quantitative problem down into its component parts called the MECE principle.', '[63] Each layer can be broken down into its components; each of the sub-components must be mutually exclusive of each other and collectively add up to the layer above them.', '[64] The relationship is referred to as \"Mutually Exclusive and Collectively Exhaustive\" or MECE.', 'For example, profit by definition can be broken down into total revenue and total cost.', '[65] In turn, total revenue can be analyzed by its components, such as the revenue of divisions A, B, and C (which are mutually exclusive of each other) and should add to the total revenue (collectively exhaustive).', '[66]\\n\\nAnalysts may use robust statistical measurements to solve certain analytical problems.', '[67] Hypothesis testing is used when a particular hypothesis about the true state of affairs is made by the analyst and data is gathered to determine whether that state of affairs is true or false.', '[68][69] For example, the hypothesis might be that \"Unemployment has no effect on inflation\", which relates to an economics concept called the Phillips Curve.', '[70] Hypothesis testing involves considering the likelihood of Type I and type II errors, which relate to whether the data supports accepting or rejecting the hypothesis.', '[71][72]\\n\\nRegression analysis may be used when the analyst is trying to determine the extent to which independent variable X affects dependent variable Y (e.g., \"To what extent do changes in the unemployment rate (X) affect the inflation rate (Y)?\").', '[73] This is an attempt to model or fit an equation line or curve to the data, such that Y is a function of X.', '[74][75]\\n\\nNecessary condition analysis (NCA) may be used when the analyst is trying to determine the extent to which independent variable X allows variable Y (e.g., \"To what extent is a certain unemployment rate (X) necessary for a certain inflation rate (Y)?\").', \"[73] Whereas (multiple) regression analysis uses additive logic where each X-variable can produce the outcome and the X's can compensate for each other (they are sufficient but not necessary),[76] necessary condition analysis (NCA) uses necessity logic, where one or more X-variables allow the outcome to exist, but may not produce it (they are necessary but not sufficient).\", 'Each single necessary condition must be present and compensation is not possible.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_words(text):\n",
        "    return word_tokenize(text)\n",
        "words = tokenize_words(sample_text)\n",
        "print(\"Words:\",words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs3LyK3dakGF",
        "outputId": "879d8d13-0038-4692-e05b-32e7320eabfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words: ['Data', 'analysis', 'is', 'the', 'process', 'of', 'inspecting', ',', 'cleansing', ',', 'transforming', ',', 'and', 'modeling', 'data', 'with', 'the', 'goal', 'of', 'discovering', 'useful', 'information', ',', 'informing', 'conclusions', ',', 'and', 'supporting', 'decision-making', '.', '[', '1', ']', 'Data', 'analysis', 'has', 'multiple', 'facets', 'and', 'approaches', ',', 'encompassing', 'diverse', 'techniques', 'under', 'a', 'variety', 'of', 'names', ',', 'and', 'is', 'used', 'in', 'different', 'business', ',', 'science', ',', 'and', 'social', 'science', 'domains', '.', '[', '2', ']', 'In', 'today', \"'s\", 'business', 'world', ',', 'data', 'analysis', 'plays', 'a', 'role', 'in', 'making', 'decisions', 'more', 'scientific', 'and', 'helping', 'businesses', 'operate', 'more', 'effectively', '.', '[', '3', ']', 'Data', 'mining', 'is', 'a', 'particular', 'data', 'analysis', 'technique', 'that', 'focuses', 'on', 'statistical', 'modeling', 'and', 'knowledge', 'discovery', 'for', 'predictive', 'rather', 'than', 'purely', 'descriptive', 'purposes', ',', 'while', 'business', 'intelligence', 'covers', 'data', 'analysis', 'that', 'relies', 'heavily', 'on', 'aggregation', ',', 'focusing', 'mainly', 'on', 'business', 'information', '.', '[', '4', ']', 'In', 'statistical', 'applications', ',', 'data', 'analysis', 'can', 'be', 'divided', 'into', 'descriptive', 'statistics', ',', 'exploratory', 'data', 'analysis', '(', 'EDA', ')', ',', 'and', 'confirmatory', 'data', 'analysis', '(', 'CDA', ')', '.', '[', '5', ']', 'EDA', 'focuses', 'on', 'discovering', 'new', 'features', 'in', 'the', 'data', 'while', 'CDA', 'focuses', 'on', 'confirming', 'or', 'falsifying', 'existing', 'hypotheses', '.', '[', '6', ']', '[', '7', ']', 'Predictive', 'analytics', 'focuses', 'on', 'the', 'application', 'of', 'statistical', 'models', 'for', 'predictive', 'forecasting', 'or', 'classification', ',', 'while', 'text', 'analytics', 'applies', 'statistical', ',', 'linguistic', ',', 'and', 'structural', 'techniques', 'to', 'extract', 'and', 'classify', 'information', 'from', 'textual', 'sources', ',', 'a', 'species', 'of', 'unstructured', 'data', '.', 'All', 'of', 'the', 'above', 'are', 'varieties', 'of', 'data', 'analysis', '.', '[', '8', ']', 'Data', 'integration', 'is', 'a', 'precursor', 'to', 'data', 'analysis', ',', 'and', 'data', 'analysis', 'is', 'closely', 'linked', 'to', 'data', 'visualization', 'and', 'data', 'dissemination.The', 'process', 'of', 'data', 'analysis', 'Data', 'science', 'process', 'flowchart', 'from', 'Doing', 'Data', 'Science', ',', 'by', 'Schutt', '&', \"O'Neil\", '(', '2013', ')', 'Analysis', 'refers', 'to', 'dividing', 'a', 'whole', 'into', 'its', 'separate', 'components', 'for', 'individual', 'examination', '.', '[', '10', ']', 'Data', 'analysis', 'is', 'a', 'process', 'for', 'obtaining', 'raw', 'data', ',', 'and', 'subsequently', 'converting', 'it', 'into', 'information', 'useful', 'for', 'decision-making', 'by', 'users', '.', '[', '1', ']', 'Data', 'is', 'collected', 'and', 'analyzed', 'to', 'answer', 'questions', ',', 'test', 'hypotheses', ',', 'or', 'disprove', 'theories', '.', '[', '11', ']', 'Statistician', 'John', 'Tukey', ',', 'defined', 'data', 'analysis', 'in', '1961', ',', 'as', ':', \"''\", 'Procedures', 'for', 'analyzing', 'data', ',', 'techniques', 'for', 'interpreting', 'the', 'results', 'of', 'such', 'procedures', ',', 'ways', 'of', 'planning', 'the', 'gathering', 'of', 'data', 'to', 'make', 'its', 'analysis', 'easier', ',', 'more', 'precise', 'or', 'more', 'accurate', ',', 'and', 'all', 'the', 'machinery', 'and', 'results', 'of', '(', 'mathematical', ')', 'statistics', 'which', 'apply', 'to', 'analyzing', 'data', '.', '``', '[', '12', ']', 'There', 'are', 'several', 'phases', 'that', 'can', 'be', 'distinguished', ',', 'described', 'below', '.', 'The', 'phases', 'are', 'iterative', ',', 'in', 'that', 'feedback', 'from', 'later', 'phases', 'may', 'result', 'in', 'additional', 'work', 'in', 'earlier', 'phases', '.', '[', '13', ']', 'The', 'CRISP', 'framework', ',', 'used', 'in', 'data', 'mining', ',', 'has', 'similar', 'steps', '.', 'Data', 'requirements', 'The', 'data', 'is', 'necessary', 'as', 'inputs', 'to', 'the', 'analysis', ',', 'which', 'is', 'specified', 'based', 'upon', 'the', 'requirements', 'of', 'those', 'directing', 'the', 'analytics', '(', 'or', 'customers', ',', 'who', 'will', 'use', 'the', 'finished', 'product', 'of', 'the', 'analysis', ')', '.', '[', '14', ']', '[', '15', ']', 'The', 'general', 'type', 'of', 'entity', 'upon', 'which', 'the', 'data', 'will', 'be', 'collected', 'is', 'referred', 'to', 'as', 'an', 'experimental', 'unit', '(', 'e.g.', ',', 'a', 'person', 'or', 'population', 'of', 'people', ')', '.', 'Specific', 'variables', 'regarding', 'a', 'population', '(', 'e.g.', ',', 'age', 'and', 'income', ')', 'may', 'be', 'specified', 'and', 'obtained', '.', 'Data', 'may', 'be', 'numerical', 'or', 'categorical', '(', 'i.e.', ',', 'a', 'text', 'label', 'for', 'numbers', ')', '.', '[', '13', ']', 'Data', 'collection', 'Data', 'is', 'collected', 'from', 'a', 'variety', 'of', 'sources', '.', '[', '16', ']', '[', '17', ']', 'A', 'list', 'of', 'data', 'sources', 'are', 'available', 'for', 'study', '&', 'research', '.', 'The', 'requirements', 'may', 'be', 'communicated', 'by', 'analysts', 'to', 'custodians', 'of', 'the', 'data', ';', 'such', 'as', ',', 'Information', 'Technology', 'personnel', 'within', 'an', 'organization', '.', '[', '18', ']', 'Data', 'collection', 'or', 'data', 'gathering', 'is', 'the', 'process', 'of', 'gathering', 'and', 'measuring', 'information', 'on', 'targeted', 'variables', 'in', 'an', 'established', 'system', ',', 'which', 'then', 'enables', 'one', 'to', 'answer', 'relevant', 'questions', 'and', 'evaluate', 'outcomes', '.', 'The', 'data', 'may', 'also', 'be', 'collected', 'from', 'sensors', 'in', 'the', 'environment', ',', 'including', 'traffic', 'cameras', ',', 'satellites', ',', 'recording', 'devices', ',', 'etc', '.', 'It', 'may', 'also', 'be', 'obtained', 'through', 'interviews', ',', 'downloads', 'from', 'online', 'sources', ',', 'or', 'reading', 'documentation', '.', '[', '13', ']', 'Data', 'processing', 'The', 'phases', 'of', 'the', 'intelligence', 'cycle', 'used', 'to', 'convert', 'raw', 'information', 'into', 'actionable', 'intelligence', 'or', 'knowledge', 'are', 'conceptually', 'similar', 'to', 'the', 'phases', 'in', 'data', 'analysis', '.', 'Data', ',', 'when', 'initially', 'obtained', ',', 'must', 'be', 'processed', 'or', 'organized', 'for', 'analysis', '.', '[', '19', ']', '[', '20', ']', 'For', 'instance', ',', 'these', 'may', 'involve', 'placing', 'data', 'into', 'rows', 'and', 'columns', 'in', 'a', 'table', 'format', '(', 'known', 'as', 'structured', 'data', ')', 'for', 'further', 'analysis', ',', 'often', 'through', 'the', 'use', 'of', 'spreadsheet', 'or', 'statistical', 'software', '.', '[', '13', ']', 'Data', 'cleaning', 'Main', 'article', ':', 'Data', 'cleansing', 'Once', 'processed', 'and', 'organized', ',', 'the', 'data', 'may', 'be', 'incomplete', ',', 'contain', 'duplicates', ',', 'or', 'contain', 'errors', '.', '[', '21', ']', '[', '22', ']', 'The', 'need', 'for', 'data', 'cleaning', 'will', 'arise', 'from', 'problems', 'in', 'the', 'way', 'that', 'the', 'datum', 'are', 'entered', 'and', 'stored', '.', '[', '21', ']', 'Data', 'cleaning', 'is', 'the', 'process', 'of', 'preventing', 'and', 'correcting', 'these', 'errors', '.', 'Common', 'tasks', 'include', 'record', 'matching', ',', 'identifying', 'inaccuracy', 'of', 'data', ',', 'overall', 'quality', 'of', 'existing', 'data', ',', 'deduplication', ',', 'and', 'column', 'segmentation', '.', '[', '23', ']', 'Such', 'data', 'problems', 'can', 'also', 'be', 'identified', 'through', 'a', 'variety', 'of', 'analytical', 'techniques', '.', 'For', 'example', ';', 'with', 'financial', 'information', ',', 'the', 'totals', 'for', 'particular', 'variables', 'may', 'be', 'compared', 'against', 'separately', 'published', 'numbers', 'that', 'are', 'believed', 'to', 'be', 'reliable', '.', '[', '24', ']', '[', '25', ']', 'Unusual', 'amounts', ',', 'above', 'or', 'below', 'predetermined', 'thresholds', ',', 'may', 'also', 'be', 'reviewed', '.', 'There', 'are', 'several', 'types', 'of', 'data', 'cleaning', ',', 'that', 'are', 'dependent', 'upon', 'the', 'type', 'of', 'data', 'in', 'the', 'set', ';', 'this', 'could', 'be', 'phone', 'numbers', ',', 'email', 'addresses', ',', 'employers', ',', 'or', 'other', 'values', '.', '[', '26', ']', '[', '27', ']', 'Quantitative', 'data', 'methods', 'for', 'outlier', 'detection', ',', 'can', 'be', 'used', 'to', 'get', 'rid', 'of', 'data', 'that', 'appears', 'to', 'have', 'a', 'higher', 'likelihood', 'of', 'being', 'input', 'incorrectly', '.', '[', '28', ']', 'Textual', 'data', 'spell', 'checkers', 'can', 'be', 'used', 'to', 'lessen', 'the', 'amount', 'of', 'mistyped', 'words', '.', 'However', ',', 'it', 'is', 'harder', 'to', 'tell', 'if', 'the', 'words', 'themselves', 'are', 'correct', '.', '[', '29', ']', 'Exploratory', 'data', 'analysis', 'Once', 'the', 'datasets', 'are', 'cleaned', ',', 'they', 'can', 'then', 'be', 'analyzed', '.', 'Analysts', 'may', 'apply', 'a', 'variety', 'of', 'techniques', ',', 'referred', 'to', 'as', 'exploratory', 'data', 'analysis', ',', 'to', 'begin', 'understanding', 'the', 'messages', 'contained', 'within', 'the', 'obtained', 'data', '.', '[', '30', ']', 'The', 'process', 'of', 'data', 'exploration', 'may', 'result', 'in', 'additional', 'data', 'cleaning', 'or', 'additional', 'requests', 'for', 'data', ';', 'thus', ',', 'the', 'initialization', 'of', 'the', 'iterative', 'phases', 'mentioned', 'in', 'the', 'lead', 'paragraph', 'of', 'this', 'section', '.', '[', '31', ']', 'Descriptive', 'statistics', ',', 'such', 'as', ',', 'the', 'average', 'or', 'median', ',', 'can', 'be', 'generated', 'to', 'aid', 'in', 'understanding', 'the', 'data', '.', '[', '32', ']', '[', '33', ']', 'Data', 'visualization', 'is', 'also', 'a', 'technique', 'used', ',', 'in', 'which', 'the', 'analyst', 'is', 'able', 'to', 'examine', 'the', 'data', 'in', 'a', 'graphical', 'format', 'in', 'order', 'to', 'obtain', 'additional', 'insights', ',', 'regarding', 'the', 'messages', 'within', 'the', 'data', '.', '[', '13', ']', 'Modeling', 'and', 'algorithms', 'Mathematical', 'formulas', 'or', 'models', '(', 'also', 'known', 'as', 'algorithms', ')', ',', 'may', 'be', 'applied', 'to', 'the', 'data', 'in', 'order', 'to', 'identify', 'relationships', 'among', 'the', 'variables', ';', 'for', 'example', ',', 'using', 'correlation', 'or', 'causation', '.', '[', '34', ']', '[', '35', ']', 'In', 'general', 'terms', ',', 'models', 'may', 'be', 'developed', 'to', 'evaluate', 'a', 'specific', 'variable', 'based', 'on', 'other', 'variable', '(', 's', ')', 'contained', 'within', 'the', 'dataset', ',', 'with', 'some', 'residual', 'error', 'depending', 'on', 'the', 'implemented', 'model', \"'s\", 'accuracy', '(', 'e.g.', ',', 'Data', '=', 'Model', '+', 'Error', ')', '.', '[', '36', ']', '[', '11', ']', 'Inferential', 'statistics', 'includes', 'utilizing', 'techniques', 'that', 'measure', 'the', 'relationships', 'between', 'particular', 'variables', '.', '[', '37', ']', 'For', 'example', ',', 'regression', 'analysis', 'may', 'be', 'used', 'to', 'model', 'whether', 'a', 'change', 'in', 'advertising', '(', 'independent', 'variable', 'X', ')', ',', 'provides', 'an', 'explanation', 'for', 'the', 'variation', 'in', 'sales', '(', 'dependent', 'variable', 'Y', ')', '.', '[', '38', ']', 'In', 'mathematical', 'terms', ',', 'Y', '(', 'sales', ')', 'is', 'a', 'function', 'of', 'X', '(', 'advertising', ')', '.', '[', '39', ']', 'It', 'may', 'be', 'described', 'as', '(', 'Y', '=', 'aX', '+', 'b', '+', 'error', ')', ',', 'where', 'the', 'model', 'is', 'designed', 'such', 'that', '(', 'a', ')', 'and', '(', 'b', ')', 'minimize', 'the', 'error', 'when', 'the', 'model', 'predicts', 'Y', 'for', 'a', 'given', 'range', 'of', 'values', 'of', 'X', '.', '[', '40', ']', 'Analysts', 'may', 'also', 'attempt', 'to', 'build', 'models', 'that', 'are', 'descriptive', 'of', 'the', 'data', ',', 'in', 'an', 'aim', 'to', 'simplify', 'analysis', 'and', 'communicate', 'results', '.', '[', '11', ']', 'Data', 'product', 'A', 'data', 'product', 'is', 'a', 'computer', 'application', 'that', 'takes', 'data', 'inputs', 'and', 'generates', 'outputs', ',', 'feeding', 'them', 'back', 'into', 'the', 'environment', '.', '[', '41', ']', 'It', 'may', 'be', 'based', 'on', 'a', 'model', 'or', 'algorithm', '.', 'For', 'instance', ',', 'an', 'application', 'that', 'analyzes', 'data', 'about', 'customer', 'purchase', 'history', ',', 'and', 'uses', 'the', 'results', 'to', 'recommend', 'other', 'purchases', 'the', 'customer', 'might', 'enjoy', '.', '[', '42', ']', '[', '13', ']', 'Communication', 'Data', 'visualization', 'is', 'used', 'to', 'help', 'understand', 'the', 'results', 'after', 'data', 'is', 'analyzed', '.', '[', '43', ']', 'Main', 'article', ':', 'Data', 'and', 'information', 'visualization', 'Once', 'data', 'is', 'analyzed', ',', 'it', 'may', 'be', 'reported', 'in', 'many', 'formats', 'to', 'the', 'users', 'of', 'the', 'analysis', 'to', 'support', 'their', 'requirements', '.', '[', '44', ']', 'The', 'users', 'may', 'have', 'feedback', ',', 'which', 'results', 'in', 'additional', 'analysis', '.', 'As', 'such', ',', 'much', 'of', 'the', 'analytical', 'cycle', 'is', 'iterative', '.', '[', '13', ']', 'When', 'determining', 'how', 'to', 'communicate', 'the', 'results', ',', 'the', 'analyst', 'may', 'consider', 'implementing', 'a', 'variety', 'of', 'data', 'visualization', 'techniques', 'to', 'help', 'communicate', 'the', 'message', 'more', 'clearly', 'and', 'efficiently', 'to', 'the', 'audience', '.', '[', '45', ']', 'Data', 'visualization', 'uses', 'information', 'displays', '(', 'graphics', 'such', 'as', ',', 'tables', 'and', 'charts', ')', 'to', 'help', 'communicate', 'key', 'messages', 'contained', 'in', 'the', 'data', '.', '[', '46', ']', 'Tables', 'are', 'a', 'valuable', 'tool', 'by', 'enabling', 'the', 'ability', 'of', 'a', 'user', 'to', 'query', 'and', 'focus', 'on', 'specific', 'numbers', ';', 'while', 'charts', '(', 'e.g.', ',', 'bar', 'charts', 'or', 'line', 'charts', ')', ',', 'may', 'help', 'explain', 'the', 'quantitative', 'messages', 'contained', 'in', 'the', 'data', '.', '[', '47', ']', 'Quantitative', 'messages', 'Main', 'article', ':', 'Data', 'and', 'information', 'visualization', 'A', 'time', 'series', 'illustrated', 'with', 'a', 'line', 'chart', 'demonstrating', 'trends', 'in', 'U.S.', 'federal', 'spending', 'and', 'revenue', 'over', 'time', '.', 'A', 'scatterplot', 'illustrating', 'the', 'correlation', 'between', 'two', 'variables', '(', 'inflation', 'and', 'unemployment', ')', 'measured', 'at', 'points', 'in', 'time', '.', 'Stephen', 'Few', 'described', 'eight', 'types', 'of', 'quantitative', 'messages', 'that', 'users', 'may', 'attempt', 'to', 'understand', 'or', 'communicate', 'from', 'a', 'set', 'of', 'data', 'and', 'the', 'associated', 'graphs', 'used', 'to', 'help', 'communicate', 'the', 'message', '.', '[', '48', ']', 'Customers', 'specifying', 'requirements', 'and', 'analysts', 'performing', 'the', 'data', 'analysis', 'may', 'consider', 'these', 'messages', 'during', 'the', 'course', 'of', 'the', 'process', '.', '[', '49', ']', 'Time-series', ':', 'A', 'single', 'variable', 'is', 'captured', 'over', 'a', 'period', 'of', 'time', ',', 'such', 'as', 'the', 'unemployment', 'rate', 'over', 'a', '10-year', 'period', '.', 'A', 'line', 'chart', 'may', 'be', 'used', 'to', 'demonstrate', 'the', 'trend', '.', '[', '50', ']', 'Ranking', ':', 'Categorical', 'subdivisions', 'are', 'ranked', 'in', 'ascending', 'or', 'descending', 'order', ',', 'such', 'as', 'a', 'ranking', 'of', 'sales', 'performance', '(', 'the', 'measure', ')', 'by', 'salespersons', '(', 'the', 'category', ',', 'with', 'each', 'salesperson', 'a', 'categorical', 'subdivision', ')', 'during', 'a', 'single', 'period', '.', '[', '51', ']', 'A', 'bar', 'chart', 'may', 'be', 'used', 'to', 'show', 'the', 'comparison', 'across', 'the', 'salespersons', '.', '[', '52', ']', 'Part-to-whole', ':', 'Categorical', 'subdivisions', 'are', 'measured', 'as', 'a', 'ratio', 'to', 'the', 'whole', '(', 'i.e.', ',', 'a', 'percentage', 'out', 'of', '100', '%', ')', '.', 'A', 'pie', 'chart', 'or', 'bar', 'chart', 'can', 'show', 'the', 'comparison', 'of', 'ratios', ',', 'such', 'as', 'the', 'market', 'share', 'represented', 'by', 'competitors', 'in', 'a', 'market', '.', '[', '53', ']', 'Deviation', ':', 'Categorical', 'subdivisions', 'are', 'compared', 'against', 'a', 'reference', ',', 'such', 'as', 'a', 'comparison', 'of', 'actual', 'vs.', 'budget', 'expenses', 'for', 'several', 'departments', 'of', 'a', 'business', 'for', 'a', 'given', 'time', 'period', '.', 'A', 'bar', 'chart', 'can', 'show', 'the', 'comparison', 'of', 'the', 'actual', 'versus', 'the', 'reference', 'amount', '.', '[', '54', ']', 'Frequency', 'distribution', ':', 'Shows', 'the', 'number', 'of', 'observations', 'of', 'a', 'particular', 'variable', 'for', 'a', 'given', 'interval', ',', 'such', 'as', 'the', 'number', 'of', 'years', 'in', 'which', 'the', 'stock', 'market', 'return', 'is', 'between', 'intervals', 'such', 'as', '0–10', '%', ',', '11–20', '%', ',', 'etc', '.', 'A', 'histogram', ',', 'a', 'type', 'of', 'bar', 'chart', ',', 'may', 'be', 'used', 'for', 'this', 'analysis', '.', '[', '55', ']', 'Correlation', ':', 'Comparison', 'between', 'observations', 'represented', 'by', 'two', 'variables', '(', 'X', ',', 'Y', ')', 'to', 'determine', 'if', 'they', 'tend', 'to', 'move', 'in', 'the', 'same', 'or', 'opposite', 'directions', '.', 'For', 'example', ',', 'plotting', 'unemployment', '(', 'X', ')', 'and', 'inflation', '(', 'Y', ')', 'for', 'a', 'sample', 'of', 'months', '.', 'A', 'scatter', 'plot', 'is', 'typically', 'used', 'for', 'this', 'message', '.', '[', '56', ']', 'Nominal', 'comparison', ':', 'Comparing', 'categorical', 'subdivisions', 'in', 'no', 'particular', 'order', ',', 'such', 'as', 'the', 'sales', 'volume', 'by', 'product', 'code', '.', 'A', 'bar', 'chart', 'may', 'be', 'used', 'for', 'this', 'comparison', '.', '[', '57', ']', 'Geographic', 'or', 'geospatial', ':', 'Comparison', 'of', 'a', 'variable', 'across', 'a', 'map', 'or', 'layout', ',', 'such', 'as', 'the', 'unemployment', 'rate', 'by', 'state', 'or', 'the', 'number', 'of', 'persons', 'on', 'the', 'various', 'floors', 'of', 'a', 'building', '.', 'A', 'cartogram', 'is', 'a', 'typical', 'graphic', 'used', '.', '[', '58', ']', '[', '59', ']', 'Techniques', 'for', 'analyzing', 'quantitative', 'data', 'See', 'also', ':', 'Problem', 'solving', 'Author', 'Jonathan', 'Koomey', 'has', 'recommended', 'a', 'series', 'of', 'best', 'practices', 'for', 'understanding', 'quantitative', 'data', '.', '[', '60', ']', 'These', 'include', ':', 'Check', 'raw', 'data', 'for', 'anomalies', 'prior', 'to', 'performing', 'an', 'analysis', ';', 'Re-perform', 'important', 'calculations', ',', 'such', 'as', 'verifying', 'columns', 'of', 'data', 'that', 'are', 'formula', 'driven', ';', 'Confirm', 'main', 'totals', 'are', 'the', 'sum', 'of', 'subtotals', ';', 'Check', 'relationships', 'between', 'numbers', 'that', 'should', 'be', 'related', 'in', 'a', 'predictable', 'way', ',', 'such', 'as', 'ratios', 'over', 'time', ';', 'Normalize', 'numbers', 'to', 'make', 'comparisons', 'easier', ',', 'such', 'as', 'analyzing', 'amounts', 'per', 'person', 'or', 'relative', 'to', 'GDP', 'or', 'as', 'an', 'index', 'value', 'relative', 'to', 'a', 'base', 'year', ';', 'Break', 'problems', 'into', 'component', 'parts', 'by', 'analyzing', 'factors', 'that', 'led', 'to', 'the', 'results', ',', 'such', 'as', 'DuPont', 'analysis', 'of', 'return', 'on', 'equity', '.', '[', '25', ']', 'For', 'the', 'variables', 'under', 'examination', ',', 'analysts', 'typically', 'obtain', 'descriptive', 'statistics', 'for', 'them', ',', 'such', 'as', 'the', 'mean', '(', 'average', ')', ',', 'median', ',', 'and', 'standard', 'deviation', '.', '[', '61', ']', 'They', 'may', 'also', 'analyze', 'the', 'distribution', 'of', 'the', 'key', 'variables', 'to', 'see', 'how', 'the', 'individual', 'values', 'cluster', 'around', 'the', 'mean', '.', '[', '62', ']', 'An', 'illustration', 'of', 'the', 'MECE', 'principle', 'used', 'for', 'data', 'analysis', '.', 'The', 'consultants', 'at', 'McKinsey', 'and', 'Company', 'named', 'a', 'technique', 'for', 'breaking', 'a', 'quantitative', 'problem', 'down', 'into', 'its', 'component', 'parts', 'called', 'the', 'MECE', 'principle', '.', '[', '63', ']', 'Each', 'layer', 'can', 'be', 'broken', 'down', 'into', 'its', 'components', ';', 'each', 'of', 'the', 'sub-components', 'must', 'be', 'mutually', 'exclusive', 'of', 'each', 'other', 'and', 'collectively', 'add', 'up', 'to', 'the', 'layer', 'above', 'them', '.', '[', '64', ']', 'The', 'relationship', 'is', 'referred', 'to', 'as', '``', 'Mutually', 'Exclusive', 'and', 'Collectively', 'Exhaustive', \"''\", 'or', 'MECE', '.', 'For', 'example', ',', 'profit', 'by', 'definition', 'can', 'be', 'broken', 'down', 'into', 'total', 'revenue', 'and', 'total', 'cost', '.', '[', '65', ']', 'In', 'turn', ',', 'total', 'revenue', 'can', 'be', 'analyzed', 'by', 'its', 'components', ',', 'such', 'as', 'the', 'revenue', 'of', 'divisions', 'A', ',', 'B', ',', 'and', 'C', '(', 'which', 'are', 'mutually', 'exclusive', 'of', 'each', 'other', ')', 'and', 'should', 'add', 'to', 'the', 'total', 'revenue', '(', 'collectively', 'exhaustive', ')', '.', '[', '66', ']', 'Analysts', 'may', 'use', 'robust', 'statistical', 'measurements', 'to', 'solve', 'certain', 'analytical', 'problems', '.', '[', '67', ']', 'Hypothesis', 'testing', 'is', 'used', 'when', 'a', 'particular', 'hypothesis', 'about', 'the', 'true', 'state', 'of', 'affairs', 'is', 'made', 'by', 'the', 'analyst', 'and', 'data', 'is', 'gathered', 'to', 'determine', 'whether', 'that', 'state', 'of', 'affairs', 'is', 'true', 'or', 'false', '.', '[', '68', ']', '[', '69', ']', 'For', 'example', ',', 'the', 'hypothesis', 'might', 'be', 'that', '``', 'Unemployment', 'has', 'no', 'effect', 'on', 'inflation', \"''\", ',', 'which', 'relates', 'to', 'an', 'economics', 'concept', 'called', 'the', 'Phillips', 'Curve', '.', '[', '70', ']', 'Hypothesis', 'testing', 'involves', 'considering', 'the', 'likelihood', 'of', 'Type', 'I', 'and', 'type', 'II', 'errors', ',', 'which', 'relate', 'to', 'whether', 'the', 'data', 'supports', 'accepting', 'or', 'rejecting', 'the', 'hypothesis', '.', '[', '71', ']', '[', '72', ']', 'Regression', 'analysis', 'may', 'be', 'used', 'when', 'the', 'analyst', 'is', 'trying', 'to', 'determine', 'the', 'extent', 'to', 'which', 'independent', 'variable', 'X', 'affects', 'dependent', 'variable', 'Y', '(', 'e.g.', ',', '``', 'To', 'what', 'extent', 'do', 'changes', 'in', 'the', 'unemployment', 'rate', '(', 'X', ')', 'affect', 'the', 'inflation', 'rate', '(', 'Y', ')', '?', \"''\", ')', '.', '[', '73', ']', 'This', 'is', 'an', 'attempt', 'to', 'model', 'or', 'fit', 'an', 'equation', 'line', 'or', 'curve', 'to', 'the', 'data', ',', 'such', 'that', 'Y', 'is', 'a', 'function', 'of', 'X', '.', '[', '74', ']', '[', '75', ']', 'Necessary', 'condition', 'analysis', '(', 'NCA', ')', 'may', 'be', 'used', 'when', 'the', 'analyst', 'is', 'trying', 'to', 'determine', 'the', 'extent', 'to', 'which', 'independent', 'variable', 'X', 'allows', 'variable', 'Y', '(', 'e.g.', ',', '``', 'To', 'what', 'extent', 'is', 'a', 'certain', 'unemployment', 'rate', '(', 'X', ')', 'necessary', 'for', 'a', 'certain', 'inflation', 'rate', '(', 'Y', ')', '?', \"''\", ')', '.', '[', '73', ']', 'Whereas', '(', 'multiple', ')', 'regression', 'analysis', 'uses', 'additive', 'logic', 'where', 'each', 'X-variable', 'can', 'produce', 'the', 'outcome', 'and', 'the', 'X', \"'s\", 'can', 'compensate', 'for', 'each', 'other', '(', 'they', 'are', 'sufficient', 'but', 'not', 'necessary', ')', ',', '[', '76', ']', 'necessary', 'condition', 'analysis', '(', 'NCA', ')', 'uses', 'necessity', 'logic', ',', 'where', 'one', 'or', 'more', 'X-variables', 'allow', 'the', 'outcome', 'to', 'exist', ',', 'but', 'may', 'not', 'produce', 'it', '(', 'they', 'are', 'necessary', 'but', 'not', 'sufficient', ')', '.', 'Each', 'single', 'necessary', 'condition', 'must', 'be', 'present', 'and', 'compensation', 'is', 'not', 'possible', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3ML9PmKa5Zt",
        "outputId": "dcc42ed5-1ddc-49c2-d5a6-b9adfb591523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2898"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "EaNwRcvsYRPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in words if word.isalpha() and word.lower() not in stop_words]\n",
        "total_tokens_after_preprocessing = len(filtered_tokens)\n",
        "# print(\"NLTK Tokens After Preprocessing:\", filtered_tokens)\n",
        "print(\"Total Number of Tokens:\", total_tokens_after_preprocessing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jSxRp7OYWuS",
        "outputId": "e56c431b-07e0-4379-bfac-372fe9a9c934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Tokens: 1312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk import FreqDist\n",
        "word_freq = FreqDist(filtered_tokens)\n",
        "print(\"Top 10 Most Common Words:\", word_freq.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p5r_WijbSge",
        "outputId": "42426969-8f9e-4531-c236-07f9a4c1f749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Most Common Words: [('data', 69), ('analysis', 35), ('may', 33), ('Data', 25), ('used', 19), ('variable', 11), ('X', 11), ('information', 10), ('variables', 9), ('also', 9)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# plot a histogram of word frequencies\n",
        "word_freq.plot(15, cumulative=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "656fkD37bUdu",
        "outputId": "89cb3ea0-4510-4d1e-e8c6-e200fd87af92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAH5CAYAAACbC9SzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB1uUlEQVR4nO3dd1xV9f8H8Ne97HEvIFtFhjLcq5xliZaaM01zlDMbX3JRWVbufg3LWZZp5qi0cpSVpSmOnORWXCAOVKYgGy5c7uf3B3LjCi6855574fV8PHjEPfd63u/wCi/O+QyFEEKAiIiIyAIp5W6AiIiIqKoYZIiIiMhiMcgQERGRxWKQISIiIovFIENEREQWi0GGiIiILBaDDBEREVksa7kbkJpOp0NiYiJUKhUUCoXc7RAREdF9EEIgJycHtWvXhlJ55+su1T7IJCYmws/PT+42iIiIqAquXr2KunXr3vH5ah9kVCoVgNIvhFqtNtp5tVotDh48iHbt2sHaWp4vo9w9sH7Nrm8OPbA+3wOsX33rZ2dnw8/PT/9z/E6qfZApu52kVquNHmScnJygVqtl/QYiZw+sX7Prm0MPrM/3AOtX//r3GhbCwb5ERERksRhkiIiIyGIxyBAREZHFYpAhIiIii8UgQ0RERBZL1iATEBAAhUJR4SMiIgIAUFhYiIiICLi7u8PZ2RkDBgxASkqKnC0TERGRGZE1yBw6dAhJSUn6j23btgEABg4cCACYNGkSfv/9d6xbtw67d+9GYmIi+vfvL2fLREREZEZkXUfG09PT4PHHH3+M+vXr44knnkBWVhaWL1+ONWvWIDw8HACwYsUKNGzYUL/4DhEREdVsZrMgXlFREb7//ntERkZCoVDgyJEjKC4uRteuXfWvCQsLQ7169XDgwIE7BhmNRgONRqN/nJ2dDaB00R6tVmu0fsvOZcxzWloPrF+z65tDD6zP9wDrV9/693tOhRBCGL16Ffz8888YOnQoEhISULt2baxZswajRo0yCCUA0KZNG3Tu3BmffPJJpeeZMWMGZs6cWeH45s2b4eTkJEnvREREZFx5eXno2bMnsrKy7royv9lckVm+fDl69OiB2rVrP9R5pkyZgsjISP3jsr0a2rVrZ/QtCqKjo9G2bVtZlwaXswfWr9n1zaEH1ud7gPWrb/2yOyr3YhZB5sqVK9i+fTs2btyoP+bj44OioiJkZmbC1dVVfzwlJQU+Pj53PJednR3s7OwqHLe2tpbkL1mq81pSD6xfs+ubQw+sz/cA61e/+vd7PrNYR2bFihXw8vJCz5499cdat24NGxsbREVF6Y+dP38eCQkJaN++vRxt6hUWl2DL6WT8EqfBD9EJsvZCRERUk8l+RUan02HFihUYMWKEQfpycXHBmDFjEBkZiVq1akGtVmPcuHFo37697DOWSnQCr689AQC4VJiIER2DZO2HiIioppI9yGzfvh0JCQkYPXp0hefmz58PpVKJAQMGQKPRoFu3bvjyyy9l6NKQk501/NwccPVmAeJSc6HTCSiVd99mnIiIiIxP9iDz9NNP404Tp+zt7bF48WIsXrzYxF3dW4i3M67eLEB+UQmu3SxAPXdHuVsiIiKqccxijIwlCvVW6T8/l3x/I6uJiIjIuBhkqijUx1n/+fnkHBk7ISIiqrkYZKoopPwVmRQGGSIiIjkwyFRRgLsjrG6N743lFRkiIiJZMMhUkY2VErWdS798F2/kQaMtkbkjIiKimodB5iHUVZV++Up0AvGpeTJ3Q0REVPMwyDwEP+f/vnznUzhziYiIyNQYZB5CHVW5IJOcK2MnRERENRODzEPwMwgyvCJDRERkagwyD6GWvQIq+9LFkbmWDBERkekxyDwEhUKBEK/ShfESswqRVVAsc0dEREQ1C4PMQwrx/m+F3zgujEdERGRSDDIPyWCFX95eIiIiMikGmYcU6s09l4iIiOTCIPOQQhhkiIiIZMMg85BcHW3hrbYDAJxPyYEQQuaOiIiIag4GGSMI9VEDALIKipGSrZG5GyIiopqDQcYIwnzKD/jlwnhERESmwiBjBKHlZi5xnAwREZHpMMgYQWi5KzLnuZYMERGRyTDIGEEDL2coFaWf84oMERGR6TDIGIG9jRUCPJwAAHGpudCW6GTuiIiIqGZgkDGSsgG/RVodLqfny9wNERFRzcAgYyTltyqI5TgZIiIik2CQMRLDKdgMMkRERKbAIGMkZYviAcB5riVDRERkEgwyRlKvliPsbUq/nJy5REREZBoMMkZipVQg2Kv09tKVjHwUFJXI3BEREVH1xyBjRGUL4wkBxKXyqgwREZHUGGSMiAN+iYiITItBxogMtipgkCEiIpIcg4wRhXItGSIiIpNikDEiT5Ud3BxtAPDWEhERkSkwyBiRQqHQ315Ky9EgI69I5o6IiIiqNwYZIwsrtzDeOS6MR0REJCkGGSMz2HOJt5eIiIgkxSBjZAYzlzjgl4iISFIMMkYWyrVkiIiITIZBxsic7axR180BQOmtJZ1OyNwRERFR9cUgI4Gy9WTyikpwPbNA5m6IiIiqLwYZCXCFXyIiItNgkJEAB/wSERGZBoOMBAzXkmGQISIikorsQeb69et44YUX4O7uDgcHBzRt2hSHDx/WPy+EwLRp0+Dr6wsHBwd07doVcXFxMnZ8b4EeTrBWKgBwLRkiIiIpyRpkbt68iY4dO8LGxgZ//fUXzpw5g7lz58LNzU3/mjlz5mDRokVYsmQJoqOj4eTkhG7duqGwsFDGzu/O1lqJ+p7OAID4tFwUaXUyd0RERFQ9WctZ/JNPPoGfnx9WrFihPxYYGKj/XAiBBQsW4P3330ffvn0BAKtXr4a3tzd+/fVXDB482OQ9369QHxXOp+RAqxO4eCPX4HYTERERGYesQea3335Dt27dMHDgQOzevRt16tTB//73P4wdOxYAcOnSJSQnJ6Nr1676P+Pi4oK2bdviwIEDlQYZjUYDjUajf5ydXbrfkVarhVarNVrvZee60zmDvZz0n5+9noUGHo5Gq32/PUiN9Wt2fXPogfX5HmD96lv/fs+pEELItmKbvb09ACAyMhIDBw7EoUOHMGHCBCxZsgQjRozA/v370bFjRyQmJsLX11f/5wYNGgSFQoGffvqpwjlnzJiBmTNnVji+efNmODk5VTgulWMpWiw4Wnr7q1eQDQaG2pmsNhERkaXLy8tDz549kZWVBbX6znc1ZL0io9Pp8Mgjj+DDDz8EALRs2RIxMTH6IFMVU6ZMQWRkpP5xdnY2/Pz80K5du7t+IR6UVqtFdHQ02rZtC2vril9G/5sFWHD0HwBAno0rOnZsZbTa99uD1Fi/Ztc3hx5Yn+8B1q++9cvuqNyLrEHG19cXjRo1MjjWsGFDbNiwAQDg4+MDAEhJSTG4IpOSkoIWLVpUek47OzvY2VW8+mFtbS3JX/Kdzuvv4QxnO2vkarSITcmV9A0m1f8b67O+pfTA+nwPsH71q3+/55N11lLHjh1x/vx5g2OxsbHw9/cHUDrw18fHB1FRUfrns7OzER0djfbt25u01welUCgQ4l06c+l6ZgFyCotl7oiIiKj6kTXITJo0CQcPHsSHH36ICxcuYM2aNVi6dCkiIiIAlIaBiRMn4oMPPsBvv/2GU6dOYfjw4ahduzb69esnZ+v3pfwKv7EpuTJ2QkREVD3Jei3y0UcfxS+//IIpU6Zg1qxZCAwMxIIFCzBs2DD9ayZPnoy8vDy8/PLLyMzMxGOPPYYtW7boBwqbs7LNI4HSPZda+7vd5dVERET0oOS9qQqgV69e6NWr1x2fVygUmDVrFmbNmmXCrowjtNzaMeeT72/QEhEREd0/2bcoqM64eSQREZG0GGQkVMvJFp6q0hlU55NzIOOSPURERNUSg4zEwm5dlbmZX4y0HM09Xk1EREQPgkFGYuUH/J7jTthERERGxSAjMcMp2AwyRERExsQgI7HyQYZXZIiIiIyLQUZiwV4qKBSln59nkCEiIjIqBhmJOdhaIcC9dNft2JQclOg4c4mIiMhYGGRMoGzAr0arQ0JGvszdEBERVR8MMiYQUn5hPK7wS0REZDQMMiYQxgG/REREkmCQMQGDrQoYZIiIiIyGQcYEAtydYGtd+qXmnktERETGwyBjAlZKBYK9nAEAl2/kobC4ROaOiIiIqgcGGRMpu72kE8CF1FyZuyEiIqoeGGRMhAN+iYiIjI9BxkRCfdT6z7nnEhERkXEwyJgId8EmIiIyPgYZE/FW28HFwQYAF8UjIiIyFgYZE1EoFPoBvynZGmTmF8ncERERkeVjkDGhMC6MR0REZFQMMiYUUm6cDBfGIyIiengMMibEKdhERETGxSBjQiG8tURERGRUDDImpLa3QR1XBwBAbHIOhBAyd0RERGTZGGRMLMS7dM+lHI0WiVmFMndDRERk2RhkTKz8Cr9cT4aIiOjhMMiYGAf8EhERGQ+DjImFlgsysQwyRERED4VBxsSCPJ1gpVQA4BUZIiKih8UgY2J21lYI8nACAMSn5aK4RCdzR0RERJaLQUYGZbeXiksELt3Ik7kbIiIiy8UgIwPuuURERGQcDDIyMNhziUGGiIioyhhkZBBWbi0ZDvglIiKqOgYZGdR1c4CjrRUA4HwKF8UjIiKqKgYZGSiVCv3tpasZBcjTaGXuiIiIyDIxyMgktNw4mdgU3l4iIiKqCgYZmYRy5hIREdFDY5CRCfdcIiIiengMMjIx2HOJt5aIiIiqhEFGJu7OdvBwtgXAW0tERERVxSAjo7KrMul5RUjL0cjcDRERkeWRNcjMmDEDCoXC4CMsLEz/fGFhISIiIuDu7g5nZ2cMGDAAKSkpMnZsXKHe/y2Mx6syRERED072KzKNGzdGUlKS/mPv3r365yZNmoTff/8d69atw+7du5GYmIj+/fvL2K1xGey5xHEyRERED8xa9gasreHj41PheFZWFpYvX441a9YgPDwcALBixQo0bNgQBw8eRLt27UzdqtGFGEzB5gq/RERED0r2IBMXF4fatWvD3t4e7du3x0cffYR69erhyJEjKC4uRteuXfWvDQsLQ7169XDgwIE7BhmNRgON5r/xJtnZpQFBq9VCqzXeCrpl53qYcwa520OhAIQAziVlP/C5jNHDw2D9ml3fHHpgfb4HWL/61r/fcyqEEMLo1e/TX3/9hdzcXISGhiIpKQkzZ87E9evXERMTg99//x2jRo0yCCUA0KZNG3Tu3BmffPJJpeecMWMGZs6cWeH45s2b4eTkJMn/x8N4a3ceUvMFbK2Ar59yglKhkLslIiIi2eXl5aFnz57IysqCWq2+4+tkvSLTo0cP/efNmjVD27Zt4e/vj59//hkODg5VOueUKVMQGRmpf5ydnQ0/Pz+0a9furl+IB6XVahEdHY22bdvC2rrqX8bml49h29lUFJUA9Rq2gr+7o8l7qCrWr9n1zaEH1ud7gPWrb/2yOyr3IvutpfJcXV0REhKCCxcu4KmnnkJRUREyMzPh6uqqf01KSkqlY2rK2NnZwc7OrsJxa2trSf6SH/a8Yb5qbDubCgC4cCMf9b0fPGxJ9f/G+qxvKT2wPt8DrF/96t/v+WSftVRebm4u4uPj4evri9atW8PGxgZRUVH658+fP4+EhAS0b99exi6Ni3suERERVZ2sEf7NN99E79694e/vj8TEREyfPh1WVlYYMmQIXFxcMGbMGERGRqJWrVpQq9UYN24c2rdvXy1mLJUJY5AhIiKqMlmDzLVr1zBkyBCkp6fD09MTjz32GA4ePAhPT08AwPz586FUKjFgwABoNBp069YNX375pZwtG12AuxNsrZQoKtFxLRkiIqIHJGuQ+fHHH+/6vL29PRYvXozFixebqCPTs7ZSor6XM84mZePSjTxotCWws7aSuy0iIiKLYFZjZGqqsttLJTqBC6m5MndDRERkORhkzAAH/BIREVUNg4wZCOWeS0RERFXCIGMGQr15RYaIiKgqGGTMgK+LPVT2peOuGWSIiIjuH4OMGVAoFPoBv0lZhcjKL5a5IyIiIsvAIGMmyo+TiU3lVRkiIqL7wSBjJsqPkznH20tERET3hUHGTIT6/LdZ5Pnk+9vxk4iIqKZjkDETnLlERET04BhkzISLow18XewBlAYZIYTMHREREZk/BhkzEnLrqkx2oRbJ2YUyd0NERGT+GGTMSJgPB/wSERE9CAYZM8I9l4iIiB4Mg4wZMVhLhkGGiIjonhhkzEh9T2dYKRUAeGuJiIjofjDImBF7GysEuDsCAC6k5UJbopO5IyIiIvPGIGNmwm4tjFek1eFyep7M3RAREZk3BhkzYzjgN1fGToiIiMwfg4yZCTFY4ZdbFRAREd0Ng4yZ4VoyRERE949BxszUq+UIBxsrAMD5FAYZIiKiu2GQMTNKpQIh3s4AgISMfOQXaWXuiIiIyHwxyJihsnEyQgBxKRzwS0REdCcMMmaIWxUQERHdHwYZM1S2lgzAAb9ERER3wyBjhgz2XOKAXyIiojtikDFDHs62qOVkC4BXZIiIiO6GQcYMKRQKhN4a8HsjV4P0XI3MHREREZknBhkzxQG/RERE98YgY6bKr/DLhfGIiIgqxyBjpkJ4RYaIiOieGGTMVPnNIzngl4iIqHIMMmbK2c4afrUcAJROwdbphMwdERERmR8GGTMW6l26MF5+UQmuZxbI3A0REZH5YZAxY6E+zvrPeXuJiIioIgYZMxZabquC88nZMnZCRERknqoUZI4ePYpTp07pH2/atAn9+vXDu+++i6KiIqM1V9OVn4LNKzJEREQVVSnIvPLKK4iNjQUAXLx4EYMHD4ajoyPWrVuHyZMnG7XBmizQwwk2VgoA3HOJiIioMlUKMrGxsWjRogUAYN26dejUqRPWrFmDlStXYsOGDcbsr0azsVKivmfpOJmLaXko0upk7oiIiMi8VCnICCGg05X+UN2+fTueeeYZAICfnx9u3LhhvO5Iv1WBVicQn5YrczdERETmpUpB5pFHHsEHH3yA7777Drt370bPnj0BAJcuXYK3t7dRG6zpuOcSERHRnVUpyMyfPx9Hjx7F66+/jvfeew8NGjQAAKxfvx4dOnQwaoM1HfdcIiIiurMqBZnmzZvj1KlTyMrKwvTp0/XHP/30U6xevbpKjXz88cdQKBSYOHGi/lhhYSEiIiLg7u4OZ2dnDBgwACkpKVU6v6Uqv1UBr8gQEREZqlKQCQoKQnp6eoXjhYWFCAkJeeDzHTp0CF9//TWaNWtmcHzSpEn4/fffsW7dOuzevRuJiYno379/VVq2WHVcHaCyswbAIENERHS7KgWZy5cvo6SkpMJxjUaDa9euPdC5cnNzMWzYMCxbtgxubm7641lZWVi+fDnmzZuH8PBwtG7dGitWrMD+/ftx8ODBqrRtkRQKhX4n7OuZBcguLJa5IyIiIvNh/SAv/u233/Sfb926FS4uLvrHJSUliIqKQmBg4AM1EBERgZ49e6Jr16744IMP9MePHDmC4uJidO3aVX8sLCwM9erVw4EDB9CuXbtKz6fRaKDRaPSPs7NLV8TVarXQarUP1NvdlJ3LmOe8kxAvJxy5chMAcC4xE63quZm8h8qwfs2ubw49sD7fA6xffevf7zkVQoj73lZZqSy9gKNQKHD7H7OxsUFAQADmzp2LXr163df5fvzxR/zf//0fDh06BHt7ezz55JNo0aIFFixYgDVr1mDUqFEGoQQA2rRpg86dO+OTTz6p9JwzZszAzJkzKxzfvHkznJyc7qsvc7P9ShG+O1O6YvLIxnboXM9G5o6IiIiklZeXh549eyIrKwtqtfqOr3ugKzJla8cEBgbi0KFD8PDwqHKDV69exYQJE7Bt2zbY29tX+Ty3mzJlCiIjI/WPs7Oz4efnh3bt2t31C/GgtFotoqOj0bZtW1hbP9CX8YFZ187Ad2cOldZ19kLHjo1M3kNlWL9m1zeHHlif7wHWr771y+6o3EuVql66dKkqf8zAkSNHkJqailatWumPlZSU4J9//sEXX3yBrVu3oqioCJmZmXB1ddW/JiUlBT4+Pnc8r52dHezs7Coct7a2luQvWarzlte4jqv+89jUvAr1TNHD3bB+za5vDj2wPt8DrF/96t/v+apcNSoqClFRUUhNTdVfqSnz7bff3vPPd+nSxWDjSQAYNWoUwsLC8Pbbb8PPzw82NjaIiorCgAEDAADnz59HQkIC2rdvX9W2LZKroy281XZIydYgNiUHQggoFAq52yIiIpJdlYLMzJkzMWvWLDzyyCPw9fWt0g9VlUqFJk2aGBxzcnKCu7u7/viYMWMQGRmJWrVqQa1WY9y4cWjfvv0dB/pWZ6E+aqRkpyEzvxipORp4q413O46IiMhSVSnILFmyBCtXrsSLL75o7H4MzJ8/H0qlEgMGDIBGo0G3bt3w5ZdfSlrTXIV6O+Of2DQAwLnkHAYZIiIiVDHIFBUVSbIVwa5duwwe29vbY/HixVi8eLHRa1maUJ//BiqfT87GEyGeMnZDRERkHqq0IN5LL72ENWvWGLsXuguDPZeSuQs2ERERUMUrMoWFhVi6dCm2b9+OZs2awcbGcF2TefPmGaU5+k8DL2coFYBOAOdT7m9KGhERUXVXpSBz8uRJtGjRAgAQExNj8Bxn00jD3sYKAe5OuHgjD3EpuSjR3fc6hkRERNVWlYLMzp07jd0H3YdQHxUu3siDRqvD5fQ8+LtxwC8REdVsVRojQ/IILTdOJpY7YRMREVXtikznzp3vegtpx44dVW6I7qz8gN9zyTl4qiFnLhERUc1WpSBTNj6mTHFxMY4fP46YmBiMGDHCGH1RJUK8y89c4hUZIiKiKgWZ+fPnV3p8xowZyM3l1GCp+Ls7wd5GicJiHc6nMMgQEREZdYzMCy+8cF/7LFHVWCkVCPYqvSpzOT0PhcUlMndEREQkL6MGmQMHDsDenjNppFQ24FcI4EIqr34REVHNVqVbS/379zd4LIRAUlISDh8+jKlTpxqlMapcaPlxMim58JGxFyIiIrlVKci4uLgYPFYqlQgNDcWsWbPw9NNPG6UxqpzBFOyUXJTbgomIiKjGqVKQWbFihbH7oPtksOdSSg46McgQEVENVqUgU+bIkSM4e/YsAKBx48Zo2bKlUZqiO/NU2cHN0QY384sRm5ILBNvc+w8RERFVU1UKMqmpqRg8eDB27doFV1dXAEBmZiY6d+6MH3/8EZ6eXKhNKgqFAiHeKkRfykBqjga5RQ+VRYmIiCxalWYtjRs3Djk5OTh9+jQyMjKQkZGBmJgYZGdnY/z48cbukW5T/vbStRydjJ0QERHJq0q/zm/ZsgXbt29Hw4YN9ccaNWqExYsXc7CvCYSWG+F7NZdryRARUc1VpSsyOp0ONjYVx2bY2NhAp+MVAqmF8ooMERERgCoGmfDwcEyYMAGJiYn6Y9evX8ekSZPQpUsXozVHlQvxdtZ/ziBDREQ1WZWCzBdffIHs7GwEBASgfv36qF+/PgIDA5GdnY3PP//c2D3SbVT2Nqjj6gAAuJilw7gfj+PPU0koKOJtJiIiqlmqNEbGz88PR48exfbt23Hu3DkAQMOGDdG1a1ejNkd31trfDdczC6ATwF8xKfgrJgUONlbo0tALvZr54slQL9jbWMndJhERkaQeKMjs2LEDr7/+Og4ePAi1Wo2nnnoKTz31FAAgKysLjRs3xpIlS/D4449L0iz9Z2qvRnC2s8Lvx68hp0gAAAqKS/DHyST8cTIJTrZW6NrIGz2b+qJTiCdDDRERVUsPFGQWLFiAsWPHQq2uuJysi4sLXnnlFcybN49BxgQ8VXaY1acRurplwMq3IbacScGWmGTczC8GAOQVlWDT8URsOp4IZztrPHUr1Dwe4gE7a4YaIiKqHh4oyJw4cQKffPLJHZ9/+umn8dlnnz10U3T/rJQKdGzgjifCvDGrbxMciE/H5pNJ2HI6GVkFpaEmV6PFL8eu45dj16Gys8ZTjb3Ru1ltdGzgAVtro26ATkREZFIPFGRSUlIqnXatP5m1NdLS0h66KaoaGyslOoV4olOIJ2b3a4J98Tew+WQStp5ORk6hFgCQo9Fi49Hr2Hj0OtT21ujW2Ac9m/miYwMP2Fgx1BARkWV5oCBTp04dxMTEoEGDBpU+f/LkSfj6+hqlMXo4ttZKdA71QudQL3z4bFPsvZCGP04mYdvpFORoSkNNdqEW645cw7oj1+DqaINujUpDTYf67rBmqCEiIgvwQEHmmWeewdSpU9G9e3fY29sbPFdQUIDp06ejV69eRm2QHp6ttRLhYd4ID/OGRluCPbE38MfJRGw7k4K8W1O2M/OL8dPhq/jp8FW4OdqgexNf9Grmi7aBtRhqiIjIbD1QkHn//fexceNGhISE4PXXX0doaCgA4Ny5c1i8eDFKSkrw3nvvSdIoGYeddelspq6NvFFYXILdsWnYfDIJ28+mIP9WqLmZX4y1/yZg7b8JcHeyRfcmpVdq2ga6w0qpkPn/gIiI6D8PFGS8vb2xf/9+vPbaa5gyZQqEKJ32q1Ao0K1bNyxevBje3t6SNErGZ29jhW6NfdCtsQ8Ki0uw63wq/jiZhKizqSgoLg016XlF+CE6AT9EJ8DD2Q49mvigVzNfPBJQS+buiYiIqrAgnr+/P/7880/cvHkTFy5cgBACwcHBcHNzk6I/MhF7Gyt0b+KL7k18kV+kxc5zadh8KhE7zqWisLh0G4QbuRp8d/AKvjt4BV4qO3Rv7I1Qa64mTERE8qnSyr4A4ObmhkcffdSYvZCZcLS1Rs9mvujZzBd5Gi12nEvF5pNJ2Hk+FRptaahJzdFg9cEEWCuABg1vom19T5m7JiKimqjKQYZqBic7a/RuXhu9m9dGrkaLqLMp+ONkEnafT0NRiQ5aAUz8+ST+mvA4XB1t5W6XiIhqGE5HofvmbGeNvi3qYNnwR3B4alc8GlB6OzEpqxBvrjupHzNFRERkKgwyVCVqexvMH9QMzrfWR9x+NgXf7rssa09ERFTzMMhQlfmo7fFys//WE/r4r7M4cTVTvoaIiKjGYZChh9LcyxpjHwsAABSXCLy+9iiyC4vlbYqIiGoMBhl6aJFPBaNlPVcAwNWMAryzgeNliIjINBhk6KHZWCmxaHBLqO1LJ8H9eSoZ30cnyNwVERHVBAwyZBR+tRzx6cDm+sez/ziD04lZMnZEREQ1AYMMGU23xj4Y2SEAAFCk1WHcmmPIvbXTNhERkRQYZMiopjwThiZ11ACAizfy8P4vpzhehoiIJMMgQ0ZlZ22FL4a0grNd6XiZX48nYt2RazJ3RURE1RWDDBldgIcTPuzfVP942qYYxKbkyNgRERFVVwwyJIk+zWtjSJt6AIDCYh0ifjiKgiLulE1ERMYla5D56quv0KxZM6jVaqjVarRv3x5//fWX/vnCwkJERETA3d0dzs7OGDBgAFJSUmTsmB7E9N6NEOajAgDEpeZixm+nZe6IiIiqG1mDTN26dfHxxx/jyJEjOHz4MMLDw9G3b1+cPl36A2/SpEn4/fffsW7dOuzevRuJiYno37+/nC3TA7C3scIXQ1vBwcYKAPDT4av49dh1mbsiIqLqxFrO4r179zZ4/H//93/46quvcPDgQdStWxfLly/HmjVrEB4eDgBYsWIFGjZsiIMHD6Jdu3aVnlOj0UCj0egfZ2dnAwC0Wi20WuNNBS47lzHPaWk93E/9gFr2mNWnId7aEAMAeO+XU2js64xADyeT1JdSTa9vDj2wPt8DrF9969/vORXCTObGlpSUYN26dRgxYgSOHTuG5ORkdOnSBTdv3oSrq6v+df7+/pg4cSImTZpU6XlmzJiBmTNnVji+efNmODk9/A9PqpplJwux93rpm7KeSomp7R1ga6WQuSsiIjJXeXl56NmzJ7KysqBWq+/4OlmvyADAqVOn0L59exQWFsLZ2Rm//PILGjVqhOPHj8PW1tYgxACAt7c3kpOT73i+KVOmIDIyUv84Ozsbfn5+aNeu3V2/EA9Kq9UiOjoabdu2hbW1PF9GuXt4kPotHtGi/5KDiE/LQ0KODruyamFm70Ymqy+Fml7fHHpgfb4HWL/61i+7o3IvsgeZ0NBQHD9+HFlZWVi/fj1GjBiB3bt3V/l8dnZ2sLOzq3Dc2tpakr9kqc5rST3cT30Xa2ssHtYKfb/YB41Whx+ir6JjA08809TXJPWlVNPrm0MPrM/3AOtXv/r3ez7Zp1/b2tqiQYMGaN26NT766CM0b94cCxcuhI+PD4qKipCZmWnw+pSUFPj4+MjTLD2UMB81ZvRprH/89vqTSEjPl7EjIiKydLIHmdvpdDpoNBq0bt0aNjY2iIqK0j93/vx5JCQkoH379jJ2SA9j8KN+6N28NgAgR6PFuLVHUaTVydwVERFZKlmvRU6ZMgU9evRAvXr1kJOTgzVr1mDXrl3YunUrXFxcMGbMGERGRqJWrVpQq9UYN24c2rdvf8cZS2T+FAoFPny2CU5ey8SV9HycuJaFOVvO4f1eDzdehoiIaiZZg0xqaiqGDx+OpKQkuLi4oFmzZti6dSueeuopAMD8+fOhVCoxYMAAaDQadOvWDV9++aWcLZMRqOxtsHhoK/T/cj+KSnT4Zu8ltAtyR9dG3nK3RkREFkbWILN8+fK7Pm9vb4/Fixdj8eLFJuqITKVJHRe8+0wYZvx+BgDwxroT+HPC46jj6iBzZ0REZEnMbowM1RwjOgSgW+PSqzBZBcUYv/YYiks4XoaIiO4fgwzJRqFQYM6A5vqrMEeu3MT8bbEyd0VERJaEQYZk5eJog8+HtoS1snSV3y93xWN3bJrMXRERkaVgkCHZtarnhsndQ/WPI386jtTsQhk7IiIiS8EgQ2bhpceC0DnUEwCQnleECT8eR4nOLLYBIyIiM8YgQ2ZBqVRg7qAW8FaXbi9x4GI6Pt8RJ3NXRERk7hhkyGzUcrLFosEtcWu4DBZGxWF//A15myIiIrPGIENmpW2QOyKfCgEACAFM/PE4buRqZO6KiIjMFYMMmZ3XnmyAxxp4AABSczSI/PkEdBwvQ0RElWCQIbNjpVRg3vPN4eFcOl7mn9g0LPknXuauiIjIHDHIkFnyUtljwfMtoLg1Xmbu37E4fDlD3qaIiMjsMMiQ2Xos2AOvd24AACjRCYxfeww384pk7oqIiMwJgwyZtQldgtEmoBYAIDGrEG+tPwEhOF6GiIhKMciQWbO2UmLRkJZwc7QBAGw/m4pv912WtykiIjIbDDJk9nxc7DFvUAv944//OosTVzNl64eIiMwHgwxZhM5hXnilUxAAoLhE4PW1R5FdUCxzV0REJDcGGbIYb3YLRct6rgCAqxkFePfX0xwvQ0RUwzHIkMWwsVJi0eCWUNtbAwC2nE7BjgStzF0REZGcGGTIovjVcsSnA5vrH689p8HRhEz5GiIiIlkxyJDF6dbYByM7BAAAinXA6FVHcCzhprxNERGRLBhkyCJNeSYMHYJK15fJ1WgxfPm/nMlERFQDMciQRbKztsLXL7RCw1pWAIAcjRYvLI/GyWuZ8jZGREQmxSBDFsvB1gqTWtujTYAbACCnUIsXvolGzPUsmTsjIiJTYZAhi2ZnrcA3w1uhTWDpbabsQi2GMcwQEdUYDDJk8RxtrbFi5KN49NaVmayCYrywPBpnErNl7oyIiKTGIEPVgpOdNVaMaoPW/qVhJjO/GMO+OYizSQwzRETVGYMMVRvOdtZYOepRtLq1+u/N/GIM+yYa55Nz5G2MiIgkwyBD1YrK3gYrR7dBCz9XAEBGXhGGLjuI2BSGGSKi6ohBhqodtb0NVo9pg+Z1XQAA6bfCTBzDDBFRtcMgQ9VSaZhpi2a3wsyN3CIMWRaNC6m5MndGRETGxCBD1ZaLgw2+G90WTeqoAQA3cjUYsuwg4tMYZoiIqgsGGarWXBxt8P2YtmjkWxpm0nI0GLL0IC7dyJO5MyIiMgYGGar2XB1t8cNLbdHwVphJvRVmLjPMEBFZPAYZqhHcnErDTJiPCgCQnF2IIcsO4ko6wwwRkSVjkKEao9atMBPqXRpmkrIKMWTpQSSk58vcGRERVRWDDNUo7s52+GFsWwR7OQMAErNKr8xczWCYISKyRAwyVON4ONthzdh2aHArzFzPLMCQZQdx7SbDDBGRpWGQoRrJU2WHNWPbor6nEwDg2s3SMHM9s0DmzoiI6EEwyFCN5aWyx9qx7RDkURpmrmYUYMjSg0jKYpghIrIUDDJUo3mp7bH25XYIvBVmEjLyMXjpQSRnFcrcGRER3Q8GGarxvNWlV2YC3B0BAFfS8zFk2UGkZDPMEBGZOwYZIgA+LqVXZvxvhZlLN/IwZOlBpDLMEBGZNQYZolt8XRywdmw7+NVyAABcvJGHIcsOIjWHYYaIyFzJGmQ++ugjPProo1CpVPDy8kK/fv1w/vx5g9cUFhYiIiIC7u7ucHZ2xoABA5CSkiJTx1Td1XYtDTN13UrDTHxaHoYui0ZajkbmzoiIqDKyBpndu3cjIiICBw8exLZt21BcXIynn34aeXn/LRs/adIk/P7771i3bh12796NxMRE9O/fX8auqbqr6+aItWPboY5raZi5kJqLocsO4kYuwwwRkbmxlrP4li1bDB6vXLkSXl5eOHLkCDp16oSsrCwsX74ca9asQXh4OABgxYoVaNiwIQ4ePIh27dpVOKdGo4FG898PnOzsbACAVquFVqs1Wu9l5zLmOS2th+pc31dti+9HP4Khyw8hKasQcbfCzHejH4W7k63k9e+H3PXNoQfW53uA9atv/fs9p0IIIYxevYouXLiA4OBgnDp1Ck2aNMGOHTvQpUsX3Lx5E66urvrX+fv7Y+LEiZg0aVKFc8yYMQMzZ86scHzz5s1wcnKSsn2qhlLzdfgougAZhaX/TOqqlHinjQNUtgqZOyMiqt7y8vLQs2dPZGVlQa1W3/F1sl6RKU+n02HixIno2LEjmjRpAgBITk6Gra2tQYgBAG9vbyQnJ1d6nilTpiAyMlL/ODs7G35+fmjXrt1dvxAPSqvVIjo6Gm3btoW1tTxfRrl7qCn1W7XKx9Dl/yIlW4NrOTosPq3E6tGPQGWrrBH//+bcA+vzPcD61bd+2R2VezGbIBMREYGYmBjs3bv3oc5jZ2cHOzu7Csetra0l+UuW6ryW1EN1r1/fW40fX26PwUsPICVbg7PJORix4ghWj2ptkvr3Ind9c+iB9fkeYP3qV/9+z2cW069ff/11/PHHH9i5cyfq1q2rP+7j44OioiJkZmYavD4lJQU+Pj4m7pJqskAPJ6wd2w5eqtKQfCYpGyNWHkFesdncmSUiqpFkDTJCCLz++uv45ZdfsGPHDgQGBho837p1a9jY2CAqKkp/7Pz580hISED79u1N3S7VcEGezlgzth08b4WZ04nZmPNvAbILimXujIio5pI1yEREROD777/HmjVroFKpkJycjOTkZBQUlG7a5+LigjFjxiAyMhI7d+7EkSNHMGrUKLRv377SGUtEUmvg5Yy1Y9vCw7k0zFzO1mHizyeh0/HKDBGRHGQNMl999RWysrLw5JNPwtfXV//x008/6V8zf/589OrVCwMGDECnTp3g4+ODjRs3ytg11XQNvFRYO7Yt3BxtAAD/xN3A0j0XZe6KiKhmknV02P3M/La3t8fixYuxePFiE3REdH+CvVVYMKg5Rq48DAHg063n8WiAG1r715K7NSKiGsUsBvsSWaKODdzRq37pVZkSncD4tceRmV8kc1dERDULgwzRQ3i2gS0e9XcDAFzPLMCb607e15VGIiIyDgYZoodgpVRg3qBm+vEy28+mYMW+y/I2RURUgzDIED0kXxd7zB3UXP/4o7/O4uS1TPkaIiKqQRhkiIwgPMwbL3cKAgAUlwi8vuYYsgu5vgwRkdQYZIiM5M2nQ9HCzxUAkJCRjykbT3G8DBGRxBhkiIzE1lqJz4e0hMq+dFWDzSeT8EN0gsxdERFVbwwyREbkV8sRnz7333iZWX+cwZnE+9vBlYiIHhyDDJGRdW/ig5EdAgAARVodXl9zFHkarbxNERFVUwwyRBKY8kwYmtRRAwAu3sjD+7/GcLwMEZEEGGSIJGBnbYUvhrSCs13peJlfjl3H+iPXZO6KiKj6YZAhkkiAhxM+7N9U/3japtOIS8mRsSMiouqHQYZIQn2a18aQNn4AgILiEkSsOYqCohKZuyIiqj4YZIgkNq1XY4R6qwAAsSm5mPn7aZk7IiKqPhhkiCTmYGuFxcNawsHGCgDw46Gr2HT8usxdERFVDwwyRCbQwEuF2f2a6B+/u/EULt3Ik7EjIqLqgUGGyESea10X/VvVAQDkFZUg4oejKCzmeBkioofBIENkQrP7NkGQpxMA4ExSNj7886zMHRERWTYGGSITcrKzxuKhrWBnXfpPb/WBK/jrVJLMXRERWS4GGSITa+irxvTejfWPJ284iasZ+TJ2RERkuRhkiGQwpI0fejXzBQDkFGrx+tpjKNLqZO6KiMjyMMgQyUChUOCj/k3h7+4IADhxNROfbj0nc1dERJaHQYZIJip7G3wxpBVsrBQAgGV7LiHqbIrMXRERWRYGGSIZNa3rgnefaah//Ma6E0jMLJCxIyIiy8IgQySzkR0C8HQjbwBAZn4xxq89Bm0Jx8sQEd0PBhkimSkUCnz6XHPUcXUAABy+chPzt8fK3BURkWVgkCEyAy6ONvh8aEtYK0vHy3y5Kx7/xKbJ3BURkfljkCEyE63queGtbqEAACGAST8dR2p2ocxdERGZNwYZIjMy9vEgPBnqCQBIzyvChB+Po0QnZO6KiMh8McgQmRGlUoG5A5vDW20HADhwMR1f7Lggc1dEROaLQYbIzLg722HR4Ja4NVwGC6NicSA+Xd6miIjMFIMMkRlqG+SOSV1DAAA6AUz48RjSczUyd0VEZH4YZIjM1P86N0DHBu4AgNQcDSb9fAI6jpchIjLAIENkpqyUCsx/vgU8nG0BAP/EpuHrfy7K3BURkXlhkCEyY14qeyx4viUUt8bLfPb3eRy5kiFvU0REZoRBhsjMPRbsgYgnGwAASnQC49YcQ2Z+kcxdERGZBwYZIgswsWsw2gTUAgAkZhXizXUnIQTHyxARMcgQWQBrKyUWDmkBN0cbAMD2sylYeeCKzF0REcmPQYbIQvi6OGDuoOb6x3O2xuJiZomMHRERyc9a7gaI6P6Fh3nj5U5BWPrPRRSXCHx5vBBtH8mBg52tLP2UlGihKeEtLiKSD4MMkYV58+lQ/HspA8evZiKtQOCZz/fL2o8CQN1D/yDUR4VgbxVCvJ0R7KVCAy9n2NtYydobEVV/DDJEFsbWWonPh7TEM4v2IKdQK3c7EACu3izA1ZsF2H42VX9cqQDq1XLUh5sQbxVCvFUI8nSCnTUDDhEZB4MMkQXyq+WIlSNbY9EfR+Dm4QVl2UIzJlZcUoKYK6lIKVAgv8hwvI5OAJfT83E5PR/bzqToj1spFfB3d0SI162rN7cCTqCHE2ytOWyPiB6MrEHmn3/+waeffoojR44gKSkJv/zyC/r166d/XgiB6dOnY9myZcjMzETHjh3x1VdfITg4WL6micxE87quGN3UHh07NoW1tTz/lLVaLfbt24f27TsgJbcYcak5iE3JRWxKDuJSchGXmoPCYp3BnynRCVxMy8PFtDxsOf3fcWulAgEeTvpbUyG3ruQEeDjBxooBh4gqJ2uQycvLQ/PmzTF69Gj079+/wvNz5szBokWLsGrVKgQGBmLq1Kno1q0bzpw5A3t7exk6JqLKKJUK+NVyhF8tR4SHeeuP63QC124W4HxKzq1wUxp0LqTlokhrGHC0OoELqbm4kJoLIFl/3MZKgUAPJ/2tqbKrOP61HE31v0dEZkzWINOjRw/06NGj0ueEEFiwYAHef/999O3bFwCwevVqeHt749dff8XgwYNN2SoRVYFSqUA9d0fUc3fEU43+CzglOoGEjHyDcBObkoOLaXkoKjEMOMUl4tbzuQCS9MdtrZQI8nSEq6IQJ4rjEerrghBvFerVcoSVUp5bbURkemY7RubSpUtITk5G165d9cdcXFzQtm1bHDhw4I5BRqPRQKPR6B9nZ2cDKL0ErtUab2Bk2bmMeU5L64H1a3b9h+3Bz9UOfq526BLq8d/5SnS4kpGPuNTcW7em8hCXmotLN/KgvW3n76ISHc4l5wIADiZd0B+3s1YiyNMJwV7OCPFyRrC3M4K9nFHX1QFKIwccuf8O5K5vDj2wfvWtf7/nVAgzWedcoVAYjJHZv38/OnbsiMTERPj6+upfN2jQICgUCvz000+VnmfGjBmYOXNmheObN2+Gk5OTJL0TkbS0OoGUPIHruTpczy3B9VwdruXokJIvoLvP72C2VkBtJyXqqJSo4/zfh7uDQrbB0kR0Z3l5eejZsyeysrKgVqvv+DqzvSJTVVOmTEFkZKT+cXZ2Nvz8/NCuXbu7fiEelFarRXR0NNq2bSvrQEs5e2D9ml3fHHrILyzCb7sOwsE7CBfTC0qv5KTm4kp6foWAU1QCXM7W4XK24a0rJ1srNPAqvWpT+t/Sqzm+LvZQ3CPgyP3/L3d9c+iB9atv/bI7KvditkHGx8cHAJCSkmJwRSYlJQUtWrS445+zs7ODnZ1dhePW1taS/CVLdV5L6oH1a3Z9OXtwtAf8VFbo2LKuQf3C4hJcTMu7NYuqdAxOXEoOrmTk4/Zr0HlFJThxLQsnrmUZHFfZWaOBtzNCvFQILrcOjrfarkLAkfvvQO765tAD61e/+vd7PrMNMoGBgfDx8UFUVJQ+uGRnZyM6OhqvvfaavM0RkVmzt7FCo9pqNKpteBW2sLgEF1JzDcJNbGoOrmYUVDhHjkaLYwmZOJaQaXBcbW+NEO/SVYwbeDoiK0WLgrOpsLIy/SJ/JSUluJCmRb2MfPh7qIw+BojIEsgaZHJzc3Hhwn+D9C5duoTjx4+jVq1aqFevHiZOnIgPPvgAwcHB+unXtWvXNlhrhojoftnbWKFJHRc0qeNicDy/SHsr4NwKN7eCzvXMigEnu1CLw1du4vCVm/8dPHpM6tbv6rPDe+Cov0V2ayVln9IrSLXv4xYZkSWTNcgcPnwYnTt31j8uG9syYsQIrFy5EpMnT0ZeXh5efvllZGZm4rHHHsOWLVu4hgwRGZWjrTWa1XVFs7quBsdzNVr9FZzy08STsgrlafQu8otKcPJaFk7edovM2c4aDbyc9dtElG0Z4aNmwKHqQdYg8+STT+Juk6YUCgVmzZqFWbNmmbArIqJSznbWaOHnihZ+rgbHswuLEZeSi3NJWTh2Jg7+/v5QKk2/+rBOp8O5+MsotHXFhbQ8JFQyBihXo8Xxq5k4fjXT4LjK3rp0inq5cBPirYKXquIYICJzZrZjZIiIzJXa3gat/d3QvI4KdTVX0LFjkGwzRvZZJ6Fjx1awtrZGQVEJ4tPucwxQoRZHEzJx9LYxQC4ONgj2Kl09ObTcVRwPZ1sGHDJLDDJERNWEg+3dxwCdT85BXOp/e2FVNgYoq6C44hggAG6ONgZXbsrG4rjYcydzkheDDBFRNXe3MUBxt0JNbEoOYlNLr+JUNgboZn4x/r2UgX8vZRgcd3O0gUKnhe2+3ZDjgo0QQFGRRtb6tqIIza+fQKiPWj9N349bZZgMgwwRUQ3lbGeNlvXc0LKem8HxsjFAZQOcy9bjScnWVDjHzfzi0k8KZR4ALXP9hJPJ+P3kf5ud2lkrbw2yvrUO0a0d3eu6GX+rjJqOQYaIiAyUjQFq7W8YcLLyixGbmqO/NRWbkoPLN/JQUKiBrZ0tFDD9D2gBgSJNkXz1hUBarqbCStIarQ6nE7NxOtFwdVoHm1vT5L2dEXrr6k2wtzPquDpwDFIVMcgQEdF9cXG0waMBtfBoQC39Ma1Wi3379qFjx47yDXiWuf7uPXvhG9Ic8TcKDKbpX07PqxBwCopLcOp6Fk5dN5wm72RrhQbeKoSUv4rjrbqvrTJqOgYZIiKih2CtVCDEW4VGdQyvYD3wVhlXM3Hi9mnyt7bKCOU0+TtikCEiIpKAKbbKaODpBG12EWJKLkKpNP0MMp2uBFcuFyHDOQnPtvYzeX2AQYaIiMikJNkqIzbOFK3f0ZXiqwwyRERENdk9t8pIzrnnNPmaiEGGiIjIjN1tq4xziVnYe/gEGoaFQSnDDuy6khKcPXcOHVoFm7x2GQYZIiIiC6S2t0Greq4ouGqNjo28ZZu15XjzAh4JcLv3iyVi+l3OiIiIiIyEQYaIiIgsFoMMERERWSwGGSIiIrJYDDJERERksRhkiIiIyGIxyBAREZHFYpAhIiIii8UgQ0RERBaLQYaIiIgsFoMMERERWSwGGSIiIrJYDDJERERksar97tdCCABAdna2Uc+r1WqRl5eH7OxsWXYcNYceWL9m1zeHHlif7wHWr771y35ul/0cv5NqH2RycnIAAH5+fjJ3QkRERA8qJycHLi4ud3xeIe4VdSycTqdDYmIiVCoVFAqF0c6bnZ0NPz8/XL16FWq12mjntaQeWL9m1zeHHlif7wHWr771hRDIyclB7dq1oVTeeSRMtb8io1QqUbduXcnOr1arZfsGYi49sH7Nrm8OPbA+3wOsXz3r3+1KTBkO9iUiIiKLxSBDREREFotBpors7Owwffp02NnZ1dgeWL9m1zeHHlif7wHWr9n1gRow2JeIiIiqL16RISIiIovFIENEREQWi0GGiIiILBaDDBEREVksBhkiIiKyWAwyRHRPU6dOhVarvePzCQkJeOqpp0zYEaWlpWHv3r3Yu3cv0tLS5G6HSDYMMlVw5swZbNmyBb/99pvBhylcvXoV165d0z/+999/MXHiRCxdutQk9Ul+8fHxeP/99zFkyBCkpqYCAP766y+cPn1aspqrVq3Co48+ipiYmArPff3112jSpIlsuy+b2pYtW7B3717948WLF6NFixYYOnQobt68KXn9vLw8jB49GrVr10anTp3QqVMn1K5dG2PGjEF+fr7k9QkICgpCenp6heOZmZkICgqSvL7cPwfy8vIwdepUdOjQAQ0aNEBQUJDBh8kJum/x8fGiWbNmQqFQCKVSKRQKhf5zpVJpkh4ee+wxsXr1aiGEEElJSUKtVov27dsLDw8PMXPmTMnrd+rUSaxatUrk5+dLXutu8vLyxNmzZ8WJEycMPqq7Xbt2CQcHB9G1a1dha2sr4uPjhRBCfPTRR2LAgAGS1c3KyhIvvviisLOzEx9++KEoKSkRV65cEV26dBFqtVp8/fXXktWuTElJiTh//rzYs2eP2L17t8GH1Jo0aSI2b94shBDi5MmTws7OTkyZMkW0a9dOjBw5UvL6L7/8sggKChJ//vmnyMrKEllZWWLz5s2ifv364tVXX5W8vhBCJCQkiKtXr+ofR0dHiwkTJpjsfXDkyBFx8uRJ/eNff/1V9O3bV0yZMkVoNBrJ6ysUCpGSklLheHJysrC1tZW8vtw/BwYPHix8fX3F5MmTxfz588WCBQsMPkyNQeYB9OrVS/Tt21ekpaUJZ2dncebMGbFnzx7Rpk0b8c8//5ikB1dXV3Hu3DkhhBALFy4UHTp0EEIIsXXrVhEYGCh5/QkTJghPT0+hVqvFSy+9JA4cOCB5zfJSU1NFz5499eHx9g8puLq6Cjc3t/v6kFq7du3E3LlzhRBCODs764NMdHS0qFOnjuT1f/31V+Ht7S2aN28u1Gq16Nq1q7h8+bLkdcs7cOCACAwMNPhlovwvFVJzcnISly5dEkIIMX36dH2APHLkiPD29pa8vru7u9i5c2eF4zt27BAeHh6S1xdC/h+kjzzyiFi/fr0QovQXTHt7ezFkyBDRoEEDMWHCBMnqbtq0SWzatEkoFAqxevVq/eNNmzaJjRs3ioiICBESEiJZ/TJy/xxwcXERe/fulbzO/WKQeQDu7u763/rVarX+jRQVFSVatGhhkh7KfxPt3bu3+Pjjj4UQQly5ckXY29ubpIfi4mKxYcMG0adPH2FjYyMaNmwoPv30U5GcnCx57aFDh4qOHTuKQ4cOCScnJ/H333+L7777ToSGhoo//vhDkporV67Uf8ydO1e4ubmJwYMHi4ULF4qFCxeKwYMHCzc3NzFv3jxJ6pfn5OQkLl68KIQwDDKXLl0SdnZ2ktdPTk4WXbt2FQqFQjg7O4tdu3ZJXvN2zZs3FwMHDhRnzpwRN2/eFJmZmQYfUnNzcxOnT58WQgjRsWNH/VWIS5cuCQcHB8nrOzg4iDNnzlQ4HhMTIxwdHSWvL4T8P0jVarW4cOGCEEKIjz/+WDz99NNCCCH27t0r6tatK1nd24Nz+Q9bW1sREhIifv/9d8nql5H750BAQECl70G5MMg8AFdXV/0PkaCgILFjxw4hhBAXLlwwyTcwIYRo06aNePvtt8U///wj7O3txfHjx4UQpb+lmuI38tulpKSI2bNnC3t7e2FjYyP69u0roqKiJKvn4+MjoqOjhRBCqFQqcf78eSFE6W9KHTt2lKxumf79+4vPP/+8wvHPP/9c9O3bV/L6derUEfv27RNCGAaZjRs3iqCgIElrr1mzRtSqVUuEh4eLc+fOibfeekvY2tqKiRMnioKCAklrl+fo6Cji4uJMVu92vXv3Ft26dROzZs0SNjY24tq1a0KI0h/iwcHBktcPDw8XAwcONPia5+fni4EDB4ouXbpIXl8I+X+QqlQqERsbK4QQomvXrvrbGab8QX7jxg3J69yJ3D8HvvvuO/Hcc8+JvLw8yWvdDwaZB/DYY4+JX375RQghxJAhQ0T37t3F3r17xfDhw0Xjxo1N0sPOnTuFq6urUCqVYtSoUfrjU6ZMEc8++6xJeigTHR0tXn31VeHq6irq1asnpk2bJsaMGSMcHBzEG2+8IUlNlUql/wZar149/eXNixcvmiRMOjk5VfpDNC4uTjg5OUle/4033hCPPfaYSEpKEiqVSsTFxYm9e/eKoKAgMWPGDMnq9u/fXzg5OYlFixYZHN+3b58ICQkRISEhYv/+/ZLVL69z587ir7/+Mkmtyly5ckX07NlTNGvWTHzzzTf64xMnThTjxo2TvP6pU6dE7dq1hbu7uwgPDxfh4eHC3d1d1KlTR8TExEheXwj5f5B27txZDB8+XKxevVrY2Njo/03u2rVL+Pv7S1q7qKhIhIeH64OUHOT+OdCiRQuhUqmEs7OzaNKkiWjZsqXBh6kxyDyALVu2iA0bNgghSn9whYaGCoVCITw8PMT27dtN1odWqxUZGRkGxy5dulTp4DNjS0lJEZ999plo3LixsLW1FQMGDBB//fWX0Ol0+tfs2bNHsh/qjzzyiNiyZYsQovQ3wRdffFFcu3ZNTJ48WfIrEkKUhqfPPvuswvHPPvtM1KtXT/L6Go1GvPTSS8La2looFAphY2MjlEqleOGFF4RWq5WsbocOHe74jTs/P1+MHz9e2NjYSFa/vI0bN4pGjRqJFStWiMOHD9e4Ad9ClA52X7p0qYiMjBSRkZFi2bJlJh2AL/cP0uPHj4smTZoItVptEOBff/11MWTIEMnre3h4yBpkhJD358CMGTPu+mFq3P36IWVkZMDNzQ0KhULuVkzC1tYW9evXx+jRozFy5Eh4enpWeE12djb69u2LnTt3Gr3+999/D61Wi5EjR+LIkSPo3r07MjIyYGtri5UrV+L55583es3yVq5ciZdeegk9evRA27ZtAQDR0dHYsmULli1bhpEjR0pav0xCQgJiYmKQm5uLli1bIjg4WNJ6Op0OSuXdV2v4559/0KlTJ0n7AFBpHwqFAkIIKBQKlJSUSN5DfHw8VqxYgfj4eCxcuBBeXl7466+/UK9ePTRu3Fjy+uagpKQE2dnZcHNz0x+7fPkyHB0d4eXlJUtPhYWFsLa2lnwpgEmTJsHOzg4ff/yxpHXuRqvVYteuXYiPj8fQoUOhUqmQmJgItVoNZ2dn2fqSA4PMAxg9ejQWLlwIlUplcDwvLw/jxo3Dt99+K0ndVq1aISoqCm5ubmjZsuVdQ9PRo0cl6aHMnj178Pjjj0ta40Hk5+fj3LlzqFevHjw8PExSMzo6GosWLcLZs2cBAA0bNsT48eP1wYakdeXKlbs+7+/vL2n93bt3o0ePHujYsSP++ecfnD17FkFBQfj4449x+PBhrF+/XtL6q1atgoeHB3r27AkAmDx5MpYuXYpGjRph7dq1kv//A0BBQQGEEHB0dARQ+nfyyy+/oGHDhujWrZvk9YOCgnDo0CG4u7sbHM/MzESrVq1w8eJFSeuPGzcOq1evRnBwMFq3bg0nJyeD5+fNmydp/StXrqB79+5ISEiARqNBbGwsgoKCMGHCBGg0GixZskTS+mWOHDmi/z7YuHFjtGzZ0iR1b8cg8wCsrKyQlJRU4beNGzduwMfH564rnz6MmTNn4q233oKjoyNmzpx519dOnz5dkh7MxaxZs/Dmm2/qv4GWKSgowKeffopp06bJ1Jl0IiMj7/u1Un8DJaB9+/YYOHAgIiMjoVKpcOLECQQFBeHff/9F//79DRYqk0JoaCi++uorhIeH48CBA+jSpQsWLFiAP/74A9bW1ti4caOk9QHg6aefRv/+/fHqq68iMzMTYWFhsLGxwY0bNzBv3jy89tprktZXKpVITk6u8L04JSUFfn5+KCoqkrR+586d7/icQqHAjh07JK3fr18/qFQqLF++HO7u7vr34K5duzB27FjExcVJWj81NRWDBw/Grl274OrqCqA0RHbu3Bk//vhjpVfqpcQgcx+ys7MhhICbmxvi4uIM/pJKSkrw+++/45133kFiYqKMXZrO+vXr8fPPPyMhIaHCNwyprwjdKUymp6fDy8vLpLcVLl68iAULFkh+W+Fu3zTLM8U3UHMRHx+PBQsW6H8bbNSoESZMmID69etLXtvZ2RmnTp1CYGCgQZC5fPkywsLCUFhYKGl9R0dH/VXIt99+G0lJSVi9ejVOnz6NJ5980iTbFXh4eGD37t1o3LgxvvnmG3z++ec4duwYNmzYgGnTpun/XoytbAX1fv36YdWqVXBxcdE/V1JSgqioKGzbtg3nz5+XpL65cHd3x/79+xEaGlrhPdioUSPJV3h+/vnncfHiRaxevRoNGzYEULri/YgRI9CgQQOsXbtW0voVmHxUjgUqv3pvZR9WVlbigw8+MEkvcq+ouXDhQuHs7Cxef/11YWtrK1555RXRtWtX4eLiIt59913J6ysUCpGamlrheFRUlEkWA5NrZV36z5YtW4Stra1o06aNmDRpkpg0aZJo06aNsLOzE3///bfk9eWcAi+EEJ6enuLo0aNCiNLZI2UL0124cMEkM+eEKF3L5sqVK0IIIQYOHKgf4JmQkCDp7MHyCx/KuY6L3FxdXfVrGZV/D+7Zs0d4eXlJXl+tVot///23wvHo6Gjh4uIief3bMcjch127domdO3cKhUIhNm7cKHbt2qX/2L9/v7h+/brJerl9RU2VSmXSFTVDQ0PFmjVrhBCG/4CmTp0qIiIiJKtbtrquUqmssNKuWq0WSqVS/O9//5Osfhm5V9YtLyEhQSQkJJi0pjlo0aKFePvttyscf/vtt00y9VOuKfBlhg4dKlq1aiXGjBkjHB0d9euZbNq0yWTLQDRt2lQsXLhQJCQkCLVarZ96f/jwYZOsbhwQECDS0tIkr3M3hw4dEm+99ZZ4/vnnxbPPPmvwIbVBgwaJsWPHCiFKvw9dvHhR5OTkiPDwcJNsk+Hs7CyOHTtW4fjRo0eFSqWSvP7tGGQewOXLl0VJSYmsPci9oqaDg4N+SXpPT0/9+hGxsbGiVq1aktVduXKlWLFihVAoFGLhwoUGq+2uWbPGZGuYyL2ybnFxsXj//ff14U2pVAq1Wi3ee+89UVRUJHl9c2BnZ1fp1Nfz58+b5O9ArinwZW7evCkiIiJEnz59DNbTmTZtmsmuDK9bt07//921a1f98Q8//FB0797dJD3Iae3atcLGxkb06tVL2Nrail69eomQkBDh4uJikiBx9epV0ahRI9GwYUNhbW0t2rVrJ9zd3UVoaKhJpl/36dNHdOrUyeCX+GvXroknnnhC9OvXT/L6t6sZ29UaSdlsgPz8/ErHhzRr1kzyHoqLi2FnZwcA2L59O/r06QMACAsLQ1JSkuT1fXx8kJGRAX9/f9SrVw8HDx5E8+bNcenSJQgJh1uNGDECABAYGIgOHTrAxsZGslp34+rqiqSkJAQGBhocP3bsGOrUqSN5/XHjxmHjxo2YM2cO2rdvDwA4cOAAZsyYgfT0dHz11VeS9yA3T09PHD9+vMKU8+PHj5tk2q+trS2WLVuGqVOnmnQKfBlXV1d88cUXFY7fayKAMT333HN47LHHkJSUhObNm+uPd+nSBc8++6wkNRctWnTfrx0/frwkPZT58MMPMX/+fEREREClUmHhwoUIDAzEK6+8Al9fX0lrA0DdunVx4sQJ/Pjjjzh58iRyc3MxZswYDBs2DA4ODpLX/+KLL9CnTx8EBATAz88PQOmO3E2aNMH3338vef3bcbDvA0hLS8OoUaPw119/Vfq8KQaatm3bFp07d0bPnj3x9NNP64PEwYMH8dxzz0k+Y+Kll16Cn58fpk+fjsWLF+Ott95Cx44dcfjwYfTv3x/Lly+XtH55hYWFFcKkWq2WtOabb76J6OhorFu3DiEhITh69ChSUlIwfPhwDB8+XPJZYy4uLvjxxx/Ro0cPg+N//vknhgwZgqysLEnrm4NZs2Zh/vz5eOedd9ChQwcAwL59+/DJJ58gMjISU6dOlblD4zt58uR9v9YUv1CVuXDhAuLj49GpUyc4ODjo1/KRwu2/PNyJQqGQfPq1k5MTTp8+jYCAALi7u2PXrl1o2rQpzp49i/DwcJP8Uik3IQS2b9+Oc+fOAShdhqJr166y9MIrMg9g4sSJyMzMRHR0NJ588kn88ssvSElJwQcffIC5c+eapIdPPvkEzz77LD799FOMGDFC/9vQb7/9hjZt2khef+nSpdDpdACAiIgIeHh4YN++fejTpw9effVVyevn5+dj8uTJ+Pnnn5Genl7heanD5IcffoiIiAj4+fmhpKQEjRo1QklJCYYOHYr3339f0toAYGdnh4CAgArHAwMDYWtrK3l9czB16lSoVCrMnTsXU6ZMAQDUrl0bM2bMkOw3cbmnwLdo0UK/6N/dmGpBwPT0dAwaNAg7d+6EQqFAXFwcgoKCMGbMGLi5uUny/fDSpUtGP2dVubm5IScnBwBQp04dxMTEoGnTpsjMzJR8xhAArF69+q7PDx8+XPIeFAoFnnrqKTz11FOS17pnL7wic/98fX2xadMmtGnTBmq1GocPH0ZISAh+++03zJkzB3v37jVJH3KvqFlYWIiTJ08iNTVVH2qA0jd27969Ja0dERGBnTt3Yvbs2XjxxRexePFiXL9+HV9//TU+/vhjDBs2TNL6Za5evYpTp06Z/LbCrFmzcO7cOaxYsUJ/i1Gj0WDMmDEIDg6u9usI3a7sh8nti1Qam9xT4O+1CGB5plgQb/jw4UhNTcU333yDhg0b6qf/bt26FZGRkTh9+rTkPchp6NCheOSRRxAZGYnZs2fj888/R9++fbFt2za0atVK8rV8yn/vB0qHHOTn58PW1haOjo7IyMgwes1Fixbh5Zdfhr29/T1v80l9a+92DDIPQK1W4+TJkwgICIC/vz/WrFmDjh074tKlS2jcuLFJkvj06dMxevRok3yzqsyWLVvw4osvVno1xBS/DdarVw+rV6/Gk08+CbVajaNHj6JBgwb47rvvsHbtWvz555+S1r9dSUkJTp06BX9//wrfXIylf//+Bo+3b98OOzs7/dW4EydOoKioCF26dDHJYmhkHs6cOVNhrJ4pfpkASsfKbd26Fc2bNzdYx+TixYto1qwZcnNzJa0/evTouz4v1SrrZTIyMlBYWIjatWtDp9Nhzpw52L9/P4KDg/H+++9L9r3gbuLi4vDaa6/hrbfekmR15cDAQBw+fBju7u53vc1nilt7t+OtpQcQGhqK8+fPIyAgAM2bN8fXX3+NgIAALFmyxCQDvABg06ZN+L//+z888cQTGDNmDAYMGKD/zdwUxo0bh0GDBmHatGnw9vY2Wd0yGRkZCAoKAlAaLMt+83jsscckX00UKL292LRpU4wZMwYlJSV44oknsH//fjg6OuKPP/7Ak08+afSa5Rf9AoABAwYYPC4bbFedmdM2HeVdvXoVgGn/Di5evIhnn30Wp06dMrjdVPY1McWtpby8vAqrawOl/z5N8f3o5s2bBo+Li4sRExODzMxMhIeHS16/Vq1a+s+VSiXeeecdyWveS3BwMD7++GO88MIL+nErxlT+1p453eYDGGQeyIQJE/SDuKZPn47u3bvj+++/h62tLVatWmWSHo4fP45jx45hxYoVmDBhAiIiIjB48GCMHj0ajz76qOT1U1JSEBkZKUuIAUr3WLl06RLq1auHsLAw/Pzzz2jTpg1+//13/VLZUlq/fj1eeOEFAMDvv/+Oixcv4ty5c/juu+/w3nvvYd++fUavuWLFCqOf09L07dtX/wOyb9++sm7SqtVqMXPmTCxatEh/5cHZ2Rnjxo3D9OnTJZ9RN2HCBAQGBiIqKgqBgYGIjo5GRkYG3njjDXz22WeS1i7z+OOPY/Xq1Zg9ezaA0hBVdmXifm/DPYxffvmlwjGdTofXXnvNJKs7l9W7cOFChVvsAEyyeWplrK2tTbLCvNltFWPyCd/VSF5enjhy5IhsCzMVFRWJDRs2iF69egkbGxvRtGlTsWDBApGZmSlZzVGjRolvvvlGsvPfy7x588TChQuFEEJs27ZN2NvbCzs7O6FUKsWCBQskr29nZ6dfWXns2LFiwoQJQgghLl68KMtCUGR6r776qvDy8hJLliwRJ06cECdOnBBLliwRPj4+4tVXX5W8vru7uzhx4oQQonSF1bJ1paKiokSLFi0kry+EEKdOnRJeXl6ie/fuwtbWVjz33HOiYcOGwtvbW1y4cMEkPVTm3LlzwsfHR/I6Bw4cEIGBgZWuMKxUKiWvv2nTJoOPX3/9VXz11VeicePGJlnHR6lUVrpezY0bN0zy/387XpG5B7lnK9yNEALFxcUoKirS7wX1xRdfYOrUqVi2bBmef/55o9f84osvMHDgQOzZswdNmzat8Nun1IO8Jk2apP+8a9euOHfuHI4cOYIGDRqYZNqpt7c3zpw5A19fX2zZskW/bkt+fj6srKwkrw/Iu9eVOZB75+M1a9ZUmALfrFkz+Pn5YciQIZKv5VNSUqIf3Ozh4YHExESEhobC39/fZHsMNWnSBLGxsfjiiy+gUqmQm5uL/v37IyIiwmS32SsTHx8v2ea95b366qt45JFHsHnzZvj6+pr8CmG/fv0MHisUCnh6eiI8PNwkM2jFHabZnzhxwuC2m6kwyNzDsWPHDB4fPXoUWq0WoaGhAIDY2FhYWVmhdevWJuvpyJEjWLFiBdauXQs7OzsMHz4cixcvRoMGDQAAn3/+OcaPHy9JkFm7di3+/vtv2NvbY9euXQZvZoVCIWmQ0el0WLlyJTZu3IjLly9DoVAgMDAQzz33HJo2bSpZ3fJGjRqFQYMG6b95la2bEB0djbCwMMnrL1q0CO+99x5GjhyJTZs2YdSoUYiPj8ehQ4cQEREheX1zcPny5UrHgWg0GsnXUQLknwLfpEkTnDhxAoGBgWjbti3mzJkDW1tbLF26VD9+zBRcXFzw3nvvmaxeebf/gimEQFJSEjZv3qxfPFNKcXFxWL9+vf57rqndfivLVNzc3KBQKKBQKBASEmLw/b+kpAS5ubkmWYbjdpy19ADmzZuHXbt2YdWqVfpR6Tdv3sSoUaPw+OOP44033pC8h6ZNm+LcuXN4+umnMXbsWPTu3bvClYAbN27Ay8tLkje7j48Pxo8fj3feeQdKpdLo578TIQR69+6NP//8E82bN0dYWBiEEDh79ixOnTqFPn364NdffzVJLxs2bEBCQgIGDhyIunXrAoD+PVG20rJUwsLCMH36dAwZMsRgtsi0adOQkZFR6Yqv1YW57Hws9xT4rVu3Ii8vD/3798eFCxfQq1cvxMbGwt3dHT/99JNJBruuWLECzs7OGDhwoMHxdevWIT8/X/Iwcfs4HKVSqb8iMXr0aFhbS/s7enh4OCZPnozu3btLWsfcrFq1CkIIjB49GgsWLDD4N2hra4uAgAD9iuOmxCDzAOrUqYO///4bjRs3NjgeExODp59+2iSDrGbPno3Ro0ebZDn8ytSqVQuHDh0y2YC6MmWDmzdt2lThm9iOHTvQr18/fPHFF5IvBDVr1qy7Pi/1IDdHR0ecPXsW/v7+8PLywrZt29C8eXPExcWhXbt2lU6Lry7KgnNlC8PZ2NggICAAc+fORa9evYxe29ynwGdkZOh/WzaFkJAQfP311xX+Le7evRsvv/yyyW5xmVL51ZXj4+Px/vvv46233qr0FrvUt7nlHvKwe/duWbeKuR1vLT2A7OxspKWlVTielpamX5hLanIvvz5ixAj89NNPePfdd01ad+3atXj33XcrnRERHh6Od955Bz/88IPkQeb22RLFxcW4dOkSrK2tUb9+fcmDjFx7XZmDsiuMgYGBOHToEDw8PExW29ynwJt6XEJCQkKla4n4+/sjISFB8voFBQUQQuhnzVy5cgW//PILGjVqhKefflqSmpWtrlx+PZuy50yxntaxY8dw7NgxFBcXVxjm0KpVK4OepPDEE0/oP5djq5jbMcg8gGeffRajRo3C3Llz9dsBREdH46233qrwG5sxyZ2+yyspKcGcOXOwdetWNGvWrEIil6r+yZMnMWfOnDs+36NHjwfaVK6qbh8zBZQG3JEjR0q2WV554eHh+O2339CyZUuMGjUKkyZNwvr16/V7XdUEcqxhwSnwhry8vPSLg5Z34sSJCoOwpdC3b1/0798fr776KjIzM9GmTRvY2trixo0bmDdvniRrSpnT2im9e/eGSqWSbZiD3FvF3I63lh5Afn4+3nzzTXz77bcoLi4GUDpvf8yYMfj000/h5OQkSV25l0e/316krG9ra4srV67ccUZEYmIiAgMDodFoJKl/L6dOnULv3r1x+fJlSevodDrodDr9GIAff/xRv6LoK6+8UmP2W8rLy8Pu3bsrnbll6uXRa6K3334bP/30E1asWKFfM2X37t0YPXo0nnvuOcnXs/Hw8MDu3bvRuHFjfPPNN/j8889x7NgxbNiwAdOmTcPZs2clrf/RRx/B29u7wgrD3377LdLS0vD2229LWl/uYQ7mslWMnqnne1cHubm5+vUjcnNz5W6nRlAqlSI1NfWOzycnJ8uyfkGZPXv2CFdXV9nq1yRHjx4VPj4+Qq1WCysrK+Hp6SkUCoVwcnISgYGBJulh3bp1YuDAgaJt27aiZcuWBh81gUajEYMGDRIKhULY2NgIGxsbYWVlJUaNGiU0Go3k9R0cHMSVK1eEEEIMHDhQzJgxQwghREJCgnBwcJC8vr+/v9i3b1+F4wcPHhQBAQGS13d2dhY7d+6scHzHjh3C2dlZ8vp+fn76+iqVSsTFxQkhhFi9erXo0aOH5PVvx1tLVeDk5GSSNUvoP0IIjBw58o7Ln5vqSsztt6/ErWmf3333ncG6IsZ08uRJNGnSBEql0mDAYWVqwvty0qRJ6N27N5YsWQIXFxccPHgQNjY2eOGFFzBhwgTJ63MKfOkV0p9++gmzZ8/GiRMn4ODggKZNm5psD7gGDRrg119/xbPPPoutW7fq15dKTU01yfiM5OTkSq8Oe3p66ld/l5JcwxzKyL1VzO0YZCzQ4cOH77ggWnXdNPB+pnOaYuv6+fPnGzwum/Y5YsQITJkyRZKaLVq0QHJyMry8vCodcFjGFIMMzcHx48fx9ddfQ6lUwsrKChqNBkFBQZgzZw5GjBgh+TfyL7/8EkuXLsWQIUOwcuVKTJ482WAKfE0SEhKi3/ndlIvCTZs2DUOHDsWkSZMQHh6un/L7999/o2XLlpLX9/Pzw759+yoMeN63bx9q164tef0lS5bgzTffxNChQysd5iA1ubeKqcDk14Dooaxdu1bY2NiIXr16CVtbW9GrVy8REhIiXFxcxMiRI+VujyRw+fJlodPp9J/f7aMm8PDwELGxsUIIIYKDg8WWLVuEEEKcPXtWODo6Sl7fwcFB/7X29PQUx48fF0IIERsbK2rVqiV5fXOxatUq0aRJE2FnZyfs7OxE06ZNxerVq01WPykpSRw9elSUlJToj0VHR4uzZ89KXvuTTz4R7u7u4ttvv9X/21u+fLlwd3cXH374oeT1y8g1zEHurWJuxyBjYZo2bSq++OILIUTpfdL4+Hih0+nE2LFjxbRp02TujqRUVFQkRo0aJS5evCh3K7J66qmnxA8//CCEEOKll14Sbdq0Ed9//73o1q2baNOmjeT1AwMDxdGjR4UQQrRu3VosWbJECCHE1q1bhZubm+T1zcHcuXOFo6OjmDx5sn6/n7feeks4OjqKefPmmayPuLg4sWXLFpGfny+EEPrALzWdTicmT54s7O3thVKpFEqlUjg6OoqZM2eapL65uXz5stiwYYN+DzBT46wlC+Pk5ITTp08jICAA7u7u2LVrF5o2bYqzZ88iPDzcJPdnST4uLi44fvx4pWt41BSHDx9GTk4OOnfujNTUVAwfPlw/c+vbb7/VL1InlZdeegl+fn6YPn06Fi9ejLfeegsdO3bUT4Ffvny5pPXNQWBgIGbOnFnhdu6qVaswY8YMyacqp6enY9CgQdi5cycUCgXi4uIQFBSE0aNHw83NzST7DQFAbm4uzp49CwcHBwQHB99xDJ8x9O/fHytXroRarb7n7VOphxgkJCTA29u7wv+vTqfDtWvXUK9ePUnr345jZCyMm5ubfvG9OnXqICYmBk2bNkVmZiby8/Nl7o6k1q9fP/z6668Gm2fWNI888oj+cy8vL2zZssWk9ZcuXapfnC8iIgLu7u7Yv38/+vTpg1deecWkvcglKSkJHTp0qHC8Q4cOJvllatKkSbCxsUFCQgIaNmyoP/78888jMjLSZEHG2dkZjz76qElqubi46Mch3b5Ao6kFBASgYcOG+O233wxWeU9LS0NgYKDJx+oxyFiYTp06Ydu2bWjatCkGDhyICRMmYMeOHdi2bRu6dOkid3skseDgYMyaNQv79u1D69atK6xdxDVUpKdUKg32GRs8eDAGDx4sY0em16BBA/z8888VVvj+6aef9IN/pfT3339j69at+r3OygQHB+PKlSuS15dD+UUZzWGBxoYNG6JNmzb4+eefDX72yHGTh7eWLExGRgYKCwtRu3Zt6HQ6zJkzR39Z/f3339ev8kjV091uKSkUCly8eNGE3cgjPT0d06ZNw86dO5Gamlphc1QpZg5xCryhDRs24Pnnn0fXrl3RsWNHAKUzdqKiovDzzz9Lvsq1SqXC0aNHERwcbLB56uHDh9GtW7dqveeYObCyskJSUhJ++OEHTJkyBXPmzMH48eORkpKC2rVrc2VfIqK7eeaZZ3DhwgWMGTMG3t7eFab9SrHzslKp1E+BVyqVNX4KPAAcPXoU8+bN06+i27BhQ7zxxhsmmf78zDPPoHXr1pg9ezZUKhVOnjwJf39/DB48GDqdDuvXr5e8BzmlpKTgzTffRFRUFFJTUyu8F6V+D5b/9/DXX39hyJAhGDhwIKZNm4aAgAAGGbo3nU6HCxcuVPrbaNly4UTVlUqlwt69eyUf1FvelStXUK9ePSgUinveujDVonByKS4uxiuvvIKpU6fKNuj89OnTCA8PR6tWrbBjxw706dMHp0+fRkZGBvbt22cwbqM66tGjBxISEvD666/D19e3Qpjv27evpPXLBxkAOHPmDPr06QMnJyfExMRwjAzd3cGDBzF06FBcuXKlQgqvSb8N1mTXrl3Db7/9VumCiFJvGmoOwsLCUFBQYNKaZeGkuLgYM2fOlPWHuNxsbGywYcMGTJ06VZb6xcXFGD9+PH7//Xds27YNKpUKubm56N+/PyIiIu64H1t1snfvXuzZswctWrSQpf4TTzxhsK9bo0aNEB0djf79+3OMDN1bixYtEBISgpkzZ1aaxOUezU7SioqKQp8+fRAUFIRz586hSZMmuHz5MoQQ+t9Oq7tDhw7hnXfewbRp09CkSZMKO7BLvUQ9p8CX3r5r0aKFbLPnPD099WMDa6JGjRrhhx9+MMltPEvAIGNhnJyccOLECTRo0EDuVkgGbdq0QY8ePTBz5kz9IEcvLy8MGzYM3bt3l2WfE1OLi4vD0KFDcfToUYPjQgiTXJWU+4e4Ofjggw8wd+5cdOnSRZbZc5MmTYKdnR0+/vhjSeuYq7///htz587F119/jYCAAJPUzM7O1v+SkJ2dfdfXmmK/q/IYZCxMeHg4Jk+ejO7du8vdCslApVLh+PHjqF+/Ptzc3LB37140btwYJ06cQN++fXH58mW5W5RcmzZtYG1tjQkTJlQ62PeJJ56QtL7cP8TNgdyz58aNG4fVq1cjODi40r+D6n6L1c3NDfn5+dBqtXB0dKxwVVKKmXtlM5XKD3i/nal+mbgdx8hYmHHjxuGNN95AcnIymjZtWuENXBOmftZkTk5O+nExvr6+iI+PR+PGjQEAN27ckLM1k4mJicGxY8cQGhoqS/3ly5fD1dUVR44cwZEjRwyeUygUNSLIlF+5t+x3YVNuGhkTE4NWrVoBAGJjYw2eM2UfclmwYIHJa+7YsQO1atUCAOzcudPk9e+GV2QsTPmFuG7Hwb7VX79+/dCzZ0+MHTsWb775JjZt2oSRI0di48aNcHNzw/bt2+VuUXKdOnXCtGnT0LVrV7lbqdGWL1+O+fPnIy4uDkDpYnQTJ07ESy+9JHNnVNPwioyFkXoPEzJv8+bNQ25uLgBg5syZyM3N1a+mWt0vp5cZN24cJkyYgLfeeotXJWUybdo0zJs3D+PGjUP79u0BAAcOHMCkSZOQkJCAWbNmydxh9WfqZTjutRBkeab+N8grMhbqzJkzFabfKhQK9O7dW8auSGovvfQSXnjhBTz55JNytyKbyq5Kli1QZ6qrkjV9CrynpycWLVqEIUOGGBxfu3Ytxo0bV2Nuc8pFjmU47rYQpCnq3w2vyFiYixcv4tlnn8WpU6cM3lRl94V5a6l6S0tLQ/fu3eHp6YnBgwfjhRdeMOnCcOZA7quS95oCXxMUFxcbbN5ZpnXr1tBqtTJ0VLO8+uqreOSRR7B58+ZKl+GQgtz/7u6GV2QsTO/evWFlZYVvvvkGgYGBiI6ORkZGBt544w189tlnePzxx+VukSR28+ZNrFu3DmvWrMGePXsQFhaGYcOGYejQoSabiimX4uJihIWF4Y8//jDY9diUOAW+9PaejY1NhatPb775JgoKCrB48WKZOqsZuAyHIQYZC+Ph4YEdO3agWbNmcHFxwb///ovQ0FDs2LEDb7zxBo4dOyZ3i2RC165dw9q1a/Htt98iLi6uRvw2XKdOHWzfvl22IMMp8P9Nf/bz80O7du0AANHR0UhISMDw4cMNxi3VhFttpmYuy3BUNsQBAPr06WPSPnhrycKUlJRApVIBKA01iYmJCA0Nhb+/P86fPy9zd2RKxcXFOHz4MKKjo3H58mV4e3vL3ZJJRERE4JNPPsE333wDa2vTfwvjFHjD6c/x8fEASr8feXh4ICYmRv+6mjAV2lTKD7aVexkOcxviwCBjYZo0aYITJ04gMDAQbdu2xZw5c2Bra4ulS5ciKChI7vbIBHbu3Ik1a9Zgw4YN0Ol06N+/P/744w+Eh4fL3ZpJHDp0CFFRUfj777/RtGnTCouhbdy4UdL67dq1w969e9GwYUM888wzeOONN3Dq1Cls3LhRf3WiujO3dURqghYtWlQYbDt69Gj956Yc8D5hwgQEBgYiKioKgYGB+Pfff5Genq4f4mBqDDIW5v3330deXh4AYNasWejVqxcef/xxuLu746effpK5O5JanTp1kJGRge7du2Pp0qXo3bs37Ozs5G7LpFxdXTFgwADZ6nMKPMnBnAbbHjhwADt27ICHhweUSiWUSiUee+wxfPTRRxg/frzJhzhwjEw1kJGRATc3N17GrQGWLVuGgQMHwtXVVe5WaixOgaeazs3NDUePHkVgYCDq16+Pb775Bp07d0Z8fDyaNm2K/Px8k/bDKzLVQNmy0VT9jR07Vu4WzEZaWpp+XFhoaCg8PT1NVremT4EneX300Ufw9vY2uLUEAN9++y3S0tLw9ttvS1rf3IY43Hm9eyIiM5SXl4fRo0fD19cXnTp1QqdOnVC7dm2MGTPGJL8Jbtq0CUlJSZg6dSoOHTqEVq1aoXHjxvjwww9rxIwlkt/XX3+NsLCwCscbN26MJUuWSF7//fff168mPGvWLFy6dAmPP/44/vzzTyxatEjy+rfjrSUisiivvPIKtm/fji+++AIdO3YEAOzduxfjx4/HU089ha+++sqk/dTEKfAkL3t7e5w9e7bCLuQXL15Eo0aNUFhYaPKe5BziwFtLRGRRNmzYgPXr1xuMUXnmmWfg4OCAQYMGmTTI1NQp8CQvPz8/7Nu3r0KQ2bdvH2rXri1LT3IOcWCQISKLkp+fX2lg8PLyMtkgw5o+BZ7kNXbsWEycOBHFxcX691xUVBQmT56MN954Q/L6nTt3vuuVlx07dkjeQ3kMMkRkUdq3b4/p06dj9erVsLe3BwAUFBRg5syZ+p2YpcQp8CS3t956C+np6fjf//6nX5zR3t4eb7/9NqZMmSJ5/RYtWhg8Li4uxvHjxxETE4MRI0ZIXv92HCNDRBbl1KlT6N69OzQajX620IkTJ2Bvb4+tW7fqV9mVCqfAk7nIzc3F2bNn4eDggODgYNkD9YwZM5Cbm2vyRfEYZIjI4uTn5+OHH37AuXPnAAANGzbEsGHD4ODgIHNnRKZz4cIFxMfHo1OnTnBwcNCv7CtnP23atEFGRoZJ6/LWEhGZvVatWiEqKgpubm6YNWsW3nzzTa6pQzVWeno6Bg0ahJ07d0KhUCAuLg5BQUEYM2YM3NzcMHfuXFn6OnDggP52rykxyBCR2Tt79izy8vLg5uaGmTNn4tVXX4Wjo6PcbRHJYtKkSbCxsUFCQoLBLvDPP/88IiMjJQ8y/fv3N3gshEBSUhIOHz6MqVOnSlq7MgwyRGT2WrRogVGjRuGxxx6DEAKfffYZnJ2dK33ttGnTTNwdkWn9/fff2Lp1K+rWrWtwPDg4GFeuXJG8vouLi8FjpVKJ0NBQzJo1C08//bTk9W/HIENEZm/lypWYPn06/vjjDygUCvz111+wtq747UuhUDDIULWXl5dX6RXJjIwMkwz4XbFiheQ1HgQH+xKRRVEqlUhOToaXl5fcrRDJ4plnnkHr1q0xe/ZsqFQqnDx5Ev7+/hg8eDB0Oh3Wr18vaf2rV69CoVDorwj9+++/WLNmDRo1aoSXX35Z0tqVYZAhIiKyIDExMejSpQtatWqFHTt2oE+fPjh9+jQyMjKwb98+1K9fX9L6jz/+OF5++WW8+OKLSE5ORkhICJo0aYK4uDiMGzfO5FdFeWuJiCxOXFwcdu7cidTUVP3mdWV4a4mqO7VajbNnz+Krr76CSqVCbm4u+vfvj4iICBQXF0tePyYmBm3atAEA/Pzzz2jatCn27duHv//+G6+++qrJ/w3yigwRWZRly5bhtddeg4eHB3x8fAzWzVAoFDh69KiM3RFJz8rKCklJSRVur6anp8PLywslJSWS1nd2dkZMTAwCAgLQp08fdOzYEW+//TYSEhIQGhqKgoICSevfjldkiMiifPDBB/i///s/vP3223K3QiSLO11/yM3NNck6Lo0bN8aSJUvQs2dPbNu2DbNnzwYAJCYmwt3dXfL6t2OQISKLcvPmTQwcOFDuNohMLjIyEsB/s/PKz1wqKSlBdHR0hX2QpPDJJ5/g2WefxaeffooRI0botwr57bff9LecTIm3lojIoowZMwaPPvooXn31VblbITKpzp07AwB2796N9u3bw9bWVv+cra0tAgIC8OabbyI4OFjyXkpKSpCdnQ03Nzf9scuXL8PR0dHkMwoZZIjIonz00UeYN28eevbsiaZNm8LGxsbg+fHjx8vUGZFpjBo1CgsXLoRarZa7FbPAIENEFiUwMPCOzykUCly8eNGE3RDVDOX3O2vZsuVdN6c09YB7jpEhIoty6dIluVsgqnH69u2rXzW4X79+8jZzG16RISKzFxkZidmzZ8PJyUk/4LEyCoVCtp1/iWqKl156CcOGDdOP2ZEbr8gQkdk7duyYfqGvY8eO3fF1d7vcTUTGkZaWhh49esDT0xNDhgzBsGHD9DOX5MArMkRERPRAbt68iXXr1mHNmjXYs2cPwsLCMGzYMAwdOhQBAQEm7YVBhoiIiKrs2rVrWLt2Lb799lvExcVBq9WatL7SpNWIiIio2iguLsbhw4cRHR2Ny5cvw9vb2+Q9MMgQERHRA9m5cyfGjh0Lb29vjBw5Emq1Gn/88QeuXbtm8l54a4mIiIjuW506dZCRkYHu3btj2LBh6N27t35qthwYZIiIiOi+LVu2DAMHDoSrq6vcrQBgkCEiIiILxjEyREREZLEYZIiIiMhiMcgQERGRxWKQISIiIovFIENENYZCocCvv/4qdxtEZEQMMkRkVGlpaXjttddQr1492NnZwcfHB926dcO+ffvkbo2IqiHufk1ERjVgwAAUFRVh1apVCAoKQkpKCqKiopCeni53a0RUDfGKDBEZTWZmJvbs2YNPPvkEnTt3hr+/P9q0aYMpU6agT58+AIB58+ahadOmcHJygp+fH/73v/8hNzdXf46VK1fC1dUVf/zxB0JDQ+Ho6IjnnnsO+fn5WLVqFQICAuDm5obx48ejpKRE/+cCAgIwe/ZsDBkyBE5OTqhTpw4WL158136vXr2KQYMGwdXVFbVq1ULfvn1x+fJl/fO7du1CmzZt4OTkBFdXV3Ts2BFXrlwx7heNiB4KgwwRGY2zszOcnZ3x66+/QqPRVPoapVKJRYsW4fTp01i1ahV27NiByZMnG7wmPz8fixYtwo8//ogtW7Zg165dePbZZ/Hnn3/izz//xHfffYevv/4a69evN/hzn376KZo3b45jx47hnXfewYQJE7Bt27ZK+yguLka3bt2gUqmwZ88e7Nu3D87OzujevTuKioqg1WrRr18/PPHEEzh58iQOHDiAl19+GQqFwjhfLCIyDkFEZETr168Xbm5uwt7eXnTo0EFMmTJFnDhx4o6vX7dunXB3d9c/XrFihQAgLly4oD/2yiuvCEdHR5GTk6M/1q1bN/HKK6/oH/v7+4vu3bsbnPv5558XPXr00D8GIH755RchhBDfffedCA0NFTqdTv+8RqMRDg4OYuvWrSI9PV0AELt27XrwLwIRmQyvyBCRUQ0YMACJiYn47bff0L17d+zatQutWrXCypUrAQDbt29Hly5dUKdOHahUKrz44otIT09Hfn6+/hyOjo6oX7++/rG3tzcCAgLg7OxscCw1NdWgdvv27Ss8Pnv2bKV9njhxAhcuXIBKpdJfSapVqxYKCwsRHx+PWrVqYeTIkejWrRt69+6NhQsXIikp6WG/PERkZAwyRGR09vb2eOqppzB16lTs378fI0eOxPTp03H58mX06tULzZo1w4YNG3DkyBH9OJaioiL9n7exsTE4n0KhqPSYTqerco+5ublo3bo1jh8/bvARGxuLoUOHAgBWrFiBAwcOoEOHDvjpp58QEhKCgwcPVrkmERkfgwwRSa5Ro0bIy8vDkSNHoNPpMHfuXLRr1w4hISFITEw0Wp3bQ8bBgwfRsGHDSl/bqlUrxMXFwcvLCw0aNDD4cHFx0b+uZcuWmDJlCvbv348mTZpgzZo1RuuXiB4egwwRGU16ejrCw8Px/fff4+TJk7h06RLWrVuHOXPmoG/fvmjQoAGKi4vx+eef4+LFi/juu++wZMkSo9Xft28f5syZg9jYWCxevBjr1q3DhAkTKn3tsGHD4OHhgb59+2LPnj24dOkSdu3ahfHjx+PatWu4dOkSpkyZggMHDuDKlSv4+++/ERcXd8dgRETy4DoyRGQ0zs7OaNu2LebPn4/4+HgUFxfDz88PY8eOxbvvvgsHBwfMmzcPn3zyCaZMmYJOnTrho48+wvDhw41S/4033sDhw4cxc+ZMqNVqzJs3D926dav0tY6Ojvjnn3/w9ttvo3///sjJyUGdOnXQpUsXqNVqFBQU4Ny5c1i1ahXS09Ph6+uLiIgIvPLKK0bplYiMQyGEEHI3QUT0sAICAjBx4kRMnDhR7laIyIR4a4mIiIgsFoMMERERWSzeWiIiIiKLxSsyREREZLEYZIiIiMhiMcgQERGRxWKQISIiIovFIENEREQWi0GGiIiILBaDDBEREVksBhkiIiKyWP8PlB+6zwx2jIEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Lexicon Normalization (Stemming, Lemmatization)***"
      ],
      "metadata": {
        "id": "PDIcCR_dbxV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "# Download WordNet corpus\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "# Initialize stemmer and lemmatizer\n",
        "porter = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Perform stemming and lemmatization\n",
        "stemmed_words = [porter.stem(word) for word in filtered_tokens]\n",
        "lemmatized_words = [lemmatizer.lemmatize(word.lower()) for word in filtered_tokens]\n",
        "\n",
        "# Print the results\n",
        "print(\"Stemmed Words:\", stemmed_words)\n",
        "print(\"Lemmatized Words:\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qlbyh0x0bwwb",
        "outputId": "76ea36c7-5791-4dbd-932a-c3d997096e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words: ['data', 'analysi', 'process', 'inspect', 'cleans', 'transform', 'model', 'data', 'goal', 'discov', 'use', 'inform', 'inform', 'conclus', 'support', 'data', 'analysi', 'multipl', 'facet', 'approach', 'encompass', 'divers', 'techniqu', 'varieti', 'name', 'use', 'differ', 'busi', 'scienc', 'social', 'scienc', 'domain', 'today', 'busi', 'world', 'data', 'analysi', 'play', 'role', 'make', 'decis', 'scientif', 'help', 'busi', 'oper', 'effect', 'data', 'mine', 'particular', 'data', 'analysi', 'techniqu', 'focus', 'statist', 'model', 'knowledg', 'discoveri', 'predict', 'rather', 'pure', 'descript', 'purpos', 'busi', 'intellig', 'cover', 'data', 'analysi', 'reli', 'heavili', 'aggreg', 'focus', 'mainli', 'busi', 'inform', 'statist', 'applic', 'data', 'analysi', 'divid', 'descript', 'statist', 'exploratori', 'data', 'analysi', 'eda', 'confirmatori', 'data', 'analysi', 'cda', 'eda', 'focus', 'discov', 'new', 'featur', 'data', 'cda', 'focus', 'confirm', 'falsifi', 'exist', 'hypothes', 'predict', 'analyt', 'focus', 'applic', 'statist', 'model', 'predict', 'forecast', 'classif', 'text', 'analyt', 'appli', 'statist', 'linguist', 'structur', 'techniqu', 'extract', 'classifi', 'inform', 'textual', 'sourc', 'speci', 'unstructur', 'data', 'varieti', 'data', 'analysi', 'data', 'integr', 'precursor', 'data', 'analysi', 'data', 'analysi', 'close', 'link', 'data', 'visual', 'data', 'process', 'data', 'analysi', 'data', 'scienc', 'process', 'flowchart', 'data', 'scienc', 'schutt', 'analysi', 'refer', 'divid', 'whole', 'separ', 'compon', 'individu', 'examin', 'data', 'analysi', 'process', 'obtain', 'raw', 'data', 'subsequ', 'convert', 'inform', 'use', 'user', 'data', 'collect', 'analyz', 'answer', 'question', 'test', 'hypothes', 'disprov', 'theori', 'statistician', 'john', 'tukey', 'defin', 'data', 'analysi', 'procedur', 'analyz', 'data', 'techniqu', 'interpret', 'result', 'procedur', 'way', 'plan', 'gather', 'data', 'make', 'analysi', 'easier', 'precis', 'accur', 'machineri', 'result', 'mathemat', 'statist', 'appli', 'analyz', 'data', 'sever', 'phase', 'distinguish', 'describ', 'phase', 'iter', 'feedback', 'later', 'phase', 'may', 'result', 'addit', 'work', 'earlier', 'phase', 'crisp', 'framework', 'use', 'data', 'mine', 'similar', 'step', 'data', 'requir', 'data', 'necessari', 'input', 'analysi', 'specifi', 'base', 'upon', 'requir', 'direct', 'analyt', 'custom', 'use', 'finish', 'product', 'analysi', 'gener', 'type', 'entiti', 'upon', 'data', 'collect', 'refer', 'experiment', 'unit', 'person', 'popul', 'peopl', 'specif', 'variabl', 'regard', 'popul', 'age', 'incom', 'may', 'specifi', 'obtain', 'data', 'may', 'numer', 'categor', 'text', 'label', 'number', 'data', 'collect', 'data', 'collect', 'varieti', 'sourc', 'list', 'data', 'sourc', 'avail', 'studi', 'research', 'requir', 'may', 'commun', 'analyst', 'custodian', 'data', 'inform', 'technolog', 'personnel', 'within', 'organ', 'data', 'collect', 'data', 'gather', 'process', 'gather', 'measur', 'inform', 'target', 'variabl', 'establish', 'system', 'enabl', 'one', 'answer', 'relev', 'question', 'evalu', 'outcom', 'data', 'may', 'also', 'collect', 'sensor', 'environ', 'includ', 'traffic', 'camera', 'satellit', 'record', 'devic', 'etc', 'may', 'also', 'obtain', 'interview', 'download', 'onlin', 'sourc', 'read', 'document', 'data', 'process', 'phase', 'intellig', 'cycl', 'use', 'convert', 'raw', 'inform', 'action', 'intellig', 'knowledg', 'conceptu', 'similar', 'phase', 'data', 'analysi', 'data', 'initi', 'obtain', 'must', 'process', 'organ', 'analysi', 'instanc', 'may', 'involv', 'place', 'data', 'row', 'column', 'tabl', 'format', 'known', 'structur', 'data', 'analysi', 'often', 'use', 'spreadsheet', 'statist', 'softwar', 'data', 'clean', 'main', 'articl', 'data', 'cleans', 'process', 'organ', 'data', 'may', 'incomplet', 'contain', 'duplic', 'contain', 'error', 'need', 'data', 'clean', 'aris', 'problem', 'way', 'datum', 'enter', 'store', 'data', 'clean', 'process', 'prevent', 'correct', 'error', 'common', 'task', 'includ', 'record', 'match', 'identifi', 'inaccuraci', 'data', 'overal', 'qualiti', 'exist', 'data', 'dedupl', 'column', 'segment', 'data', 'problem', 'also', 'identifi', 'varieti', 'analyt', 'techniqu', 'exampl', 'financi', 'inform', 'total', 'particular', 'variabl', 'may', 'compar', 'separ', 'publish', 'number', 'believ', 'reliabl', 'unusu', 'amount', 'predetermin', 'threshold', 'may', 'also', 'review', 'sever', 'type', 'data', 'clean', 'depend', 'upon', 'type', 'data', 'set', 'could', 'phone', 'number', 'email', 'address', 'employ', 'valu', 'quantit', 'data', 'method', 'outlier', 'detect', 'use', 'get', 'rid', 'data', 'appear', 'higher', 'likelihood', 'input', 'incorrectli', 'textual', 'data', 'spell', 'checker', 'use', 'lessen', 'amount', 'mistyp', 'word', 'howev', 'harder', 'tell', 'word', 'correct', 'exploratori', 'data', 'analysi', 'dataset', 'clean', 'analyz', 'analyst', 'may', 'appli', 'varieti', 'techniqu', 'refer', 'exploratori', 'data', 'analysi', 'begin', 'understand', 'messag', 'contain', 'within', 'obtain', 'data', 'process', 'data', 'explor', 'may', 'result', 'addit', 'data', 'clean', 'addit', 'request', 'data', 'thu', 'initi', 'iter', 'phase', 'mention', 'lead', 'paragraph', 'section', 'descript', 'statist', 'averag', 'median', 'gener', 'aid', 'understand', 'data', 'data', 'visual', 'also', 'techniqu', 'use', 'analyst', 'abl', 'examin', 'data', 'graphic', 'format', 'order', 'obtain', 'addit', 'insight', 'regard', 'messag', 'within', 'data', 'model', 'algorithm', 'mathemat', 'formula', 'model', 'also', 'known', 'algorithm', 'may', 'appli', 'data', 'order', 'identifi', 'relationship', 'among', 'variabl', 'exampl', 'use', 'correl', 'causat', 'gener', 'term', 'model', 'may', 'develop', 'evalu', 'specif', 'variabl', 'base', 'variabl', 'contain', 'within', 'dataset', 'residu', 'error', 'depend', 'implement', 'model', 'accuraci', 'data', 'model', 'error', 'inferenti', 'statist', 'includ', 'util', 'techniqu', 'measur', 'relationship', 'particular', 'variabl', 'exampl', 'regress', 'analysi', 'may', 'use', 'model', 'whether', 'chang', 'advertis', 'independ', 'variabl', 'x', 'provid', 'explan', 'variat', 'sale', 'depend', 'variabl', 'mathemat', 'term', 'sale', 'function', 'x', 'advertis', 'may', 'describ', 'ax', 'b', 'error', 'model', 'design', 'b', 'minim', 'error', 'model', 'predict', 'given', 'rang', 'valu', 'x', 'analyst', 'may', 'also', 'attempt', 'build', 'model', 'descript', 'data', 'aim', 'simplifi', 'analysi', 'commun', 'result', 'data', 'product', 'data', 'product', 'comput', 'applic', 'take', 'data', 'input', 'gener', 'output', 'feed', 'back', 'environ', 'may', 'base', 'model', 'algorithm', 'instanc', 'applic', 'analyz', 'data', 'custom', 'purchas', 'histori', 'use', 'result', 'recommend', 'purchas', 'custom', 'might', 'enjoy', 'commun', 'data', 'visual', 'use', 'help', 'understand', 'result', 'data', 'analyz', 'main', 'articl', 'data', 'inform', 'visual', 'data', 'analyz', 'may', 'report', 'mani', 'format', 'user', 'analysi', 'support', 'requir', 'user', 'may', 'feedback', 'result', 'addit', 'analysi', 'much', 'analyt', 'cycl', 'iter', 'determin', 'commun', 'result', 'analyst', 'may', 'consid', 'implement', 'varieti', 'data', 'visual', 'techniqu', 'help', 'commun', 'messag', 'clearli', 'effici', 'audienc', 'data', 'visual', 'use', 'inform', 'display', 'graphic', 'tabl', 'chart', 'help', 'commun', 'key', 'messag', 'contain', 'data', 'tabl', 'valuabl', 'tool', 'enabl', 'abil', 'user', 'queri', 'focu', 'specif', 'number', 'chart', 'bar', 'chart', 'line', 'chart', 'may', 'help', 'explain', 'quantit', 'messag', 'contain', 'data', 'quantit', 'messag', 'main', 'articl', 'data', 'inform', 'visual', 'time', 'seri', 'illustr', 'line', 'chart', 'demonstr', 'trend', 'feder', 'spend', 'revenu', 'time', 'scatterplot', 'illustr', 'correl', 'two', 'variabl', 'inflat', 'unemploy', 'measur', 'point', 'time', 'stephen', 'describ', 'eight', 'type', 'quantit', 'messag', 'user', 'may', 'attempt', 'understand', 'commun', 'set', 'data', 'associ', 'graph', 'use', 'help', 'commun', 'messag', 'custom', 'specifi', 'requir', 'analyst', 'perform', 'data', 'analysi', 'may', 'consid', 'messag', 'cours', 'process', 'singl', 'variabl', 'captur', 'period', 'time', 'unemploy', 'rate', 'period', 'line', 'chart', 'may', 'use', 'demonstr', 'trend', 'rank', 'categor', 'subdivis', 'rank', 'ascend', 'descend', 'order', 'rank', 'sale', 'perform', 'measur', 'salesperson', 'categori', 'salesperson', 'categor', 'subdivis', 'singl', 'period', 'bar', 'chart', 'may', 'use', 'show', 'comparison', 'across', 'salesperson', 'categor', 'subdivis', 'measur', 'ratio', 'whole', 'percentag', 'pie', 'chart', 'bar', 'chart', 'show', 'comparison', 'ratio', 'market', 'share', 'repres', 'competitor', 'market', 'deviat', 'categor', 'subdivis', 'compar', 'refer', 'comparison', 'actual', 'budget', 'expens', 'sever', 'depart', 'busi', 'given', 'time', 'period', 'bar', 'chart', 'show', 'comparison', 'actual', 'versu', 'refer', 'amount', 'frequenc', 'distribut', 'show', 'number', 'observ', 'particular', 'variabl', 'given', 'interv', 'number', 'year', 'stock', 'market', 'return', 'interv', 'etc', 'histogram', 'type', 'bar', 'chart', 'may', 'use', 'analysi', 'correl', 'comparison', 'observ', 'repres', 'two', 'variabl', 'x', 'determin', 'tend', 'move', 'opposit', 'direct', 'exampl', 'plot', 'unemploy', 'x', 'inflat', 'sampl', 'month', 'scatter', 'plot', 'typic', 'use', 'messag', 'nomin', 'comparison', 'compar', 'categor', 'subdivis', 'particular', 'order', 'sale', 'volum', 'product', 'code', 'bar', 'chart', 'may', 'use', 'comparison', 'geograph', 'geospati', 'comparison', 'variabl', 'across', 'map', 'layout', 'unemploy', 'rate', 'state', 'number', 'person', 'variou', 'floor', 'build', 'cartogram', 'typic', 'graphic', 'use', 'techniqu', 'analyz', 'quantit', 'data', 'see', 'also', 'problem', 'solv', 'author', 'jonathan', 'koomey', 'recommend', 'seri', 'best', 'practic', 'understand', 'quantit', 'data', 'includ', 'check', 'raw', 'data', 'anomali', 'prior', 'perform', 'analysi', 'import', 'calcul', 'verifi', 'column', 'data', 'formula', 'driven', 'confirm', 'main', 'total', 'sum', 'subtot', 'check', 'relationship', 'number', 'relat', 'predict', 'way', 'ratio', 'time', 'normal', 'number', 'make', 'comparison', 'easier', 'analyz', 'amount', 'per', 'person', 'rel', 'gdp', 'index', 'valu', 'rel', 'base', 'year', 'break', 'problem', 'compon', 'part', 'analyz', 'factor', 'led', 'result', 'dupont', 'analysi', 'return', 'equiti', 'variabl', 'examin', 'analyst', 'typic', 'obtain', 'descript', 'statist', 'mean', 'averag', 'median', 'standard', 'deviat', 'may', 'also', 'analyz', 'distribut', 'key', 'variabl', 'see', 'individu', 'valu', 'cluster', 'around', 'mean', 'illustr', 'mece', 'principl', 'use', 'data', 'analysi', 'consult', 'mckinsey', 'compani', 'name', 'techniqu', 'break', 'quantit', 'problem', 'compon', 'part', 'call', 'mece', 'principl', 'layer', 'broken', 'compon', 'must', 'mutual', 'exclus', 'collect', 'add', 'layer', 'relationship', 'refer', 'mutual', 'exclus', 'collect', 'exhaust', 'mece', 'exampl', 'profit', 'definit', 'broken', 'total', 'revenu', 'total', 'cost', 'turn', 'total', 'revenu', 'analyz', 'compon', 'revenu', 'divis', 'b', 'c', 'mutual', 'exclus', 'add', 'total', 'revenu', 'collect', 'exhaust', 'analyst', 'may', 'use', 'robust', 'statist', 'measur', 'solv', 'certain', 'analyt', 'problem', 'hypothesi', 'test', 'use', 'particular', 'hypothesi', 'true', 'state', 'affair', 'made', 'analyst', 'data', 'gather', 'determin', 'whether', 'state', 'affair', 'true', 'fals', 'exampl', 'hypothesi', 'might', 'unemploy', 'effect', 'inflat', 'relat', 'econom', 'concept', 'call', 'phillip', 'curv', 'hypothesi', 'test', 'involv', 'consid', 'likelihood', 'type', 'type', 'ii', 'error', 'relat', 'whether', 'data', 'support', 'accept', 'reject', 'hypothesi', 'regress', 'analysi', 'may', 'use', 'analyst', 'tri', 'determin', 'extent', 'independ', 'variabl', 'x', 'affect', 'depend', 'variabl', 'extent', 'chang', 'unemploy', 'rate', 'x', 'affect', 'inflat', 'rate', 'attempt', 'model', 'fit', 'equat', 'line', 'curv', 'data', 'function', 'x', 'necessari', 'condit', 'analysi', 'nca', 'may', 'use', 'analyst', 'tri', 'determin', 'extent', 'independ', 'variabl', 'x', 'allow', 'variabl', 'extent', 'certain', 'unemploy', 'rate', 'x', 'necessari', 'certain', 'inflat', 'rate', 'wherea', 'multipl', 'regress', 'analysi', 'use', 'addit', 'logic', 'produc', 'outcom', 'x', 'compens', 'suffici', 'necessari', 'necessari', 'condit', 'analysi', 'nca', 'use', 'necess', 'logic', 'one', 'allow', 'outcom', 'exist', 'may', 'produc', 'necessari', 'suffici', 'singl', 'necessari', 'condit', 'must', 'present', 'compens', 'possibl']\n",
            "Lemmatized Words: ['data', 'analysis', 'process', 'inspecting', 'cleansing', 'transforming', 'modeling', 'data', 'goal', 'discovering', 'useful', 'information', 'informing', 'conclusion', 'supporting', 'data', 'analysis', 'multiple', 'facet', 'approach', 'encompassing', 'diverse', 'technique', 'variety', 'name', 'used', 'different', 'business', 'science', 'social', 'science', 'domain', 'today', 'business', 'world', 'data', 'analysis', 'play', 'role', 'making', 'decision', 'scientific', 'helping', 'business', 'operate', 'effectively', 'data', 'mining', 'particular', 'data', 'analysis', 'technique', 'focus', 'statistical', 'modeling', 'knowledge', 'discovery', 'predictive', 'rather', 'purely', 'descriptive', 'purpose', 'business', 'intelligence', 'cover', 'data', 'analysis', 'relies', 'heavily', 'aggregation', 'focusing', 'mainly', 'business', 'information', 'statistical', 'application', 'data', 'analysis', 'divided', 'descriptive', 'statistic', 'exploratory', 'data', 'analysis', 'eda', 'confirmatory', 'data', 'analysis', 'cda', 'eda', 'focus', 'discovering', 'new', 'feature', 'data', 'cda', 'focus', 'confirming', 'falsifying', 'existing', 'hypothesis', 'predictive', 'analytics', 'focus', 'application', 'statistical', 'model', 'predictive', 'forecasting', 'classification', 'text', 'analytics', 'applies', 'statistical', 'linguistic', 'structural', 'technique', 'extract', 'classify', 'information', 'textual', 'source', 'specie', 'unstructured', 'data', 'variety', 'data', 'analysis', 'data', 'integration', 'precursor', 'data', 'analysis', 'data', 'analysis', 'closely', 'linked', 'data', 'visualization', 'data', 'process', 'data', 'analysis', 'data', 'science', 'process', 'flowchart', 'data', 'science', 'schutt', 'analysis', 'refers', 'dividing', 'whole', 'separate', 'component', 'individual', 'examination', 'data', 'analysis', 'process', 'obtaining', 'raw', 'data', 'subsequently', 'converting', 'information', 'useful', 'user', 'data', 'collected', 'analyzed', 'answer', 'question', 'test', 'hypothesis', 'disprove', 'theory', 'statistician', 'john', 'tukey', 'defined', 'data', 'analysis', 'procedure', 'analyzing', 'data', 'technique', 'interpreting', 'result', 'procedure', 'way', 'planning', 'gathering', 'data', 'make', 'analysis', 'easier', 'precise', 'accurate', 'machinery', 'result', 'mathematical', 'statistic', 'apply', 'analyzing', 'data', 'several', 'phase', 'distinguished', 'described', 'phase', 'iterative', 'feedback', 'later', 'phase', 'may', 'result', 'additional', 'work', 'earlier', 'phase', 'crisp', 'framework', 'used', 'data', 'mining', 'similar', 'step', 'data', 'requirement', 'data', 'necessary', 'input', 'analysis', 'specified', 'based', 'upon', 'requirement', 'directing', 'analytics', 'customer', 'use', 'finished', 'product', 'analysis', 'general', 'type', 'entity', 'upon', 'data', 'collected', 'referred', 'experimental', 'unit', 'person', 'population', 'people', 'specific', 'variable', 'regarding', 'population', 'age', 'income', 'may', 'specified', 'obtained', 'data', 'may', 'numerical', 'categorical', 'text', 'label', 'number', 'data', 'collection', 'data', 'collected', 'variety', 'source', 'list', 'data', 'source', 'available', 'study', 'research', 'requirement', 'may', 'communicated', 'analyst', 'custodian', 'data', 'information', 'technology', 'personnel', 'within', 'organization', 'data', 'collection', 'data', 'gathering', 'process', 'gathering', 'measuring', 'information', 'targeted', 'variable', 'established', 'system', 'enables', 'one', 'answer', 'relevant', 'question', 'evaluate', 'outcome', 'data', 'may', 'also', 'collected', 'sensor', 'environment', 'including', 'traffic', 'camera', 'satellite', 'recording', 'device', 'etc', 'may', 'also', 'obtained', 'interview', 'downloads', 'online', 'source', 'reading', 'documentation', 'data', 'processing', 'phase', 'intelligence', 'cycle', 'used', 'convert', 'raw', 'information', 'actionable', 'intelligence', 'knowledge', 'conceptually', 'similar', 'phase', 'data', 'analysis', 'data', 'initially', 'obtained', 'must', 'processed', 'organized', 'analysis', 'instance', 'may', 'involve', 'placing', 'data', 'row', 'column', 'table', 'format', 'known', 'structured', 'data', 'analysis', 'often', 'use', 'spreadsheet', 'statistical', 'software', 'data', 'cleaning', 'main', 'article', 'data', 'cleansing', 'processed', 'organized', 'data', 'may', 'incomplete', 'contain', 'duplicate', 'contain', 'error', 'need', 'data', 'cleaning', 'arise', 'problem', 'way', 'datum', 'entered', 'stored', 'data', 'cleaning', 'process', 'preventing', 'correcting', 'error', 'common', 'task', 'include', 'record', 'matching', 'identifying', 'inaccuracy', 'data', 'overall', 'quality', 'existing', 'data', 'deduplication', 'column', 'segmentation', 'data', 'problem', 'also', 'identified', 'variety', 'analytical', 'technique', 'example', 'financial', 'information', 'total', 'particular', 'variable', 'may', 'compared', 'separately', 'published', 'number', 'believed', 'reliable', 'unusual', 'amount', 'predetermined', 'threshold', 'may', 'also', 'reviewed', 'several', 'type', 'data', 'cleaning', 'dependent', 'upon', 'type', 'data', 'set', 'could', 'phone', 'number', 'email', 'address', 'employer', 'value', 'quantitative', 'data', 'method', 'outlier', 'detection', 'used', 'get', 'rid', 'data', 'appears', 'higher', 'likelihood', 'input', 'incorrectly', 'textual', 'data', 'spell', 'checker', 'used', 'lessen', 'amount', 'mistyped', 'word', 'however', 'harder', 'tell', 'word', 'correct', 'exploratory', 'data', 'analysis', 'datasets', 'cleaned', 'analyzed', 'analyst', 'may', 'apply', 'variety', 'technique', 'referred', 'exploratory', 'data', 'analysis', 'begin', 'understanding', 'message', 'contained', 'within', 'obtained', 'data', 'process', 'data', 'exploration', 'may', 'result', 'additional', 'data', 'cleaning', 'additional', 'request', 'data', 'thus', 'initialization', 'iterative', 'phase', 'mentioned', 'lead', 'paragraph', 'section', 'descriptive', 'statistic', 'average', 'median', 'generated', 'aid', 'understanding', 'data', 'data', 'visualization', 'also', 'technique', 'used', 'analyst', 'able', 'examine', 'data', 'graphical', 'format', 'order', 'obtain', 'additional', 'insight', 'regarding', 'message', 'within', 'data', 'modeling', 'algorithm', 'mathematical', 'formula', 'model', 'also', 'known', 'algorithm', 'may', 'applied', 'data', 'order', 'identify', 'relationship', 'among', 'variable', 'example', 'using', 'correlation', 'causation', 'general', 'term', 'model', 'may', 'developed', 'evaluate', 'specific', 'variable', 'based', 'variable', 'contained', 'within', 'dataset', 'residual', 'error', 'depending', 'implemented', 'model', 'accuracy', 'data', 'model', 'error', 'inferential', 'statistic', 'includes', 'utilizing', 'technique', 'measure', 'relationship', 'particular', 'variable', 'example', 'regression', 'analysis', 'may', 'used', 'model', 'whether', 'change', 'advertising', 'independent', 'variable', 'x', 'provides', 'explanation', 'variation', 'sale', 'dependent', 'variable', 'mathematical', 'term', 'sale', 'function', 'x', 'advertising', 'may', 'described', 'ax', 'b', 'error', 'model', 'designed', 'b', 'minimize', 'error', 'model', 'predicts', 'given', 'range', 'value', 'x', 'analyst', 'may', 'also', 'attempt', 'build', 'model', 'descriptive', 'data', 'aim', 'simplify', 'analysis', 'communicate', 'result', 'data', 'product', 'data', 'product', 'computer', 'application', 'take', 'data', 'input', 'generates', 'output', 'feeding', 'back', 'environment', 'may', 'based', 'model', 'algorithm', 'instance', 'application', 'analyzes', 'data', 'customer', 'purchase', 'history', 'us', 'result', 'recommend', 'purchase', 'customer', 'might', 'enjoy', 'communication', 'data', 'visualization', 'used', 'help', 'understand', 'result', 'data', 'analyzed', 'main', 'article', 'data', 'information', 'visualization', 'data', 'analyzed', 'may', 'reported', 'many', 'format', 'user', 'analysis', 'support', 'requirement', 'user', 'may', 'feedback', 'result', 'additional', 'analysis', 'much', 'analytical', 'cycle', 'iterative', 'determining', 'communicate', 'result', 'analyst', 'may', 'consider', 'implementing', 'variety', 'data', 'visualization', 'technique', 'help', 'communicate', 'message', 'clearly', 'efficiently', 'audience', 'data', 'visualization', 'us', 'information', 'display', 'graphic', 'table', 'chart', 'help', 'communicate', 'key', 'message', 'contained', 'data', 'table', 'valuable', 'tool', 'enabling', 'ability', 'user', 'query', 'focus', 'specific', 'number', 'chart', 'bar', 'chart', 'line', 'chart', 'may', 'help', 'explain', 'quantitative', 'message', 'contained', 'data', 'quantitative', 'message', 'main', 'article', 'data', 'information', 'visualization', 'time', 'series', 'illustrated', 'line', 'chart', 'demonstrating', 'trend', 'federal', 'spending', 'revenue', 'time', 'scatterplot', 'illustrating', 'correlation', 'two', 'variable', 'inflation', 'unemployment', 'measured', 'point', 'time', 'stephen', 'described', 'eight', 'type', 'quantitative', 'message', 'user', 'may', 'attempt', 'understand', 'communicate', 'set', 'data', 'associated', 'graph', 'used', 'help', 'communicate', 'message', 'customer', 'specifying', 'requirement', 'analyst', 'performing', 'data', 'analysis', 'may', 'consider', 'message', 'course', 'process', 'single', 'variable', 'captured', 'period', 'time', 'unemployment', 'rate', 'period', 'line', 'chart', 'may', 'used', 'demonstrate', 'trend', 'ranking', 'categorical', 'subdivision', 'ranked', 'ascending', 'descending', 'order', 'ranking', 'sale', 'performance', 'measure', 'salesperson', 'category', 'salesperson', 'categorical', 'subdivision', 'single', 'period', 'bar', 'chart', 'may', 'used', 'show', 'comparison', 'across', 'salesperson', 'categorical', 'subdivision', 'measured', 'ratio', 'whole', 'percentage', 'pie', 'chart', 'bar', 'chart', 'show', 'comparison', 'ratio', 'market', 'share', 'represented', 'competitor', 'market', 'deviation', 'categorical', 'subdivision', 'compared', 'reference', 'comparison', 'actual', 'budget', 'expense', 'several', 'department', 'business', 'given', 'time', 'period', 'bar', 'chart', 'show', 'comparison', 'actual', 'versus', 'reference', 'amount', 'frequency', 'distribution', 'show', 'number', 'observation', 'particular', 'variable', 'given', 'interval', 'number', 'year', 'stock', 'market', 'return', 'interval', 'etc', 'histogram', 'type', 'bar', 'chart', 'may', 'used', 'analysis', 'correlation', 'comparison', 'observation', 'represented', 'two', 'variable', 'x', 'determine', 'tend', 'move', 'opposite', 'direction', 'example', 'plotting', 'unemployment', 'x', 'inflation', 'sample', 'month', 'scatter', 'plot', 'typically', 'used', 'message', 'nominal', 'comparison', 'comparing', 'categorical', 'subdivision', 'particular', 'order', 'sale', 'volume', 'product', 'code', 'bar', 'chart', 'may', 'used', 'comparison', 'geographic', 'geospatial', 'comparison', 'variable', 'across', 'map', 'layout', 'unemployment', 'rate', 'state', 'number', 'person', 'various', 'floor', 'building', 'cartogram', 'typical', 'graphic', 'used', 'technique', 'analyzing', 'quantitative', 'data', 'see', 'also', 'problem', 'solving', 'author', 'jonathan', 'koomey', 'recommended', 'series', 'best', 'practice', 'understanding', 'quantitative', 'data', 'include', 'check', 'raw', 'data', 'anomaly', 'prior', 'performing', 'analysis', 'important', 'calculation', 'verifying', 'column', 'data', 'formula', 'driven', 'confirm', 'main', 'total', 'sum', 'subtotal', 'check', 'relationship', 'number', 'related', 'predictable', 'way', 'ratio', 'time', 'normalize', 'number', 'make', 'comparison', 'easier', 'analyzing', 'amount', 'per', 'person', 'relative', 'gdp', 'index', 'value', 'relative', 'base', 'year', 'break', 'problem', 'component', 'part', 'analyzing', 'factor', 'led', 'result', 'dupont', 'analysis', 'return', 'equity', 'variable', 'examination', 'analyst', 'typically', 'obtain', 'descriptive', 'statistic', 'mean', 'average', 'median', 'standard', 'deviation', 'may', 'also', 'analyze', 'distribution', 'key', 'variable', 'see', 'individual', 'value', 'cluster', 'around', 'mean', 'illustration', 'mece', 'principle', 'used', 'data', 'analysis', 'consultant', 'mckinsey', 'company', 'named', 'technique', 'breaking', 'quantitative', 'problem', 'component', 'part', 'called', 'mece', 'principle', 'layer', 'broken', 'component', 'must', 'mutually', 'exclusive', 'collectively', 'add', 'layer', 'relationship', 'referred', 'mutually', 'exclusive', 'collectively', 'exhaustive', 'mece', 'example', 'profit', 'definition', 'broken', 'total', 'revenue', 'total', 'cost', 'turn', 'total', 'revenue', 'analyzed', 'component', 'revenue', 'division', 'b', 'c', 'mutually', 'exclusive', 'add', 'total', 'revenue', 'collectively', 'exhaustive', 'analyst', 'may', 'use', 'robust', 'statistical', 'measurement', 'solve', 'certain', 'analytical', 'problem', 'hypothesis', 'testing', 'used', 'particular', 'hypothesis', 'true', 'state', 'affair', 'made', 'analyst', 'data', 'gathered', 'determine', 'whether', 'state', 'affair', 'true', 'false', 'example', 'hypothesis', 'might', 'unemployment', 'effect', 'inflation', 'relates', 'economics', 'concept', 'called', 'phillips', 'curve', 'hypothesis', 'testing', 'involves', 'considering', 'likelihood', 'type', 'type', 'ii', 'error', 'relate', 'whether', 'data', 'support', 'accepting', 'rejecting', 'hypothesis', 'regression', 'analysis', 'may', 'used', 'analyst', 'trying', 'determine', 'extent', 'independent', 'variable', 'x', 'affect', 'dependent', 'variable', 'extent', 'change', 'unemployment', 'rate', 'x', 'affect', 'inflation', 'rate', 'attempt', 'model', 'fit', 'equation', 'line', 'curve', 'data', 'function', 'x', 'necessary', 'condition', 'analysis', 'nca', 'may', 'used', 'analyst', 'trying', 'determine', 'extent', 'independent', 'variable', 'x', 'allows', 'variable', 'extent', 'certain', 'unemployment', 'rate', 'x', 'necessary', 'certain', 'inflation', 'rate', 'whereas', 'multiple', 'regression', 'analysis', 'us', 'additive', 'logic', 'produce', 'outcome', 'x', 'compensate', 'sufficient', 'necessary', 'necessary', 'condition', 'analysis', 'nca', 'us', 'necessity', 'logic', 'one', 'allow', 'outcome', 'exist', 'may', 'produce', 'necessary', 'sufficient', 'single', 'necessary', 'condition', 'must', 'present', 'compensation', 'possible']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part of speech"
      ],
      "metadata": {
        "id": "1MiR-M_Wcz8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "pos_tags = nltk.pos_tag(filtered_tokens)\n",
        "print(\"Part of Speech Tags:\", pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WVy-tuTczgD",
        "outputId": "f7fa311b-275b-4bd3-d663-c5104291ec05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part of Speech Tags: [('Data', 'NNP'), ('analysis', 'NN'), ('process', 'NN'), ('inspecting', 'VBG'), ('cleansing', 'VBG'), ('transforming', 'VBG'), ('modeling', 'VBG'), ('data', 'NNS'), ('goal', 'NN'), ('discovering', 'VBG'), ('useful', 'JJ'), ('information', 'NN'), ('informing', 'VBG'), ('conclusions', 'NNS'), ('supporting', 'VBG'), ('Data', 'NNP'), ('analysis', 'NN'), ('multiple', 'JJ'), ('facets', 'NNS'), ('approaches', 'VBZ'), ('encompassing', 'VBG'), ('diverse', 'NN'), ('techniques', 'NNS'), ('variety', 'NN'), ('names', 'NNS'), ('used', 'VBN'), ('different', 'JJ'), ('business', 'NN'), ('science', 'NN'), ('social', 'JJ'), ('science', 'NN'), ('domains', 'NNS'), ('today', 'NN'), ('business', 'NN'), ('world', 'NN'), ('data', 'NN'), ('analysis', 'NN'), ('plays', 'VBZ'), ('role', 'NN'), ('making', 'NN'), ('decisions', 'NNS'), ('scientific', 'JJ'), ('helping', 'VBG'), ('businesses', 'NNS'), ('operate', 'VBP'), ('effectively', 'RB'), ('Data', 'NNP'), ('mining', 'NN'), ('particular', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('technique', 'NN'), ('focuses', 'VBZ'), ('statistical', 'JJ'), ('modeling', 'VBG'), ('knowledge', 'NN'), ('discovery', 'NN'), ('predictive', 'VBP'), ('rather', 'RB'), ('purely', 'RB'), ('descriptive', 'JJ'), ('purposes', 'NNS'), ('business', 'NN'), ('intelligence', 'NN'), ('covers', 'VBZ'), ('data', 'NNS'), ('analysis', 'NN'), ('relies', 'NNS'), ('heavily', 'RB'), ('aggregation', 'VBP'), ('focusing', 'VBG'), ('mainly', 'RB'), ('business', 'NN'), ('information', 'NN'), ('statistical', 'JJ'), ('applications', 'NNS'), ('data', 'NNS'), ('analysis', 'NN'), ('divided', 'VBD'), ('descriptive', 'JJ'), ('statistics', 'NNS'), ('exploratory', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('EDA', 'NNP'), ('confirmatory', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('CDA', 'NNP'), ('EDA', 'NNP'), ('focuses', 'VBZ'), ('discovering', 'VBG'), ('new', 'JJ'), ('features', 'NNS'), ('data', 'VBP'), ('CDA', 'NNP'), ('focuses', 'VBZ'), ('confirming', 'VBG'), ('falsifying', 'VBG'), ('existing', 'VBG'), ('hypotheses', 'NNS'), ('Predictive', 'NNP'), ('analytics', 'NNS'), ('focuses', 'VBZ'), ('application', 'NN'), ('statistical', 'JJ'), ('models', 'NNS'), ('predictive', 'VBP'), ('forecasting', 'VBG'), ('classification', 'NN'), ('text', 'NN'), ('analytics', 'NNS'), ('applies', 'VBZ'), ('statistical', 'JJ'), ('linguistic', 'JJ'), ('structural', 'JJ'), ('techniques', 'NNS'), ('extract', 'VBP'), ('classify', 'JJ'), ('information', 'NN'), ('textual', 'JJ'), ('sources', 'NNS'), ('species', 'NNS'), ('unstructured', 'VBD'), ('data', 'NNS'), ('varieties', 'NNS'), ('data', 'VBP'), ('analysis', 'NN'), ('Data', 'NNP'), ('integration', 'NN'), ('precursor', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('closely', 'RB'), ('linked', 'VBN'), ('data', 'NNS'), ('visualization', 'NN'), ('data', 'NNS'), ('process', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('Data', 'NNP'), ('science', 'NN'), ('process', 'NN'), ('flowchart', 'NN'), ('Data', 'NNP'), ('Science', 'NNP'), ('Schutt', 'NNP'), ('Analysis', 'NNP'), ('refers', 'NNS'), ('dividing', 'VBG'), ('whole', 'JJ'), ('separate', 'JJ'), ('components', 'NNS'), ('individual', 'JJ'), ('examination', 'NN'), ('Data', 'NNP'), ('analysis', 'NN'), ('process', 'NN'), ('obtaining', 'VBG'), ('raw', 'JJ'), ('data', 'NNS'), ('subsequently', 'RB'), ('converting', 'VBG'), ('information', 'NN'), ('useful', 'JJ'), ('users', 'NNS'), ('Data', 'NNP'), ('collected', 'VBD'), ('analyzed', 'JJ'), ('answer', 'NN'), ('questions', 'NNS'), ('test', 'VBP'), ('hypotheses', 'NNS'), ('disprove', 'VB'), ('theories', 'NNS'), ('Statistician', 'NNP'), ('John', 'NNP'), ('Tukey', 'NNP'), ('defined', 'VBD'), ('data', 'NNS'), ('analysis', 'NN'), ('Procedures', 'NNS'), ('analyzing', 'VBG'), ('data', 'NNS'), ('techniques', 'NNS'), ('interpreting', 'VBG'), ('results', 'NNS'), ('procedures', 'NNS'), ('ways', 'NNS'), ('planning', 'VBG'), ('gathering', 'NN'), ('data', 'NNS'), ('make', 'VBP'), ('analysis', 'NN'), ('easier', 'JJR'), ('precise', 'JJ'), ('accurate', 'JJ'), ('machinery', 'NN'), ('results', 'NNS'), ('mathematical', 'JJ'), ('statistics', 'NNS'), ('apply', 'VBP'), ('analyzing', 'VBG'), ('data', 'NNS'), ('several', 'JJ'), ('phases', 'NNS'), ('distinguished', 'VBN'), ('described', 'JJ'), ('phases', 'NNS'), ('iterative', 'JJ'), ('feedback', 'NN'), ('later', 'RBR'), ('phases', 'NNS'), ('may', 'MD'), ('result', 'VB'), ('additional', 'JJ'), ('work', 'NN'), ('earlier', 'RBR'), ('phases', 'NNS'), ('CRISP', 'NNP'), ('framework', 'NN'), ('used', 'VBN'), ('data', 'NNS'), ('mining', 'NN'), ('similar', 'JJ'), ('steps', 'NNS'), ('Data', 'NNP'), ('requirements', 'NNS'), ('data', 'NNS'), ('necessary', 'JJ'), ('inputs', 'NNS'), ('analysis', 'NN'), ('specified', 'VBN'), ('based', 'VBN'), ('upon', 'IN'), ('requirements', 'NNS'), ('directing', 'VBG'), ('analytics', 'NNS'), ('customers', 'NNS'), ('use', 'VBP'), ('finished', 'JJ'), ('product', 'NN'), ('analysis', 'NN'), ('general', 'JJ'), ('type', 'NN'), ('entity', 'NN'), ('upon', 'IN'), ('data', 'NNS'), ('collected', 'VBN'), ('referred', 'JJ'), ('experimental', 'JJ'), ('unit', 'NN'), ('person', 'NN'), ('population', 'NN'), ('people', 'NNS'), ('Specific', 'NNP'), ('variables', 'VBZ'), ('regarding', 'VBG'), ('population', 'NN'), ('age', 'NN'), ('income', 'NN'), ('may', 'MD'), ('specified', 'VB'), ('obtained', 'VBN'), ('Data', 'NNP'), ('may', 'MD'), ('numerical', 'JJ'), ('categorical', 'JJ'), ('text', 'NN'), ('label', 'NN'), ('numbers', 'NNS'), ('Data', 'NNP'), ('collection', 'NN'), ('Data', 'NNP'), ('collected', 'VBD'), ('variety', 'NN'), ('sources', 'NNS'), ('list', 'NN'), ('data', 'NNS'), ('sources', 'NNS'), ('available', 'JJ'), ('study', 'NN'), ('research', 'NN'), ('requirements', 'NNS'), ('may', 'MD'), ('communicated', 'VB'), ('analysts', 'NNS'), ('custodians', 'VBZ'), ('data', 'JJ'), ('Information', 'NNP'), ('Technology', 'NNP'), ('personnel', 'NNS'), ('within', 'IN'), ('organization', 'NN'), ('Data', 'NNP'), ('collection', 'NN'), ('data', 'NNS'), ('gathering', 'NN'), ('process', 'NN'), ('gathering', 'VBG'), ('measuring', 'VBG'), ('information', 'NN'), ('targeted', 'VBD'), ('variables', 'NNS'), ('established', 'VBN'), ('system', 'NN'), ('enables', 'VBZ'), ('one', 'CD'), ('answer', 'NN'), ('relevant', 'JJ'), ('questions', 'NNS'), ('evaluate', 'VBP'), ('outcomes', 'NNS'), ('data', 'NNS'), ('may', 'MD'), ('also', 'RB'), ('collected', 'VBN'), ('sensors', 'NNS'), ('environment', 'NN'), ('including', 'VBG'), ('traffic', 'NN'), ('cameras', 'NNS'), ('satellites', 'VBZ'), ('recording', 'VBG'), ('devices', 'NNS'), ('etc', 'NN'), ('may', 'MD'), ('also', 'RB'), ('obtained', 'VBN'), ('interviews', 'NNS'), ('downloads', 'NNS'), ('online', 'JJ'), ('sources', 'NNS'), ('reading', 'VBG'), ('documentation', 'NN'), ('Data', 'NNP'), ('processing', 'NN'), ('phases', 'NNS'), ('intelligence', 'NN'), ('cycle', 'NN'), ('used', 'VBN'), ('convert', 'JJ'), ('raw', 'JJ'), ('information', 'NN'), ('actionable', 'JJ'), ('intelligence', 'NN'), ('knowledge', 'NN'), ('conceptually', 'RB'), ('similar', 'JJ'), ('phases', 'NNS'), ('data', 'NNS'), ('analysis', 'NN'), ('Data', 'NNP'), ('initially', 'RB'), ('obtained', 'VBD'), ('must', 'MD'), ('processed', 'VBN'), ('organized', 'VBN'), ('analysis', 'NN'), ('instance', 'NN'), ('may', 'MD'), ('involve', 'VB'), ('placing', 'VBG'), ('data', 'NNS'), ('rows', 'NNS'), ('columns', 'VBP'), ('table', 'JJ'), ('format', 'NN'), ('known', 'VBN'), ('structured', 'VBN'), ('data', 'NNS'), ('analysis', 'NN'), ('often', 'RB'), ('use', 'JJ'), ('spreadsheet', 'JJ'), ('statistical', 'JJ'), ('software', 'NN'), ('Data', 'NNP'), ('cleaning', 'NN'), ('Main', 'NNP'), ('article', 'NN'), ('Data', 'NNP'), ('cleansing', 'NN'), ('processed', 'VBD'), ('organized', 'VBN'), ('data', 'NNS'), ('may', 'MD'), ('incomplete', 'VB'), ('contain', 'NN'), ('duplicates', 'NNS'), ('contain', 'VBP'), ('errors', 'NNS'), ('need', 'VBP'), ('data', 'NNS'), ('cleaning', 'VBG'), ('arise', 'NN'), ('problems', 'NNS'), ('way', 'NN'), ('datum', 'NN'), ('entered', 'VBD'), ('stored', 'VBN'), ('Data', 'NNP'), ('cleaning', 'NN'), ('process', 'NN'), ('preventing', 'VBG'), ('correcting', 'VBG'), ('errors', 'NNS'), ('Common', 'NNP'), ('tasks', 'NNS'), ('include', 'VBP'), ('record', 'NN'), ('matching', 'VBG'), ('identifying', 'VBG'), ('inaccuracy', 'NN'), ('data', 'NNS'), ('overall', 'JJ'), ('quality', 'NN'), ('existing', 'VBG'), ('data', 'NNS'), ('deduplication', 'NN'), ('column', 'NN'), ('segmentation', 'NN'), ('data', 'NNS'), ('problems', 'NNS'), ('also', 'RB'), ('identified', 'VBD'), ('variety', 'NN'), ('analytical', 'JJ'), ('techniques', 'NNS'), ('example', 'NN'), ('financial', 'JJ'), ('information', 'NN'), ('totals', 'NNS'), ('particular', 'JJ'), ('variables', 'NNS'), ('may', 'MD'), ('compared', 'VBN'), ('separately', 'RB'), ('published', 'VBN'), ('numbers', 'NNS'), ('believed', 'VBN'), ('reliable', 'JJ'), ('Unusual', 'JJ'), ('amounts', 'NNS'), ('predetermined', 'VBN'), ('thresholds', 'NNS'), ('may', 'MD'), ('also', 'RB'), ('reviewed', 'VB'), ('several', 'JJ'), ('types', 'NNS'), ('data', 'NNS'), ('cleaning', 'NN'), ('dependent', 'JJ'), ('upon', 'IN'), ('type', 'JJ'), ('data', 'NNS'), ('set', 'NN'), ('could', 'MD'), ('phone', 'NN'), ('numbers', 'NNS'), ('email', 'VBP'), ('addresses', 'VBZ'), ('employers', 'NNS'), ('values', 'NNS'), ('Quantitative', 'NNP'), ('data', 'NNS'), ('methods', 'NNS'), ('outlier', 'JJR'), ('detection', 'NN'), ('used', 'VBN'), ('get', 'VB'), ('rid', 'JJ'), ('data', 'NNS'), ('appears', 'VBZ'), ('higher', 'JJR'), ('likelihood', 'NN'), ('input', 'NN'), ('incorrectly', 'RB'), ('Textual', 'NNP'), ('data', 'NN'), ('spell', 'NN'), ('checkers', 'NNS'), ('used', 'VBD'), ('lessen', 'JJ'), ('amount', 'NN'), ('mistyped', 'VBD'), ('words', 'NNS'), ('However', 'RB'), ('harder', 'VBP'), ('tell', 'NN'), ('words', 'NNS'), ('correct', 'VBP'), ('Exploratory', 'NNP'), ('data', 'NNS'), ('analysis', 'NN'), ('datasets', 'NNS'), ('cleaned', 'VBD'), ('analyzed', 'JJ'), ('Analysts', 'NNS'), ('may', 'MD'), ('apply', 'VB'), ('variety', 'NN'), ('techniques', 'NNS'), ('referred', 'VBD'), ('exploratory', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('begin', 'VBP'), ('understanding', 'VBG'), ('messages', 'NNS'), ('contained', 'VBN'), ('within', 'IN'), ('obtained', 'VBN'), ('data', 'NNS'), ('process', 'NN'), ('data', 'NNS'), ('exploration', 'NN'), ('may', 'MD'), ('result', 'VB'), ('additional', 'JJ'), ('data', 'NNS'), ('cleaning', 'VBG'), ('additional', 'JJ'), ('requests', 'NNS'), ('data', 'NNS'), ('thus', 'RB'), ('initialization', 'NN'), ('iterative', 'JJ'), ('phases', 'NNS'), ('mentioned', 'VBN'), ('lead', 'JJ'), ('paragraph', 'NN'), ('section', 'NN'), ('Descriptive', 'NNP'), ('statistics', 'NNS'), ('average', 'JJ'), ('median', 'JJ'), ('generated', 'VBN'), ('aid', 'NN'), ('understanding', 'VBG'), ('data', 'NNS'), ('Data', 'NNP'), ('visualization', 'NN'), ('also', 'RB'), ('technique', 'NN'), ('used', 'VBN'), ('analyst', 'NN'), ('able', 'JJ'), ('examine', 'NN'), ('data', 'NNS'), ('graphical', 'JJ'), ('format', 'JJ'), ('order', 'NN'), ('obtain', 'VB'), ('additional', 'JJ'), ('insights', 'NNS'), ('regarding', 'VBG'), ('messages', 'NNS'), ('within', 'IN'), ('data', 'NNS'), ('Modeling', 'VBG'), ('algorithms', 'JJ'), ('Mathematical', 'NNP'), ('formulas', 'NN'), ('models', 'NNS'), ('also', 'RB'), ('known', 'VBN'), ('algorithms', 'NN'), ('may', 'MD'), ('applied', 'VB'), ('data', 'NNS'), ('order', 'NN'), ('identify', 'JJ'), ('relationships', 'NNS'), ('among', 'IN'), ('variables', 'NNS'), ('example', 'NN'), ('using', 'VBG'), ('correlation', 'NN'), ('causation', 'NN'), ('general', 'JJ'), ('terms', 'NNS'), ('models', 'NNS'), ('may', 'MD'), ('developed', 'VB'), ('evaluate', 'VB'), ('specific', 'JJ'), ('variable', 'JJ'), ('based', 'VBN'), ('variable', 'JJ'), ('contained', 'VBN'), ('within', 'IN'), ('dataset', 'VBN'), ('residual', 'JJ'), ('error', 'NN'), ('depending', 'VBG'), ('implemented', 'VBN'), ('model', 'NN'), ('accuracy', 'NN'), ('Data', 'NNP'), ('Model', 'NNP'), ('Error', 'NNP'), ('Inferential', 'NNP'), ('statistics', 'NNS'), ('includes', 'VBZ'), ('utilizing', 'VBG'), ('techniques', 'NNS'), ('measure', 'NN'), ('relationships', 'VBZ'), ('particular', 'JJ'), ('variables', 'NNS'), ('example', 'NN'), ('regression', 'NN'), ('analysis', 'NN'), ('may', 'MD'), ('used', 'VBN'), ('model', 'NN'), ('whether', 'IN'), ('change', 'NN'), ('advertising', 'NN'), ('independent', 'JJ'), ('variable', 'JJ'), ('X', 'NNP'), ('provides', 'VBZ'), ('explanation', 'JJ'), ('variation', 'NN'), ('sales', 'NNS'), ('dependent', 'RBR'), ('variable', 'JJ'), ('mathematical', 'JJ'), ('terms', 'NNS'), ('sales', 'NNS'), ('function', 'NN'), ('X', 'IN'), ('advertising', 'NN'), ('may', 'MD'), ('described', 'VB'), ('aX', 'NN'), ('b', 'NN'), ('error', 'NN'), ('model', 'NN'), ('designed', 'VBN'), ('b', 'IN'), ('minimize', 'NN'), ('error', 'NN'), ('model', 'NN'), ('predicts', 'VBZ'), ('given', 'VBN'), ('range', 'NN'), ('values', 'NNS'), ('X', 'VBP'), ('Analysts', 'NNS'), ('may', 'MD'), ('also', 'RB'), ('attempt', 'VB'), ('build', 'JJ'), ('models', 'NNS'), ('descriptive', 'VBP'), ('data', 'NNS'), ('aim', 'NN'), ('simplify', 'NN'), ('analysis', 'NN'), ('communicate', 'NN'), ('results', 'NNS'), ('Data', 'NNP'), ('product', 'NN'), ('data', 'NNS'), ('product', 'NN'), ('computer', 'NN'), ('application', 'NN'), ('takes', 'VBZ'), ('data', 'NNS'), ('inputs', 'NNS'), ('generates', 'NNS'), ('outputs', 'VBP'), ('feeding', 'VBG'), ('back', 'RP'), ('environment', 'NN'), ('may', 'MD'), ('based', 'VBN'), ('model', 'NN'), ('algorithm', 'JJ'), ('instance', 'NN'), ('application', 'NN'), ('analyzes', 'VBZ'), ('data', 'NNS'), ('customer', 'NN'), ('purchase', 'NN'), ('history', 'NN'), ('uses', 'VBZ'), ('results', 'NNS'), ('recommend', 'VBP'), ('purchases', 'NNS'), ('customer', 'NN'), ('might', 'MD'), ('enjoy', 'VB'), ('Communication', 'NNP'), ('Data', 'NNP'), ('visualization', 'NN'), ('used', 'VBN'), ('help', 'NN'), ('understand', 'VB'), ('results', 'NNS'), ('data', 'NNS'), ('analyzed', 'VBD'), ('Main', 'NNP'), ('article', 'NN'), ('Data', 'NNP'), ('information', 'NN'), ('visualization', 'NN'), ('data', 'NNS'), ('analyzed', 'VBN'), ('may', 'MD'), ('reported', 'VBD'), ('many', 'JJ'), ('formats', 'NNS'), ('users', 'NNS'), ('analysis', 'VBP'), ('support', 'NN'), ('requirements', 'NNS'), ('users', 'NNS'), ('may', 'MD'), ('feedback', 'VB'), ('results', 'NNS'), ('additional', 'JJ'), ('analysis', 'NN'), ('much', 'JJ'), ('analytical', 'JJ'), ('cycle', 'NN'), ('iterative', 'JJ'), ('determining', 'VBG'), ('communicate', 'JJ'), ('results', 'NNS'), ('analyst', 'NN'), ('may', 'MD'), ('consider', 'VB'), ('implementing', 'VBG'), ('variety', 'NN'), ('data', 'NNS'), ('visualization', 'NN'), ('techniques', 'NNS'), ('help', 'VBP'), ('communicate', 'VB'), ('message', 'NN'), ('clearly', 'RB'), ('efficiently', 'RB'), ('audience', 'NN'), ('Data', 'NNP'), ('visualization', 'NN'), ('uses', 'VBZ'), ('information', 'NN'), ('displays', 'NNS'), ('graphics', 'NNS'), ('tables', 'NNS'), ('charts', 'NNS'), ('help', 'VBP'), ('communicate', 'VB'), ('key', 'JJ'), ('messages', 'NNS'), ('contained', 'VBN'), ('data', 'NNS'), ('Tables', 'NNP'), ('valuable', 'JJ'), ('tool', 'NN'), ('enabling', 'VBG'), ('ability', 'NN'), ('user', 'RB'), ('query', 'RB'), ('focus', 'VB'), ('specific', 'JJ'), ('numbers', 'NNS'), ('charts', 'VBP'), ('bar', 'NN'), ('charts', 'NNS'), ('line', 'NN'), ('charts', 'NNS'), ('may', 'MD'), ('help', 'VB'), ('explain', 'VB'), ('quantitative', 'JJ'), ('messages', 'NNS'), ('contained', 'VBN'), ('data', 'NNS'), ('Quantitative', 'NNP'), ('messages', 'NNS'), ('Main', 'NNP'), ('article', 'NN'), ('Data', 'NNP'), ('information', 'NN'), ('visualization', 'NN'), ('time', 'NN'), ('series', 'NN'), ('illustrated', 'VBD'), ('line', 'NN'), ('chart', 'NN'), ('demonstrating', 'VBG'), ('trends', 'NNS'), ('federal', 'JJ'), ('spending', 'NN'), ('revenue', 'NN'), ('time', 'NN'), ('scatterplot', 'NN'), ('illustrating', 'VBG'), ('correlation', 'NN'), ('two', 'CD'), ('variables', 'NNS'), ('inflation', 'NN'), ('unemployment', 'NN'), ('measured', 'VBD'), ('points', 'NNS'), ('time', 'NN'), ('Stephen', 'NNP'), ('described', 'VBD'), ('eight', 'CD'), ('types', 'NNS'), ('quantitative', 'JJ'), ('messages', 'NNS'), ('users', 'NNS'), ('may', 'MD'), ('attempt', 'VB'), ('understand', 'JJ'), ('communicate', 'NN'), ('set', 'VBN'), ('data', 'NNS'), ('associated', 'VBD'), ('graphs', 'NN'), ('used', 'VBN'), ('help', 'NN'), ('communicate', 'VB'), ('message', 'NN'), ('Customers', 'NNPS'), ('specifying', 'VBG'), ('requirements', 'NNS'), ('analysts', 'NNS'), ('performing', 'VBG'), ('data', 'NNS'), ('analysis', 'NN'), ('may', 'MD'), ('consider', 'VB'), ('messages', 'NNS'), ('course', 'NN'), ('process', 'NN'), ('single', 'JJ'), ('variable', 'JJ'), ('captured', 'JJ'), ('period', 'NN'), ('time', 'NN'), ('unemployment', 'NN'), ('rate', 'NN'), ('period', 'NN'), ('line', 'NN'), ('chart', 'NN'), ('may', 'MD'), ('used', 'VBN'), ('demonstrate', 'VB'), ('trend', 'NN'), ('Ranking', 'NNP'), ('Categorical', 'NNP'), ('subdivisions', 'NNS'), ('ranked', 'VBD'), ('ascending', 'VBG'), ('descending', 'VBG'), ('order', 'NN'), ('ranking', 'VBG'), ('sales', 'NNS'), ('performance', 'NN'), ('measure', 'NN'), ('salespersons', 'NNS'), ('category', 'NN'), ('salesperson', 'NN'), ('categorical', 'JJ'), ('subdivision', 'NN'), ('single', 'JJ'), ('period', 'NN'), ('bar', 'IN'), ('chart', 'NN'), ('may', 'MD'), ('used', 'VBD'), ('show', 'VB'), ('comparison', 'JJ'), ('across', 'IN'), ('salespersons', 'NNS'), ('Categorical', 'NNP'), ('subdivisions', 'NNS'), ('measured', 'VBD'), ('ratio', 'JJ'), ('whole', 'JJ'), ('percentage', 'NN'), ('pie', 'NN'), ('chart', 'NN'), ('bar', 'NN'), ('chart', 'NN'), ('show', 'NN'), ('comparison', 'JJ'), ('ratios', 'NNS'), ('market', 'NN'), ('share', 'NN'), ('represented', 'VBN'), ('competitors', 'NNS'), ('market', 'NN'), ('Deviation', 'NNP'), ('Categorical', 'NNP'), ('subdivisions', 'NNS'), ('compared', 'VBN'), ('reference', 'NN'), ('comparison', 'NN'), ('actual', 'JJ'), ('budget', 'NN'), ('expenses', 'NNS'), ('several', 'JJ'), ('departments', 'NNS'), ('business', 'NN'), ('given', 'VBN'), ('time', 'NN'), ('period', 'NN'), ('bar', 'IN'), ('chart', 'NN'), ('show', 'NN'), ('comparison', 'NN'), ('actual', 'JJ'), ('versus', 'NN'), ('reference', 'NN'), ('amount', 'NN'), ('Frequency', 'NNP'), ('distribution', 'NN'), ('Shows', 'NNP'), ('number', 'NN'), ('observations', 'NNS'), ('particular', 'JJ'), ('variable', 'JJ'), ('given', 'VBN'), ('interval', 'JJ'), ('number', 'NN'), ('years', 'NNS'), ('stock', 'NN'), ('market', 'NN'), ('return', 'NN'), ('intervals', 'NNS'), ('etc', 'VBP'), ('histogram', 'JJ'), ('type', 'NN'), ('bar', 'NN'), ('chart', 'NN'), ('may', 'MD'), ('used', 'VBN'), ('analysis', 'NN'), ('Correlation', 'NNP'), ('Comparison', 'NNP'), ('observations', 'NNS'), ('represented', 'VBD'), ('two', 'CD'), ('variables', 'NNS'), ('X', 'VBP'), ('determine', 'JJ'), ('tend', 'VBP'), ('move', 'NN'), ('opposite', 'JJ'), ('directions', 'NNS'), ('example', 'NN'), ('plotting', 'VBG'), ('unemployment', 'NN'), ('X', 'NNP'), ('inflation', 'NN'), ('sample', 'JJ'), ('months', 'NNS'), ('scatter', 'NN'), ('plot', 'NN'), ('typically', 'RB'), ('used', 'JJ'), ('message', 'NN'), ('Nominal', 'NNP'), ('comparison', 'NN'), ('Comparing', 'NNP'), ('categorical', 'JJ'), ('subdivisions', 'NNS'), ('particular', 'JJ'), ('order', 'NN'), ('sales', 'NNS'), ('volume', 'NN'), ('product', 'NN'), ('code', 'NN'), ('bar', 'IN'), ('chart', 'NN'), ('may', 'MD'), ('used', 'VBN'), ('comparison', 'NN'), ('Geographic', 'NNP'), ('geospatial', 'JJ'), ('Comparison', 'NNP'), ('variable', 'JJ'), ('across', 'IN'), ('map', 'NN'), ('layout', 'NN'), ('unemployment', 'NN'), ('rate', 'NN'), ('state', 'NN'), ('number', 'NN'), ('persons', 'NNS'), ('various', 'JJ'), ('floors', 'NNS'), ('building', 'VBG'), ('cartogram', 'NN'), ('typical', 'JJ'), ('graphic', 'NN'), ('used', 'VBN'), ('Techniques', 'NNP'), ('analyzing', 'VBG'), ('quantitative', 'JJ'), ('data', 'NNS'), ('See', 'NNP'), ('also', 'RB'), ('Problem', 'NNP'), ('solving', 'VBG'), ('Author', 'NNP'), ('Jonathan', 'NNP'), ('Koomey', 'NNP'), ('recommended', 'VBD'), ('series', 'NN'), ('best', 'JJS'), ('practices', 'NNS'), ('understanding', 'VBG'), ('quantitative', 'JJ'), ('data', 'NNS'), ('include', 'VBP'), ('Check', 'NNP'), ('raw', 'JJ'), ('data', 'NN'), ('anomalies', 'NNS'), ('prior', 'RB'), ('performing', 'VBG'), ('analysis', 'NN'), ('important', 'JJ'), ('calculations', 'NNS'), ('verifying', 'VBG'), ('columns', 'NN'), ('data', 'NNS'), ('formula', 'NN'), ('driven', 'VBN'), ('Confirm', 'NNP'), ('main', 'JJ'), ('totals', 'NNS'), ('sum', 'VBP'), ('subtotals', 'NNS'), ('Check', 'NNP'), ('relationships', 'NNS'), ('numbers', 'NNS'), ('related', 'VBN'), ('predictable', 'JJ'), ('way', 'NN'), ('ratios', 'NNS'), ('time', 'NN'), ('Normalize', 'NNP'), ('numbers', 'NNS'), ('make', 'VBP'), ('comparisons', 'NNS'), ('easier', 'RBR'), ('analyzing', 'VBG'), ('amounts', 'NNS'), ('per', 'IN'), ('person', 'NN'), ('relative', 'JJ'), ('GDP', 'NNP'), ('index', 'NN'), ('value', 'NN'), ('relative', 'JJ'), ('base', 'NN'), ('year', 'NN'), ('Break', 'NNP'), ('problems', 'NNS'), ('component', 'JJ'), ('parts', 'NNS'), ('analyzing', 'VBG'), ('factors', 'NNS'), ('led', 'VBD'), ('results', 'NNS'), ('DuPont', 'NNP'), ('analysis', 'NN'), ('return', 'NN'), ('equity', 'NN'), ('variables', 'NNS'), ('examination', 'NN'), ('analysts', 'NNS'), ('typically', 'RB'), ('obtain', 'VB'), ('descriptive', 'JJ'), ('statistics', 'NNS'), ('mean', 'JJ'), ('average', 'JJ'), ('median', 'JJ'), ('standard', 'NN'), ('deviation', 'NN'), ('may', 'MD'), ('also', 'RB'), ('analyze', 'VB'), ('distribution', 'NN'), ('key', 'JJ'), ('variables', 'NNS'), ('see', 'VBP'), ('individual', 'JJ'), ('values', 'NNS'), ('cluster', 'VBP'), ('around', 'IN'), ('mean', 'JJ'), ('illustration', 'NN'), ('MECE', 'NNP'), ('principle', 'NN'), ('used', 'VBN'), ('data', 'NNS'), ('analysis', 'NN'), ('consultants', 'NNS'), ('McKinsey', 'NNP'), ('Company', 'NNP'), ('named', 'VBD'), ('technique', 'NN'), ('breaking', 'VBG'), ('quantitative', 'JJ'), ('problem', 'NN'), ('component', 'NN'), ('parts', 'NNS'), ('called', 'VBD'), ('MECE', 'NNP'), ('principle', 'NN'), ('layer', 'NN'), ('broken', 'JJ'), ('components', 'NNS'), ('must', 'MD'), ('mutually', 'RB'), ('exclusive', 'JJ'), ('collectively', 'RB'), ('add', 'VBP'), ('layer', 'JJ'), ('relationship', 'NN'), ('referred', 'VBD'), ('Mutually', 'NNP'), ('Exclusive', 'NNP'), ('Collectively', 'NNP'), ('Exhaustive', 'NNP'), ('MECE', 'NNP'), ('example', 'NN'), ('profit', 'NN'), ('definition', 'NN'), ('broken', 'VBN'), ('total', 'JJ'), ('revenue', 'NN'), ('total', 'JJ'), ('cost', 'NN'), ('turn', 'VBP'), ('total', 'JJ'), ('revenue', 'NN'), ('analyzed', 'VBD'), ('components', 'NNS'), ('revenue', 'NN'), ('divisions', 'NNS'), ('B', 'NNP'), ('C', 'NNP'), ('mutually', 'RB'), ('exclusive', 'JJ'), ('add', 'VBP'), ('total', 'JJ'), ('revenue', 'NN'), ('collectively', 'RB'), ('exhaustive', 'JJ'), ('Analysts', 'NNS'), ('may', 'MD'), ('use', 'VB'), ('robust', 'JJ'), ('statistical', 'JJ'), ('measurements', 'NNS'), ('solve', 'VBP'), ('certain', 'JJ'), ('analytical', 'JJ'), ('problems', 'NNS'), ('Hypothesis', 'NNP'), ('testing', 'VBG'), ('used', 'VBN'), ('particular', 'JJ'), ('hypothesis', 'NN'), ('true', 'JJ'), ('state', 'NN'), ('affairs', 'NNS'), ('made', 'VBD'), ('analyst', 'NN'), ('data', 'NNS'), ('gathered', 'VBD'), ('determine', 'NN'), ('whether', 'IN'), ('state', 'NN'), ('affairs', 'NNS'), ('true', 'JJ'), ('false', 'JJ'), ('example', 'NN'), ('hypothesis', 'NN'), ('might', 'MD'), ('Unemployment', 'VB'), ('effect', 'NN'), ('inflation', 'NN'), ('relates', 'VBZ'), ('economics', 'NNS'), ('concept', 'NN'), ('called', 'VBN'), ('Phillips', 'NNP'), ('Curve', 'NNP'), ('Hypothesis', 'NNP'), ('testing', 'VBG'), ('involves', 'NNS'), ('considering', 'VBG'), ('likelihood', 'NN'), ('Type', 'NNP'), ('type', 'NN'), ('II', 'NNP'), ('errors', 'NNS'), ('relate', 'VBP'), ('whether', 'IN'), ('data', 'NNS'), ('supports', 'NNS'), ('accepting', 'VBG'), ('rejecting', 'VBG'), ('hypothesis', 'NN'), ('Regression', 'NNP'), ('analysis', 'NN'), ('may', 'MD'), ('used', 'VBN'), ('analyst', 'NN'), ('trying', 'VBG'), ('determine', 'JJ'), ('extent', 'NN'), ('independent', 'JJ'), ('variable', 'JJ'), ('X', 'NN'), ('affects', 'NNS'), ('dependent', 'JJ'), ('variable', 'JJ'), ('extent', 'NN'), ('changes', 'NNS'), ('unemployment', 'NN'), ('rate', 'NN'), ('X', 'NNP'), ('affect', 'CC'), ('inflation', 'NN'), ('rate', 'NN'), ('attempt', 'NN'), ('model', 'NN'), ('fit', 'JJ'), ('equation', 'NN'), ('line', 'NN'), ('curve', 'NN'), ('data', 'NNS'), ('function', 'NN'), ('X', 'NNP'), ('Necessary', 'NNP'), ('condition', 'NN'), ('analysis', 'NN'), ('NCA', 'NNP'), ('may', 'MD'), ('used', 'VBN'), ('analyst', 'NN'), ('trying', 'VBG'), ('determine', 'JJ'), ('extent', 'NN'), ('independent', 'JJ'), ('variable', 'JJ'), ('X', 'NN'), ('allows', 'VBZ'), ('variable', 'JJ'), ('extent', 'NN'), ('certain', 'JJ'), ('unemployment', 'NN'), ('rate', 'NN'), ('X', 'NNP'), ('necessary', 'JJ'), ('certain', 'JJ'), ('inflation', 'NN'), ('rate', 'NN'), ('Whereas', 'NNP'), ('multiple', 'NN'), ('regression', 'NN'), ('analysis', 'NN'), ('uses', 'VBZ'), ('additive', 'JJ'), ('logic', 'JJ'), ('produce', 'VBP'), ('outcome', 'JJ'), ('X', 'NNP'), ('compensate', 'NN'), ('sufficient', 'JJ'), ('necessary', 'JJ'), ('necessary', 'JJ'), ('condition', 'NN'), ('analysis', 'NN'), ('NCA', 'NNP'), ('uses', 'VBZ'), ('necessity', 'NN'), ('logic', 'JJ'), ('one', 'CD'), ('allow', 'JJ'), ('outcome', 'NN'), ('exist', 'NN'), ('may', 'MD'), ('produce', 'VB'), ('necessary', 'JJ'), ('sufficient', 'JJ'), ('single', 'JJ'), ('necessary', 'JJ'), ('condition', 'NN'), ('must', 'MD'), ('present', 'VB'), ('compensation', 'NN'), ('possible', 'JJ')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_named_entity_recognition(pos_tags):\n",
        "    return ne_chunk(pos_tags)\n",
        "named_entities = perform_named_entity_recognition(pos_tags)\n",
        "print(\"Named Entities:\", named_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iygfbcBSdM4o",
        "outputId": "88c404d6-0bba-435d-9285-c3330e9a1b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities: (S\n",
            "  (GPE Data/NNP)\n",
            "  analysis/NN\n",
            "  process/NN\n",
            "  inspecting/VBG\n",
            "  cleansing/VBG\n",
            "  transforming/VBG\n",
            "  modeling/VBG\n",
            "  data/NNS\n",
            "  goal/NN\n",
            "  discovering/VBG\n",
            "  useful/JJ\n",
            "  information/NN\n",
            "  informing/VBG\n",
            "  conclusions/NNS\n",
            "  supporting/VBG\n",
            "  (PERSON Data/NNP)\n",
            "  analysis/NN\n",
            "  multiple/JJ\n",
            "  facets/NNS\n",
            "  approaches/VBZ\n",
            "  encompassing/VBG\n",
            "  diverse/NN\n",
            "  techniques/NNS\n",
            "  variety/NN\n",
            "  names/NNS\n",
            "  used/VBN\n",
            "  different/JJ\n",
            "  business/NN\n",
            "  science/NN\n",
            "  social/JJ\n",
            "  science/NN\n",
            "  domains/NNS\n",
            "  today/NN\n",
            "  business/NN\n",
            "  world/NN\n",
            "  data/NN\n",
            "  analysis/NN\n",
            "  plays/VBZ\n",
            "  role/NN\n",
            "  making/NN\n",
            "  decisions/NNS\n",
            "  scientific/JJ\n",
            "  helping/VBG\n",
            "  businesses/NNS\n",
            "  operate/VBP\n",
            "  effectively/RB\n",
            "  (PERSON Data/NNP)\n",
            "  mining/NN\n",
            "  particular/JJ\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  technique/NN\n",
            "  focuses/VBZ\n",
            "  statistical/JJ\n",
            "  modeling/VBG\n",
            "  knowledge/NN\n",
            "  discovery/NN\n",
            "  predictive/VBP\n",
            "  rather/RB\n",
            "  purely/RB\n",
            "  descriptive/JJ\n",
            "  purposes/NNS\n",
            "  business/NN\n",
            "  intelligence/NN\n",
            "  covers/VBZ\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  relies/NNS\n",
            "  heavily/RB\n",
            "  aggregation/VBP\n",
            "  focusing/VBG\n",
            "  mainly/RB\n",
            "  business/NN\n",
            "  information/NN\n",
            "  statistical/JJ\n",
            "  applications/NNS\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  divided/VBD\n",
            "  descriptive/JJ\n",
            "  statistics/NNS\n",
            "  exploratory/JJ\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  (ORGANIZATION EDA/NNP)\n",
            "  confirmatory/NN\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  (ORGANIZATION CDA/NNP)\n",
            "  EDA/NNP\n",
            "  focuses/VBZ\n",
            "  discovering/VBG\n",
            "  new/JJ\n",
            "  features/NNS\n",
            "  data/VBP\n",
            "  (ORGANIZATION CDA/NNP)\n",
            "  focuses/VBZ\n",
            "  confirming/VBG\n",
            "  falsifying/VBG\n",
            "  existing/VBG\n",
            "  hypotheses/NNS\n",
            "  Predictive/NNP\n",
            "  analytics/NNS\n",
            "  focuses/VBZ\n",
            "  application/NN\n",
            "  statistical/JJ\n",
            "  models/NNS\n",
            "  predictive/VBP\n",
            "  forecasting/VBG\n",
            "  classification/NN\n",
            "  text/NN\n",
            "  analytics/NNS\n",
            "  applies/VBZ\n",
            "  statistical/JJ\n",
            "  linguistic/JJ\n",
            "  structural/JJ\n",
            "  techniques/NNS\n",
            "  extract/VBP\n",
            "  classify/JJ\n",
            "  information/NN\n",
            "  textual/JJ\n",
            "  sources/NNS\n",
            "  species/NNS\n",
            "  unstructured/VBD\n",
            "  data/NNS\n",
            "  varieties/NNS\n",
            "  data/VBP\n",
            "  analysis/NN\n",
            "  (PERSON Data/NNP)\n",
            "  integration/NN\n",
            "  precursor/NN\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  closely/RB\n",
            "  linked/VBN\n",
            "  data/NNS\n",
            "  visualization/NN\n",
            "  data/NNS\n",
            "  process/NN\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  (PERSON Data/NNP)\n",
            "  science/NN\n",
            "  process/NN\n",
            "  flowchart/NN\n",
            "  (PERSON Data/NNP Science/NNP Schutt/NNP Analysis/NNP)\n",
            "  refers/NNS\n",
            "  dividing/VBG\n",
            "  whole/JJ\n",
            "  separate/JJ\n",
            "  components/NNS\n",
            "  individual/JJ\n",
            "  examination/NN\n",
            "  (PERSON Data/NNP)\n",
            "  analysis/NN\n",
            "  process/NN\n",
            "  obtaining/VBG\n",
            "  raw/JJ\n",
            "  data/NNS\n",
            "  subsequently/RB\n",
            "  converting/VBG\n",
            "  information/NN\n",
            "  useful/JJ\n",
            "  users/NNS\n",
            "  (PERSON Data/NNP)\n",
            "  collected/VBD\n",
            "  analyzed/JJ\n",
            "  answer/NN\n",
            "  questions/NNS\n",
            "  test/VBP\n",
            "  hypotheses/NNS\n",
            "  disprove/VB\n",
            "  theories/NNS\n",
            "  (PERSON Statistician/NNP John/NNP Tukey/NNP)\n",
            "  defined/VBD\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  Procedures/NNS\n",
            "  analyzing/VBG\n",
            "  data/NNS\n",
            "  techniques/NNS\n",
            "  interpreting/VBG\n",
            "  results/NNS\n",
            "  procedures/NNS\n",
            "  ways/NNS\n",
            "  planning/VBG\n",
            "  gathering/NN\n",
            "  data/NNS\n",
            "  make/VBP\n",
            "  analysis/NN\n",
            "  easier/JJR\n",
            "  precise/JJ\n",
            "  accurate/JJ\n",
            "  machinery/NN\n",
            "  results/NNS\n",
            "  mathematical/JJ\n",
            "  statistics/NNS\n",
            "  apply/VBP\n",
            "  analyzing/VBG\n",
            "  data/NNS\n",
            "  several/JJ\n",
            "  phases/NNS\n",
            "  distinguished/VBN\n",
            "  described/JJ\n",
            "  phases/NNS\n",
            "  iterative/JJ\n",
            "  feedback/NN\n",
            "  later/RBR\n",
            "  phases/NNS\n",
            "  may/MD\n",
            "  result/VB\n",
            "  additional/JJ\n",
            "  work/NN\n",
            "  earlier/RBR\n",
            "  phases/NNS\n",
            "  CRISP/NNP\n",
            "  framework/NN\n",
            "  used/VBN\n",
            "  data/NNS\n",
            "  mining/NN\n",
            "  similar/JJ\n",
            "  steps/NNS\n",
            "  Data/NNP\n",
            "  requirements/NNS\n",
            "  data/NNS\n",
            "  necessary/JJ\n",
            "  inputs/NNS\n",
            "  analysis/NN\n",
            "  specified/VBN\n",
            "  based/VBN\n",
            "  upon/IN\n",
            "  requirements/NNS\n",
            "  directing/VBG\n",
            "  analytics/NNS\n",
            "  customers/NNS\n",
            "  use/VBP\n",
            "  finished/JJ\n",
            "  product/NN\n",
            "  analysis/NN\n",
            "  general/JJ\n",
            "  type/NN\n",
            "  entity/NN\n",
            "  upon/IN\n",
            "  data/NNS\n",
            "  collected/VBN\n",
            "  referred/JJ\n",
            "  experimental/JJ\n",
            "  unit/NN\n",
            "  person/NN\n",
            "  population/NN\n",
            "  people/NNS\n",
            "  Specific/NNP\n",
            "  variables/VBZ\n",
            "  regarding/VBG\n",
            "  population/NN\n",
            "  age/NN\n",
            "  income/NN\n",
            "  may/MD\n",
            "  specified/VB\n",
            "  obtained/VBN\n",
            "  (PERSON Data/NNP)\n",
            "  may/MD\n",
            "  numerical/JJ\n",
            "  categorical/JJ\n",
            "  text/NN\n",
            "  label/NN\n",
            "  numbers/NNS\n",
            "  (PERSON Data/NNP)\n",
            "  collection/NN\n",
            "  (PERSON Data/NNP)\n",
            "  collected/VBD\n",
            "  variety/NN\n",
            "  sources/NNS\n",
            "  list/NN\n",
            "  data/NNS\n",
            "  sources/NNS\n",
            "  available/JJ\n",
            "  study/NN\n",
            "  research/NN\n",
            "  requirements/NNS\n",
            "  may/MD\n",
            "  communicated/VB\n",
            "  analysts/NNS\n",
            "  custodians/VBZ\n",
            "  data/JJ\n",
            "  Information/NNP\n",
            "  Technology/NNP\n",
            "  personnel/NNS\n",
            "  within/IN\n",
            "  organization/NN\n",
            "  (PERSON Data/NNP)\n",
            "  collection/NN\n",
            "  data/NNS\n",
            "  gathering/NN\n",
            "  process/NN\n",
            "  gathering/VBG\n",
            "  measuring/VBG\n",
            "  information/NN\n",
            "  targeted/VBD\n",
            "  variables/NNS\n",
            "  established/VBN\n",
            "  system/NN\n",
            "  enables/VBZ\n",
            "  one/CD\n",
            "  answer/NN\n",
            "  relevant/JJ\n",
            "  questions/NNS\n",
            "  evaluate/VBP\n",
            "  outcomes/NNS\n",
            "  data/NNS\n",
            "  may/MD\n",
            "  also/RB\n",
            "  collected/VBN\n",
            "  sensors/NNS\n",
            "  environment/NN\n",
            "  including/VBG\n",
            "  traffic/NN\n",
            "  cameras/NNS\n",
            "  satellites/VBZ\n",
            "  recording/VBG\n",
            "  devices/NNS\n",
            "  etc/NN\n",
            "  may/MD\n",
            "  also/RB\n",
            "  obtained/VBN\n",
            "  interviews/NNS\n",
            "  downloads/NNS\n",
            "  online/JJ\n",
            "  sources/NNS\n",
            "  reading/VBG\n",
            "  documentation/NN\n",
            "  (PERSON Data/NNP)\n",
            "  processing/NN\n",
            "  phases/NNS\n",
            "  intelligence/NN\n",
            "  cycle/NN\n",
            "  used/VBN\n",
            "  convert/JJ\n",
            "  raw/JJ\n",
            "  information/NN\n",
            "  actionable/JJ\n",
            "  intelligence/NN\n",
            "  knowledge/NN\n",
            "  conceptually/RB\n",
            "  similar/JJ\n",
            "  phases/NNS\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  (PERSON Data/NNP)\n",
            "  initially/RB\n",
            "  obtained/VBD\n",
            "  must/MD\n",
            "  processed/VBN\n",
            "  organized/VBN\n",
            "  analysis/NN\n",
            "  instance/NN\n",
            "  may/MD\n",
            "  involve/VB\n",
            "  placing/VBG\n",
            "  data/NNS\n",
            "  rows/NNS\n",
            "  columns/VBP\n",
            "  table/JJ\n",
            "  format/NN\n",
            "  known/VBN\n",
            "  structured/VBN\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  often/RB\n",
            "  use/JJ\n",
            "  spreadsheet/JJ\n",
            "  statistical/JJ\n",
            "  software/NN\n",
            "  (PERSON Data/NNP)\n",
            "  cleaning/NN\n",
            "  (GPE Main/NNP)\n",
            "  article/NN\n",
            "  (PERSON Data/NNP)\n",
            "  cleansing/NN\n",
            "  processed/VBD\n",
            "  organized/VBN\n",
            "  data/NNS\n",
            "  may/MD\n",
            "  incomplete/VB\n",
            "  contain/NN\n",
            "  duplicates/NNS\n",
            "  contain/VBP\n",
            "  errors/NNS\n",
            "  need/VBP\n",
            "  data/NNS\n",
            "  cleaning/VBG\n",
            "  arise/NN\n",
            "  problems/NNS\n",
            "  way/NN\n",
            "  datum/NN\n",
            "  entered/VBD\n",
            "  stored/VBN\n",
            "  (PERSON Data/NNP)\n",
            "  cleaning/NN\n",
            "  process/NN\n",
            "  preventing/VBG\n",
            "  correcting/VBG\n",
            "  errors/NNS\n",
            "  (ORGANIZATION Common/NNP)\n",
            "  tasks/NNS\n",
            "  include/VBP\n",
            "  record/NN\n",
            "  matching/VBG\n",
            "  identifying/VBG\n",
            "  inaccuracy/NN\n",
            "  data/NNS\n",
            "  overall/JJ\n",
            "  quality/NN\n",
            "  existing/VBG\n",
            "  data/NNS\n",
            "  deduplication/NN\n",
            "  column/NN\n",
            "  segmentation/NN\n",
            "  data/NNS\n",
            "  problems/NNS\n",
            "  also/RB\n",
            "  identified/VBD\n",
            "  variety/NN\n",
            "  analytical/JJ\n",
            "  techniques/NNS\n",
            "  example/NN\n",
            "  financial/JJ\n",
            "  information/NN\n",
            "  totals/NNS\n",
            "  particular/JJ\n",
            "  variables/NNS\n",
            "  may/MD\n",
            "  compared/VBN\n",
            "  separately/RB\n",
            "  published/VBN\n",
            "  numbers/NNS\n",
            "  believed/VBN\n",
            "  reliable/JJ\n",
            "  Unusual/JJ\n",
            "  amounts/NNS\n",
            "  predetermined/VBN\n",
            "  thresholds/NNS\n",
            "  may/MD\n",
            "  also/RB\n",
            "  reviewed/VB\n",
            "  several/JJ\n",
            "  types/NNS\n",
            "  data/NNS\n",
            "  cleaning/NN\n",
            "  dependent/JJ\n",
            "  upon/IN\n",
            "  type/JJ\n",
            "  data/NNS\n",
            "  set/NN\n",
            "  could/MD\n",
            "  phone/NN\n",
            "  numbers/NNS\n",
            "  email/VBP\n",
            "  addresses/VBZ\n",
            "  employers/NNS\n",
            "  values/NNS\n",
            "  Quantitative/NNP\n",
            "  data/NNS\n",
            "  methods/NNS\n",
            "  outlier/JJR\n",
            "  detection/NN\n",
            "  used/VBN\n",
            "  get/VB\n",
            "  rid/JJ\n",
            "  data/NNS\n",
            "  appears/VBZ\n",
            "  higher/JJR\n",
            "  likelihood/NN\n",
            "  input/NN\n",
            "  incorrectly/RB\n",
            "  (GPE Textual/NNP)\n",
            "  data/NN\n",
            "  spell/NN\n",
            "  checkers/NNS\n",
            "  used/VBD\n",
            "  lessen/JJ\n",
            "  amount/NN\n",
            "  mistyped/VBD\n",
            "  words/NNS\n",
            "  However/RB\n",
            "  harder/VBP\n",
            "  tell/NN\n",
            "  words/NNS\n",
            "  correct/VBP\n",
            "  Exploratory/NNP\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  datasets/NNS\n",
            "  cleaned/VBD\n",
            "  analyzed/JJ\n",
            "  Analysts/NNS\n",
            "  may/MD\n",
            "  apply/VB\n",
            "  variety/NN\n",
            "  techniques/NNS\n",
            "  referred/VBD\n",
            "  exploratory/JJ\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  begin/VBP\n",
            "  understanding/VBG\n",
            "  messages/NNS\n",
            "  contained/VBN\n",
            "  within/IN\n",
            "  obtained/VBN\n",
            "  data/NNS\n",
            "  process/NN\n",
            "  data/NNS\n",
            "  exploration/NN\n",
            "  may/MD\n",
            "  result/VB\n",
            "  additional/JJ\n",
            "  data/NNS\n",
            "  cleaning/VBG\n",
            "  additional/JJ\n",
            "  requests/NNS\n",
            "  data/NNS\n",
            "  thus/RB\n",
            "  initialization/NN\n",
            "  iterative/JJ\n",
            "  phases/NNS\n",
            "  mentioned/VBN\n",
            "  lead/JJ\n",
            "  paragraph/NN\n",
            "  section/NN\n",
            "  Descriptive/NNP\n",
            "  statistics/NNS\n",
            "  average/JJ\n",
            "  median/JJ\n",
            "  generated/VBN\n",
            "  aid/NN\n",
            "  understanding/VBG\n",
            "  data/NNS\n",
            "  (PERSON Data/NNP)\n",
            "  visualization/NN\n",
            "  also/RB\n",
            "  technique/NN\n",
            "  used/VBN\n",
            "  analyst/NN\n",
            "  able/JJ\n",
            "  examine/NN\n",
            "  data/NNS\n",
            "  graphical/JJ\n",
            "  format/JJ\n",
            "  order/NN\n",
            "  obtain/VB\n",
            "  additional/JJ\n",
            "  insights/NNS\n",
            "  regarding/VBG\n",
            "  messages/NNS\n",
            "  within/IN\n",
            "  data/NNS\n",
            "  Modeling/VBG\n",
            "  algorithms/JJ\n",
            "  Mathematical/NNP\n",
            "  formulas/NN\n",
            "  models/NNS\n",
            "  also/RB\n",
            "  known/VBN\n",
            "  algorithms/NN\n",
            "  may/MD\n",
            "  applied/VB\n",
            "  data/NNS\n",
            "  order/NN\n",
            "  identify/JJ\n",
            "  relationships/NNS\n",
            "  among/IN\n",
            "  variables/NNS\n",
            "  example/NN\n",
            "  using/VBG\n",
            "  correlation/NN\n",
            "  causation/NN\n",
            "  general/JJ\n",
            "  terms/NNS\n",
            "  models/NNS\n",
            "  may/MD\n",
            "  developed/VB\n",
            "  evaluate/VB\n",
            "  specific/JJ\n",
            "  variable/JJ\n",
            "  based/VBN\n",
            "  variable/JJ\n",
            "  contained/VBN\n",
            "  within/IN\n",
            "  dataset/VBN\n",
            "  residual/JJ\n",
            "  error/NN\n",
            "  depending/VBG\n",
            "  implemented/VBN\n",
            "  model/NN\n",
            "  accuracy/NN\n",
            "  (PERSON Data/NNP Model/NNP Error/NNP)\n",
            "  Inferential/NNP\n",
            "  statistics/NNS\n",
            "  includes/VBZ\n",
            "  utilizing/VBG\n",
            "  techniques/NNS\n",
            "  measure/NN\n",
            "  relationships/VBZ\n",
            "  particular/JJ\n",
            "  variables/NNS\n",
            "  example/NN\n",
            "  regression/NN\n",
            "  analysis/NN\n",
            "  may/MD\n",
            "  used/VBN\n",
            "  model/NN\n",
            "  whether/IN\n",
            "  change/NN\n",
            "  advertising/NN\n",
            "  independent/JJ\n",
            "  variable/JJ\n",
            "  X/NNP\n",
            "  provides/VBZ\n",
            "  explanation/JJ\n",
            "  variation/NN\n",
            "  sales/NNS\n",
            "  dependent/RBR\n",
            "  variable/JJ\n",
            "  mathematical/JJ\n",
            "  terms/NNS\n",
            "  sales/NNS\n",
            "  function/NN\n",
            "  X/IN\n",
            "  advertising/NN\n",
            "  may/MD\n",
            "  described/VB\n",
            "  aX/NN\n",
            "  b/NN\n",
            "  error/NN\n",
            "  model/NN\n",
            "  designed/VBN\n",
            "  b/IN\n",
            "  minimize/NN\n",
            "  error/NN\n",
            "  model/NN\n",
            "  predicts/VBZ\n",
            "  given/VBN\n",
            "  range/NN\n",
            "  values/NNS\n",
            "  X/VBP\n",
            "  Analysts/NNS\n",
            "  may/MD\n",
            "  also/RB\n",
            "  attempt/VB\n",
            "  build/JJ\n",
            "  models/NNS\n",
            "  descriptive/VBP\n",
            "  data/NNS\n",
            "  aim/NN\n",
            "  simplify/NN\n",
            "  analysis/NN\n",
            "  communicate/NN\n",
            "  results/NNS\n",
            "  (PERSON Data/NNP)\n",
            "  product/NN\n",
            "  data/NNS\n",
            "  product/NN\n",
            "  computer/NN\n",
            "  application/NN\n",
            "  takes/VBZ\n",
            "  data/NNS\n",
            "  inputs/NNS\n",
            "  generates/NNS\n",
            "  outputs/VBP\n",
            "  feeding/VBG\n",
            "  back/RP\n",
            "  environment/NN\n",
            "  may/MD\n",
            "  based/VBN\n",
            "  model/NN\n",
            "  algorithm/JJ\n",
            "  instance/NN\n",
            "  application/NN\n",
            "  analyzes/VBZ\n",
            "  data/NNS\n",
            "  customer/NN\n",
            "  purchase/NN\n",
            "  history/NN\n",
            "  uses/VBZ\n",
            "  results/NNS\n",
            "  recommend/VBP\n",
            "  purchases/NNS\n",
            "  customer/NN\n",
            "  might/MD\n",
            "  enjoy/VB\n",
            "  (ORGANIZATION Communication/NNP Data/NNP)\n",
            "  visualization/NN\n",
            "  used/VBN\n",
            "  help/NN\n",
            "  understand/VB\n",
            "  results/NNS\n",
            "  data/NNS\n",
            "  analyzed/VBD\n",
            "  (GPE Main/NNP)\n",
            "  article/NN\n",
            "  (PERSON Data/NNP)\n",
            "  information/NN\n",
            "  visualization/NN\n",
            "  data/NNS\n",
            "  analyzed/VBN\n",
            "  may/MD\n",
            "  reported/VBD\n",
            "  many/JJ\n",
            "  formats/NNS\n",
            "  users/NNS\n",
            "  analysis/VBP\n",
            "  support/NN\n",
            "  requirements/NNS\n",
            "  users/NNS\n",
            "  may/MD\n",
            "  feedback/VB\n",
            "  results/NNS\n",
            "  additional/JJ\n",
            "  analysis/NN\n",
            "  much/JJ\n",
            "  analytical/JJ\n",
            "  cycle/NN\n",
            "  iterative/JJ\n",
            "  determining/VBG\n",
            "  communicate/JJ\n",
            "  results/NNS\n",
            "  analyst/NN\n",
            "  may/MD\n",
            "  consider/VB\n",
            "  implementing/VBG\n",
            "  variety/NN\n",
            "  data/NNS\n",
            "  visualization/NN\n",
            "  techniques/NNS\n",
            "  help/VBP\n",
            "  communicate/VB\n",
            "  message/NN\n",
            "  clearly/RB\n",
            "  efficiently/RB\n",
            "  audience/NN\n",
            "  (PERSON Data/NNP)\n",
            "  visualization/NN\n",
            "  uses/VBZ\n",
            "  information/NN\n",
            "  displays/NNS\n",
            "  graphics/NNS\n",
            "  tables/NNS\n",
            "  charts/NNS\n",
            "  help/VBP\n",
            "  communicate/VB\n",
            "  key/JJ\n",
            "  messages/NNS\n",
            "  contained/VBN\n",
            "  data/NNS\n",
            "  (PERSON Tables/NNP)\n",
            "  valuable/JJ\n",
            "  tool/NN\n",
            "  enabling/VBG\n",
            "  ability/NN\n",
            "  user/RB\n",
            "  query/RB\n",
            "  focus/VB\n",
            "  specific/JJ\n",
            "  numbers/NNS\n",
            "  charts/VBP\n",
            "  bar/NN\n",
            "  charts/NNS\n",
            "  line/NN\n",
            "  charts/NNS\n",
            "  may/MD\n",
            "  help/VB\n",
            "  explain/VB\n",
            "  quantitative/JJ\n",
            "  messages/NNS\n",
            "  contained/VBN\n",
            "  data/NNS\n",
            "  Quantitative/NNP\n",
            "  messages/NNS\n",
            "  (GPE Main/NNP)\n",
            "  article/NN\n",
            "  (PERSON Data/NNP)\n",
            "  information/NN\n",
            "  visualization/NN\n",
            "  time/NN\n",
            "  series/NN\n",
            "  illustrated/VBD\n",
            "  line/NN\n",
            "  chart/NN\n",
            "  demonstrating/VBG\n",
            "  trends/NNS\n",
            "  federal/JJ\n",
            "  spending/NN\n",
            "  revenue/NN\n",
            "  time/NN\n",
            "  scatterplot/NN\n",
            "  illustrating/VBG\n",
            "  correlation/NN\n",
            "  two/CD\n",
            "  variables/NNS\n",
            "  inflation/NN\n",
            "  unemployment/NN\n",
            "  measured/VBD\n",
            "  points/NNS\n",
            "  time/NN\n",
            "  (PERSON Stephen/NNP)\n",
            "  described/VBD\n",
            "  eight/CD\n",
            "  types/NNS\n",
            "  quantitative/JJ\n",
            "  messages/NNS\n",
            "  users/NNS\n",
            "  may/MD\n",
            "  attempt/VB\n",
            "  understand/JJ\n",
            "  communicate/NN\n",
            "  set/VBN\n",
            "  data/NNS\n",
            "  associated/VBD\n",
            "  graphs/NN\n",
            "  used/VBN\n",
            "  help/NN\n",
            "  communicate/VB\n",
            "  message/NN\n",
            "  Customers/NNPS\n",
            "  specifying/VBG\n",
            "  requirements/NNS\n",
            "  analysts/NNS\n",
            "  performing/VBG\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  may/MD\n",
            "  consider/VB\n",
            "  messages/NNS\n",
            "  course/NN\n",
            "  process/NN\n",
            "  single/JJ\n",
            "  variable/JJ\n",
            "  captured/JJ\n",
            "  period/NN\n",
            "  time/NN\n",
            "  unemployment/NN\n",
            "  rate/NN\n",
            "  period/NN\n",
            "  line/NN\n",
            "  chart/NN\n",
            "  may/MD\n",
            "  used/VBN\n",
            "  demonstrate/VB\n",
            "  trend/NN\n",
            "  Ranking/NNP\n",
            "  Categorical/NNP\n",
            "  subdivisions/NNS\n",
            "  ranked/VBD\n",
            "  ascending/VBG\n",
            "  descending/VBG\n",
            "  order/NN\n",
            "  ranking/VBG\n",
            "  sales/NNS\n",
            "  performance/NN\n",
            "  measure/NN\n",
            "  salespersons/NNS\n",
            "  category/NN\n",
            "  salesperson/NN\n",
            "  categorical/JJ\n",
            "  subdivision/NN\n",
            "  single/JJ\n",
            "  period/NN\n",
            "  bar/IN\n",
            "  chart/NN\n",
            "  may/MD\n",
            "  used/VBD\n",
            "  show/VB\n",
            "  comparison/JJ\n",
            "  across/IN\n",
            "  salespersons/NNS\n",
            "  (ORGANIZATION Categorical/NNP)\n",
            "  subdivisions/NNS\n",
            "  measured/VBD\n",
            "  ratio/JJ\n",
            "  whole/JJ\n",
            "  percentage/NN\n",
            "  pie/NN\n",
            "  chart/NN\n",
            "  bar/NN\n",
            "  chart/NN\n",
            "  show/NN\n",
            "  comparison/JJ\n",
            "  ratios/NNS\n",
            "  market/NN\n",
            "  share/NN\n",
            "  represented/VBN\n",
            "  competitors/NNS\n",
            "  market/NN\n",
            "  (PERSON Deviation/NNP Categorical/NNP)\n",
            "  subdivisions/NNS\n",
            "  compared/VBN\n",
            "  reference/NN\n",
            "  comparison/NN\n",
            "  actual/JJ\n",
            "  budget/NN\n",
            "  expenses/NNS\n",
            "  several/JJ\n",
            "  departments/NNS\n",
            "  business/NN\n",
            "  given/VBN\n",
            "  time/NN\n",
            "  period/NN\n",
            "  bar/IN\n",
            "  chart/NN\n",
            "  show/NN\n",
            "  comparison/NN\n",
            "  actual/JJ\n",
            "  versus/NN\n",
            "  reference/NN\n",
            "  amount/NN\n",
            "  (PERSON Frequency/NNP)\n",
            "  distribution/NN\n",
            "  Shows/NNP\n",
            "  number/NN\n",
            "  observations/NNS\n",
            "  particular/JJ\n",
            "  variable/JJ\n",
            "  given/VBN\n",
            "  interval/JJ\n",
            "  number/NN\n",
            "  years/NNS\n",
            "  stock/NN\n",
            "  market/NN\n",
            "  return/NN\n",
            "  intervals/NNS\n",
            "  etc/VBP\n",
            "  histogram/JJ\n",
            "  type/NN\n",
            "  bar/NN\n",
            "  chart/NN\n",
            "  may/MD\n",
            "  used/VBN\n",
            "  analysis/NN\n",
            "  (ORGANIZATION Correlation/NNP Comparison/NNP)\n",
            "  observations/NNS\n",
            "  represented/VBD\n",
            "  two/CD\n",
            "  variables/NNS\n",
            "  X/VBP\n",
            "  determine/JJ\n",
            "  tend/VBP\n",
            "  move/NN\n",
            "  opposite/JJ\n",
            "  directions/NNS\n",
            "  example/NN\n",
            "  plotting/VBG\n",
            "  unemployment/NN\n",
            "  X/NNP\n",
            "  inflation/NN\n",
            "  sample/JJ\n",
            "  months/NNS\n",
            "  scatter/NN\n",
            "  plot/NN\n",
            "  typically/RB\n",
            "  used/JJ\n",
            "  message/NN\n",
            "  Nominal/NNP\n",
            "  comparison/NN\n",
            "  Comparing/NNP\n",
            "  categorical/JJ\n",
            "  subdivisions/NNS\n",
            "  particular/JJ\n",
            "  order/NN\n",
            "  sales/NNS\n",
            "  volume/NN\n",
            "  product/NN\n",
            "  code/NN\n",
            "  bar/IN\n",
            "  chart/NN\n",
            "  may/MD\n",
            "  used/VBN\n",
            "  comparison/NN\n",
            "  (PERSON Geographic/NNP)\n",
            "  geospatial/JJ\n",
            "  (ORGANIZATION Comparison/NNP)\n",
            "  variable/JJ\n",
            "  across/IN\n",
            "  map/NN\n",
            "  layout/NN\n",
            "  unemployment/NN\n",
            "  rate/NN\n",
            "  state/NN\n",
            "  number/NN\n",
            "  persons/NNS\n",
            "  various/JJ\n",
            "  floors/NNS\n",
            "  building/VBG\n",
            "  cartogram/NN\n",
            "  typical/JJ\n",
            "  graphic/NN\n",
            "  used/VBN\n",
            "  (PERSON Techniques/NNP)\n",
            "  analyzing/VBG\n",
            "  quantitative/JJ\n",
            "  data/NNS\n",
            "  (PERSON See/NNP)\n",
            "  also/RB\n",
            "  Problem/NNP\n",
            "  solving/VBG\n",
            "  (PERSON Author/NNP Jonathan/NNP Koomey/NNP)\n",
            "  recommended/VBD\n",
            "  series/NN\n",
            "  best/JJS\n",
            "  practices/NNS\n",
            "  understanding/VBG\n",
            "  quantitative/JJ\n",
            "  data/NNS\n",
            "  include/VBP\n",
            "  (PERSON Check/NNP)\n",
            "  raw/JJ\n",
            "  data/NN\n",
            "  anomalies/NNS\n",
            "  prior/RB\n",
            "  performing/VBG\n",
            "  analysis/NN\n",
            "  important/JJ\n",
            "  calculations/NNS\n",
            "  verifying/VBG\n",
            "  columns/NN\n",
            "  data/NNS\n",
            "  formula/NN\n",
            "  driven/VBN\n",
            "  (ORGANIZATION Confirm/NNP)\n",
            "  main/JJ\n",
            "  totals/NNS\n",
            "  sum/VBP\n",
            "  subtotals/NNS\n",
            "  (GPE Check/NNP)\n",
            "  relationships/NNS\n",
            "  numbers/NNS\n",
            "  related/VBN\n",
            "  predictable/JJ\n",
            "  way/NN\n",
            "  ratios/NNS\n",
            "  time/NN\n",
            "  (GPE Normalize/NNP)\n",
            "  numbers/NNS\n",
            "  make/VBP\n",
            "  comparisons/NNS\n",
            "  easier/RBR\n",
            "  analyzing/VBG\n",
            "  amounts/NNS\n",
            "  per/IN\n",
            "  person/NN\n",
            "  relative/JJ\n",
            "  (ORGANIZATION GDP/NNP)\n",
            "  index/NN\n",
            "  value/NN\n",
            "  relative/JJ\n",
            "  base/NN\n",
            "  year/NN\n",
            "  Break/NNP\n",
            "  problems/NNS\n",
            "  component/JJ\n",
            "  parts/NNS\n",
            "  analyzing/VBG\n",
            "  factors/NNS\n",
            "  led/VBD\n",
            "  results/NNS\n",
            "  (ORGANIZATION DuPont/NNP)\n",
            "  analysis/NN\n",
            "  return/NN\n",
            "  equity/NN\n",
            "  variables/NNS\n",
            "  examination/NN\n",
            "  analysts/NNS\n",
            "  typically/RB\n",
            "  obtain/VB\n",
            "  descriptive/JJ\n",
            "  statistics/NNS\n",
            "  mean/JJ\n",
            "  average/JJ\n",
            "  median/JJ\n",
            "  standard/NN\n",
            "  deviation/NN\n",
            "  may/MD\n",
            "  also/RB\n",
            "  analyze/VB\n",
            "  distribution/NN\n",
            "  key/JJ\n",
            "  variables/NNS\n",
            "  see/VBP\n",
            "  individual/JJ\n",
            "  values/NNS\n",
            "  cluster/VBP\n",
            "  around/IN\n",
            "  mean/JJ\n",
            "  illustration/NN\n",
            "  (ORGANIZATION MECE/NNP)\n",
            "  principle/NN\n",
            "  used/VBN\n",
            "  data/NNS\n",
            "  analysis/NN\n",
            "  consultants/NNS\n",
            "  (ORGANIZATION McKinsey/NNP Company/NNP)\n",
            "  named/VBD\n",
            "  technique/NN\n",
            "  breaking/VBG\n",
            "  quantitative/JJ\n",
            "  problem/NN\n",
            "  component/NN\n",
            "  parts/NNS\n",
            "  called/VBD\n",
            "  (ORGANIZATION MECE/NNP)\n",
            "  principle/NN\n",
            "  layer/NN\n",
            "  broken/JJ\n",
            "  components/NNS\n",
            "  must/MD\n",
            "  mutually/RB\n",
            "  exclusive/JJ\n",
            "  collectively/RB\n",
            "  add/VBP\n",
            "  layer/JJ\n",
            "  relationship/NN\n",
            "  referred/VBD\n",
            "  (PERSON Mutually/NNP Exclusive/NNP Collectively/NNP Exhaustive/NNP)\n",
            "  MECE/NNP\n",
            "  example/NN\n",
            "  profit/NN\n",
            "  definition/NN\n",
            "  broken/VBN\n",
            "  total/JJ\n",
            "  revenue/NN\n",
            "  total/JJ\n",
            "  cost/NN\n",
            "  turn/VBP\n",
            "  total/JJ\n",
            "  revenue/NN\n",
            "  analyzed/VBD\n",
            "  components/NNS\n",
            "  revenue/NN\n",
            "  divisions/NNS\n",
            "  B/NNP\n",
            "  C/NNP\n",
            "  mutually/RB\n",
            "  exclusive/JJ\n",
            "  add/VBP\n",
            "  total/JJ\n",
            "  revenue/NN\n",
            "  collectively/RB\n",
            "  exhaustive/JJ\n",
            "  Analysts/NNS\n",
            "  may/MD\n",
            "  use/VB\n",
            "  robust/JJ\n",
            "  statistical/JJ\n",
            "  measurements/NNS\n",
            "  solve/VBP\n",
            "  certain/JJ\n",
            "  analytical/JJ\n",
            "  problems/NNS\n",
            "  Hypothesis/NNP\n",
            "  testing/VBG\n",
            "  used/VBN\n",
            "  particular/JJ\n",
            "  hypothesis/NN\n",
            "  true/JJ\n",
            "  state/NN\n",
            "  affairs/NNS\n",
            "  made/VBD\n",
            "  analyst/NN\n",
            "  data/NNS\n",
            "  gathered/VBD\n",
            "  determine/NN\n",
            "  whether/IN\n",
            "  state/NN\n",
            "  affairs/NNS\n",
            "  true/JJ\n",
            "  false/JJ\n",
            "  example/NN\n",
            "  hypothesis/NN\n",
            "  might/MD\n",
            "  Unemployment/VB\n",
            "  effect/NN\n",
            "  inflation/NN\n",
            "  relates/VBZ\n",
            "  economics/NNS\n",
            "  concept/NN\n",
            "  called/VBN\n",
            "  (PERSON Phillips/NNP Curve/NNP Hypothesis/NNP)\n",
            "  testing/VBG\n",
            "  involves/NNS\n",
            "  considering/VBG\n",
            "  likelihood/NN\n",
            "  (PERSON Type/NNP)\n",
            "  type/NN\n",
            "  II/NNP\n",
            "  errors/NNS\n",
            "  relate/VBP\n",
            "  whether/IN\n",
            "  data/NNS\n",
            "  supports/NNS\n",
            "  accepting/VBG\n",
            "  rejecting/VBG\n",
            "  hypothesis/NN\n",
            "  Regression/NNP\n",
            "  analysis/NN\n",
            "  may/MD\n",
            "  used/VBN\n",
            "  analyst/NN\n",
            "  trying/VBG\n",
            "  determine/JJ\n",
            "  extent/NN\n",
            "  independent/JJ\n",
            "  variable/JJ\n",
            "  X/NN\n",
            "  affects/NNS\n",
            "  dependent/JJ\n",
            "  variable/JJ\n",
            "  extent/NN\n",
            "  changes/NNS\n",
            "  unemployment/NN\n",
            "  rate/NN\n",
            "  X/NNP\n",
            "  affect/CC\n",
            "  inflation/NN\n",
            "  rate/NN\n",
            "  attempt/NN\n",
            "  model/NN\n",
            "  fit/JJ\n",
            "  equation/NN\n",
            "  line/NN\n",
            "  curve/NN\n",
            "  data/NNS\n",
            "  function/NN\n",
            "  X/NNP\n",
            "  Necessary/NNP\n",
            "  condition/NN\n",
            "  analysis/NN\n",
            "  (ORGANIZATION NCA/NNP)\n",
            "  may/MD\n",
            "  used/VBN\n",
            "  analyst/NN\n",
            "  trying/VBG\n",
            "  determine/JJ\n",
            "  extent/NN\n",
            "  independent/JJ\n",
            "  variable/JJ\n",
            "  X/NN\n",
            "  allows/VBZ\n",
            "  variable/JJ\n",
            "  extent/NN\n",
            "  certain/JJ\n",
            "  unemployment/NN\n",
            "  rate/NN\n",
            "  X/NNP\n",
            "  necessary/JJ\n",
            "  certain/JJ\n",
            "  inflation/NN\n",
            "  rate/NN\n",
            "  Whereas/NNP\n",
            "  multiple/NN\n",
            "  regression/NN\n",
            "  analysis/NN\n",
            "  uses/VBZ\n",
            "  additive/JJ\n",
            "  logic/JJ\n",
            "  produce/VBP\n",
            "  outcome/JJ\n",
            "  X/NNP\n",
            "  compensate/NN\n",
            "  sufficient/JJ\n",
            "  necessary/JJ\n",
            "  necessary/JJ\n",
            "  condition/NN\n",
            "  analysis/NN\n",
            "  (ORGANIZATION NCA/NNP)\n",
            "  uses/VBZ\n",
            "  necessity/NN\n",
            "  logic/JJ\n",
            "  one/CD\n",
            "  allow/JJ\n",
            "  outcome/NN\n",
            "  exist/NN\n",
            "  may/MD\n",
            "  produce/VB\n",
            "  necessary/JJ\n",
            "  sufficient/JJ\n",
            "  single/JJ\n",
            "  necessary/JJ\n",
            "  condition/NN\n",
            "  must/MD\n",
            "  present/VB\n",
            "  compensation/NN\n",
            "  possible/JJ)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scrapping Websites using BeautifulSoup"
      ],
      "metadata": {
        "id": "aL9-U8Ljdjkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_website(url):\n",
        "    try:\n",
        "        # Send an HTTP GET request to the URL\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Check if the request was successful (status code 200)\n",
        "        if response.status_code == 200:\n",
        "            # Parse the HTML content of the webpage\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            return soup\n",
        "        else:\n",
        "            print('Failed to retrieve the webpage. Status code:', response.status_code)\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print('An error occurred while scraping the website:', e)\n",
        "        return None\n",
        "\n",
        "def extract_paragraphs(soup):\n",
        "    if soup:\n",
        "        try:\n",
        "            # Find and extract specific elements or data from the webpage\n",
        "            paragraphs = soup.find_all('p')\n",
        "            return paragraphs\n",
        "        except Exception as e:\n",
        "            print('An error occurred while extracting paragraphs:', e)\n",
        "            return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "url = 'https://toscrape.com/'\n",
        "soup = scrape_website(url)\n",
        "if soup:\n",
        "    paragraphs = extract_paragraphs(soup)\n",
        "    if paragraphs:\n",
        "        x = ''\n",
        "        for paragraph in paragraphs:\n",
        "          print(paragraph.text)\n",
        "          x += paragraph.text\n",
        "    else:\n",
        "      print('No paragraphs found on the webpage.')\n",
        "else:\n",
        "  print('No soup object returned. Exiting.')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN7kbFizdp_E",
        "outputId": "4560712d-1cc6-41fe-af92-a59b0c28b591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A fictional bookstore that desperately wants to be scraped. It's a safe place for beginners learning web scraping and for developers validating their scraping technologies as well. Available at: books.toscrape.com\n",
            "A website that lists quotes from famous people. It has many endpoints showing the quotes in many different ways, each of them including new scraping challenges for you, as described below.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using R**"
      ],
      "metadata": {
        "id": "8Nf-m6EDd_pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"tm\")\n",
        "install.packages(\"rvest\")\n",
        "install.packages(\"tokenizers\")\n",
        "install.packages(\"openNLP\")\n",
        "install.packages('tm')\n",
        "install.packages('NLP')\n",
        "install.packages('quanteda')\n",
        "install.packages('tidyverse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMpJ8-13eCRq",
        "outputId": "91a5b131-7f58-4240-9d77-bd2185acddbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘openNLPdata’, ‘rJava’\n",
            "\n",
            "\n",
            "Warning message in install.packages(\"openNLP\"):\n",
            "“installation of package ‘rJava’ had non-zero exit status”\n",
            "Warning message in install.packages(\"openNLP\"):\n",
            "“installation of package ‘openNLPdata’ had non-zero exit status”\n",
            "Warning message in install.packages(\"openNLP\"):\n",
            "“installation of package ‘openNLP’ had non-zero exit status”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘ISOcodes’, ‘fastmatch’, ‘RcppParallel’, ‘stopwords’, ‘RcppArmadillo’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages('udpipe')\n",
        "install.packages('rvest')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7-ATVF3frcR",
        "outputId": "aeeb0145-9f8c-410e-8193-987637916e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(tm)\n",
        "library(rvest)\n",
        "library(NLP)\n",
        "library(tokenizers)\n",
        "library(SnowballC)\n",
        "library(tm)\n",
        "library(NLP)\n",
        "library(quanteda)\n",
        "library(udpipe)\n",
        "library(rvest)\n",
        "library(tidyverse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBga9LVkeH14",
        "outputId": "6742b6d9-9db4-49a6-85e0-d0265e2c3ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Package version: 3.3.1\n",
            "Unicode version: 14.0\n",
            "ICU version: 70.1\n",
            "\n",
            "Parallel computing: 2 of 2 threads used.\n",
            "\n",
            "See https://quanteda.io for tutorials and examples.\n",
            "\n",
            "\n",
            "Attaching package: ‘quanteda’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:tm’:\n",
            "\n",
            "    stopwords\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:NLP’:\n",
            "\n",
            "    meta, meta<-\n",
            "\n",
            "\n",
            "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
            "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
            "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.4.4     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
            "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
            "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
            "\u001b[31m✖\u001b[39m \u001b[34mggplot2\u001b[39m::\u001b[32mannotate()\u001b[39m     masks \u001b[34mNLP\u001b[39m::annotate()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m         masks \u001b[34mstats\u001b[39m::filter()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mreadr\u001b[39m::\u001b[32mguess_encoding()\u001b[39m masks \u001b[34mrvest\u001b[39m::guess_encoding()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m            masks \u001b[34mstats\u001b[39m::lag()\n",
            "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "text <- \"In this article, you will learn various concepts of web scraping and get comfortable with scraping various types of websites and their data. The goal is to scrape data from the Wikipedia Home page and parse it through various web scraping techniques. You will be getting familiar with various web scraping techniques, python modules for web scraping, and processes of Data extraction and data processing. Web scraping is an automatic process of extracting information from the web. This article will give you an in-depth idea of web scraping, its comparison with web crawling, and why you should opt for web scraping.\n",
        "\n",
        "Introduction to Web scraping and Python\n",
        "It is basically a technique or a process in which large amounts of data from a huge number of websites is passed through a web scraping software coded in a programming language and as a result, structured data is extracted which can be saved locally in our devices preferably in Excel sheets, JSON or spreadsheets. Now, we don’t have to manually copy and paste data from websites but a scraper can perform that task for us in a couple of seconds.\n",
        "\n",
        "Web scraping is also known as Screen Scraping, Web Data Extraction, Web Harvesting, etc.\n",
        "\n",
        "\n",
        "Process of Web scraping\n",
        "\n",
        "This helps programmers write clear, logical code for small and large-scale projects. Python is mostly known as the best web scraper language. It’s more like an all-rounder and can handle most of the web crawling related processes smoothly. Scrapy and Beautiful Soup are among the widely used frameworks based on Python that makes scraping using this language such an easy route to take.\n",
        "\n",
        "\n",
        "A brief list of Python libraries used for web scraping\n",
        "Let’s see the web scraping libraries in Python!\n",
        "\n",
        "Requests (HTTP for Humans) Library for Web Scraping – It is used for making various types of HTTP requests like GET, POST, etc. It is the most basic yet the most essential of all libraries.\n",
        "lxml Library for Web Scraping – lxml library provides super-fast and high-performance parsing of HTML and XML content from websites. If you are planning to scrape large datasets, this is the one you should go for.\n",
        "Beautiful Soup Library for Web Scraping – Its work involves creating a parse tree for parsing content. A perfect starting library for beginners and very easy to work with.\n",
        "Selenium Library for Web Scraping – Originally made for automated testing of web applications, this library overcomes the issue all the above libraries face i.e. scraping content from dynamically populated websites. This makes it slower and not suitable for industry-level projects.\n",
        "Scrapy for Web Scraping – The BOSS of all libraries, an entire web scraping framework which is asynchronous in its usage. This makes it blazing fast and increases efficiency.\n",
        "Practical Implementation – Scraping Wikipedia\n",
        "\n",
        "Steps of web scraping\n",
        "\n",
        "Step 1: How to use python for web scraping?\n",
        "We need python IDE and should be familiar with the use of it.\n",
        "Virtualenv is a tool to create isolated Python environments. With the help of virtualenv, we can create a folder that contains all necessary executables to use the packages that our Python project requires. Here we can add and modify python modules without affecting any global installation.\n",
        "We need to install various Python modules and libraries using the pip command for our purpose. But, we should always keep in mind that whether the website we are scraping is legal or not.\n",
        "Requirements:\n",
        "\n",
        "Requests: It is an efficient HTTP library used for accessing web pages.\n",
        "Urlib3: It is used for retrieving data from URLs.\n",
        "Selenium: It is an open-source automated testing suite for web applications across different browsers and platforms.\n",
        "Installation:\n",
        "\n",
        "pip install virtualenv\n",
        "python -m pip install selenium\n",
        "python -m pip install requests\n",
        "python -m pip install urllib3\n",
        "\n",
        "Sample image during installing\n",
        "\n",
        "Step 2: Introduction to Requests library\n",
        "Here, we will learn various python modules to fetch data from the web.\n",
        "The python requests library is used to make download the webpage we are trying to scrape.\n",
        "Requirements:\n",
        "\n",
        "Python IDE\n",
        "Python Modules\n",
        "Requests library\n",
        "Code Walk-Through:\n",
        "\n",
        "URL: https://en.wikipedia.org/wiki/Main_Page\n",
        "# import required modules\n",
        "import requests\n",
        "\n",
        "# get URL\n",
        "page = requests.get(https://en.wikipedia.org/wiki/Main_Page)\n",
        "\n",
        "# display status code\n",
        "print(page.status_code)\n",
        "\n",
        "# display scraped data\n",
        "print(page.content)\n",
        "Output:\n",
        "\n",
        "\n",
        "\n",
        "The first thing we’ll need to do to scrape a web page is to download the page. We can download pages using the Python requests library. The requests library will make a GET request to a web server, which will download the HTML contents of a given web page for us. There are several types of requests we can make using requests, of which GET is just one. The URL of our sample website is https://en.wikipedia.org/wiki/Main_Page. The task is to download it using requests.get() method. After running our request, we get a Response object. This object has a status_code property, which indicates if the page was downloaded successfully. And a content property that gives the HTML content of the webpage as output.\n",
        "\n",
        "Step 3: Introduction to Beautiful Soup for page parsing\n",
        "We have a lot of python modules for data extraction. We are going to use BeautifulSoup for our purpose.\n",
        "\n",
        "BeautifulSoup is a Python library for pulling data out of HTML and XML files.\n",
        "It needs an input (document or URL) to create a soup object as it cannot fetch a web page by itself.\n",
        "We have other modules such as regular expression, lxml for the same purpose.\n",
        "We then process the data in CSV or JSON or MySQL format.\n",
        "Requirements:\n",
        "\n",
        "PythonIDE\n",
        "Python Modules\n",
        "Beautiful Soup library\n",
        "pip install bs4\n",
        "Code Walk-Through:\n",
        "\n",
        "# import required modules\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# get URL\n",
        "page = requests.get(https://en.wikipedia.org/wiki/Main_Page)\n",
        "\n",
        "# scrape webpage\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "# display scraped data\n",
        "print(soup.prettify())\n",
        "Output:\n",
        "\n",
        "\n",
        "\n",
        "As you can see above, we now have downloaded an HTML document. We can use the BeautifulSoup library to parse this document and extract the text from the p tag. We first have to import the library and create an instance of the BeautifulSoup class to parse our document. We can now print out the HTML content of the page, formatted nicely, using the prettify method on the BeautifulSoup object. As all the tags are nested, we can move through the structure one level at a time. We can first select all the elements at the top level of the page using the children’s property of soup. Note that children return a list generator, so we need to call the list function on it.\n",
        "\n",
        "Step 4: Digging deep into Beautiful Soup further\n",
        "Three features that make Beautiful Soup so powerful:\n",
        "\n",
        "Beautiful Soup provides a few simple methods and Pythonic idioms for navigating, searching, and modifying a parse tree: a toolkit for dissecting a document and extracting what you need. It doesn’t take much code to write an application\n",
        "Beautiful Soup automatically converts incoming documents to Unicode and outgoing documents to UTF-8. You don’t have to think about encodings unless the document doesn’t specify an encoding and Beautiful Soup can’t detect one. Then you just have to specify the original encoding.\n",
        "Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, allowing you to try out different parsing strategies or trade speed for flexibility. Then we have to just process our data in a proper format such as CSV or JSON or MySQL.\n",
        "Requirements:\n",
        "\n",
        "PythonIDE\n",
        "Python Modules\n",
        "Beautiful Soup library\n",
        "Code Walk-Through:\n",
        "\n",
        "# import required modules\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# get URL\n",
        "page = requests.get(https://en.wikipedia.org/wiki/Main_Page)\n",
        "\n",
        "# scrape webpage\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "list(soup.children)\n",
        "\n",
        "# find all occurrence of p in HTML\n",
        "# includes HTML tags\n",
        "print(soup.find_all('p'))\n",
        "\n",
        "print('\\n\\n')\n",
        "\n",
        "# return only text\n",
        "# does not include HTML tags\n",
        "print(soup.find_all('p')[0].get_text())\n",
        "Output:\n",
        "\n",
        "\n",
        "\n",
        "What we did above was useful for figuring out how to navigate a page, but it took a lot of commands to do something fairly simple. If we want to extract a single tag, we can instead use the find_all() method, which will find all the instances of a tag on a page. Note that find_all() returns a list, so we’ll have to loop through, or use list indexing, to extract text. If you instead only want to find the first instance of a tag, you can use the find method, which will return a single BeautifulSoup object.\n",
        "\n",
        "Step 5: Exploring page structure with Chrome Dev tools and extracting information\n",
        "The first thing we’ll need to do is inspect the page using Chrome Devtools. If you’re using another browser, Firefox and Safari have equivalents. It’s recommended to use Chrome though.\n",
        "\n",
        "You can start the developer tools in Chrome by clicking View -> Developer -> Developer Tools. You should end up with a panel at the bottom of the browser like what you see below. Make sure the Elements panel is highlighted. The elements panel will show you all the HTML tags on the page, and let you navigate through them. It’s a really handy feature! By right-clicking on the page near where it says Extended Forecast, then clicking Inspect, we’ll open up the tag that contains the text Extended Forecast in the elements panel.\n",
        "\n",
        "\n",
        "Analyzing by Chrome Dev tools\n",
        "\n",
        "Code Walk-Through:\n",
        "\n",
        "# import required modules\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# get URL\n",
        "page = requests.get(https://en.wikipedia.org/wiki/Main_Page)\n",
        "\n",
        "# scrape webpage\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "# create object\n",
        "object = soup.find(id=mp-left)\n",
        "\n",
        "# find tags\n",
        "items = object.find_all(class_=mp-h2)\n",
        "result = items[0]\n",
        "\n",
        "# display tags\n",
        "print(result.prettify())\n",
        "Output:\n",
        "\n",
        "\n",
        "\n",
        "Here we have to select that element that has an id to it and contains children having the same class. For example, the element with id mp-left is the parent element and its nested children have the class mp-h2. So we will print the information with the first nested child and prettify it using the prettify() function.\n",
        "\n",
        "Conclusion and Digging deeper into Web scraping\n",
        "We learned various concepts of web scraping and scraped data from the Wikipedia Home page and parsed it through various web scraping techniques. The article helped us in getting an in-depth idea of web scraping, its comparison with web crawling, and why you should opt for web scraping. We also learned about the components and working of a web scraper.\n",
        "\n",
        "Although web scraping opens up many doors for ethical purposes, there can be unintended data scraping by unethical practitioners which creates a moral hazard to many companies and organizations where they can retrieve the data easily and use it for their own selfish means. Data-scraping in combination with big data can provide the company’s market intelligence and help them identify critical trends and patterns and identify the best opportunities and solutions. Therefore, it’s quite accurate to predict that Data scraping can be upgraded to the better soon.\n",
        "\n",
        "\n",
        "Uses of Web scraping\n",
        "\n",
        "\n",
        "Don't miss your chance to ride the wave of the data revolution! Every industry is scaling new heights by tapping into the power of data. Sharpen your skills and become a part of the hottest trend in the 21st century.\n",
        "\n",
        "Dive into the future of technology - explore the Complete Machine Learning and Data Science Program by GeeksforGeeks and stay ahead of the curve.\""
      ],
      "metadata": {
        "id": "4_R32hfTeVpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens <- unlist(tokenize_words(text))\n",
        "\n",
        "# Print the result\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnbKKweafEpY",
        "outputId": "a681a1a1-d421-477b-bb5c-d0fd9cc21444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   [1] \"in\"               \"this\"             \"article\"         \n",
            "   [4] \"you\"              \"will\"             \"learn\"           \n",
            "   [7] \"various\"          \"concepts\"         \"of\"              \n",
            "  [10] \"web\"              \"scraping\"         \"and\"             \n",
            "  [13] \"get\"              \"comfortable\"      \"with\"            \n",
            "  [16] \"scraping\"         \"various\"          \"types\"           \n",
            "  [19] \"of\"               \"websites\"         \"and\"             \n",
            "  [22] \"their\"            \"data\"             \"the\"             \n",
            "  [25] \"goal\"             \"is\"               \"to\"              \n",
            "  [28] \"scrape\"           \"data\"             \"from\"            \n",
            "  [31] \"the\"              \"wikipedia\"        \"home\"            \n",
            "  [34] \"page\"             \"and\"              \"parse\"           \n",
            "  [37] \"it\"               \"through\"          \"various\"         \n",
            "  [40] \"web\"              \"scraping\"         \"techniques\"      \n",
            "  [43] \"you\"              \"will\"             \"be\"              \n",
            "  [46] \"getting\"          \"familiar\"         \"with\"            \n",
            "  [49] \"various\"          \"web\"              \"scraping\"        \n",
            "  [52] \"techniques\"       \"python\"           \"modules\"         \n",
            "  [55] \"for\"              \"web\"              \"scraping\"        \n",
            "  [58] \"and\"              \"processes\"        \"of\"              \n",
            "  [61] \"data\"             \"extraction\"       \"and\"             \n",
            "  [64] \"data\"             \"processing\"       \"web\"             \n",
            "  [67] \"scraping\"         \"is\"               \"an\"              \n",
            "  [70] \"automatic\"        \"process\"          \"of\"              \n",
            "  [73] \"extracting\"       \"information\"      \"from\"            \n",
            "  [76] \"the\"              \"web\"              \"this\"            \n",
            "  [79] \"article\"          \"will\"             \"give\"            \n",
            "  [82] \"you\"              \"an\"               \"in\"              \n",
            "  [85] \"depth\"            \"idea\"             \"of\"              \n",
            "  [88] \"web\"              \"scraping\"         \"its\"             \n",
            "  [91] \"comparison\"       \"with\"             \"web\"             \n",
            "  [94] \"crawling\"         \"and\"              \"why\"             \n",
            "  [97] \"you\"              \"should\"           \"opt\"             \n",
            " [100] \"for\"              \"web\"              \"scraping\"        \n",
            " [103] \"introduction\"     \"to\"               \"web\"             \n",
            " [106] \"scraping\"         \"and\"              \"python\"          \n",
            " [109] \"it\"               \"is\"               \"basically\"       \n",
            " [112] \"a\"                \"technique\"        \"or\"              \n",
            " [115] \"a\"                \"process\"          \"in\"              \n",
            " [118] \"which\"            \"large\"            \"amounts\"         \n",
            " [121] \"of\"               \"data\"             \"from\"            \n",
            " [124] \"a\"                \"huge\"             \"number\"          \n",
            " [127] \"of\"               \"websites\"         \"is\"              \n",
            " [130] \"passed\"           \"through\"          \"a\"               \n",
            " [133] \"web\"              \"scraping\"         \"software\"        \n",
            " [136] \"coded\"            \"in\"               \"a\"               \n",
            " [139] \"programming\"      \"language\"         \"and\"             \n",
            " [142] \"as\"               \"a\"                \"result\"          \n",
            " [145] \"structured\"       \"data\"             \"is\"              \n",
            " [148] \"extracted\"        \"which\"            \"can\"             \n",
            " [151] \"be\"               \"saved\"            \"locally\"         \n",
            " [154] \"in\"               \"our\"              \"devices\"         \n",
            " [157] \"preferably\"       \"in\"               \"excel\"           \n",
            " [160] \"sheets\"           \"json\"             \"or\"              \n",
            " [163] \"spreadsheets\"     \"now\"              \"we\"              \n",
            " [166] \"don’t\"            \"have\"             \"to\"              \n",
            " [169] \"manually\"         \"copy\"             \"and\"             \n",
            " [172] \"paste\"            \"data\"             \"from\"            \n",
            " [175] \"websites\"         \"but\"              \"a\"               \n",
            " [178] \"scraper\"          \"can\"              \"perform\"         \n",
            " [181] \"that\"             \"task\"             \"for\"             \n",
            " [184] \"us\"               \"in\"               \"a\"               \n",
            " [187] \"couple\"           \"of\"               \"seconds\"         \n",
            " [190] \"web\"              \"scraping\"         \"is\"              \n",
            " [193] \"also\"             \"known\"            \"as\"              \n",
            " [196] \"screen\"           \"scraping\"         \"web\"             \n",
            " [199] \"data\"             \"extraction\"       \"web\"             \n",
            " [202] \"harvesting\"       \"etc\"              \"process\"         \n",
            " [205] \"of\"               \"web\"              \"scraping\"        \n",
            " [208] \"this\"             \"helps\"            \"programmers\"     \n",
            " [211] \"write\"            \"clear\"            \"logical\"         \n",
            " [214] \"code\"             \"for\"              \"small\"           \n",
            " [217] \"and\"              \"large\"            \"scale\"           \n",
            " [220] \"projects\"         \"python\"           \"is\"              \n",
            " [223] \"mostly\"           \"known\"            \"as\"              \n",
            " [226] \"the\"              \"best\"             \"web\"             \n",
            " [229] \"scraper\"          \"language\"         \"it’s\"            \n",
            " [232] \"more\"             \"like\"             \"an\"              \n",
            " [235] \"all\"              \"rounder\"          \"and\"             \n",
            " [238] \"can\"              \"handle\"           \"most\"            \n",
            " [241] \"of\"               \"the\"              \"web\"             \n",
            " [244] \"crawling\"         \"related\"          \"processes\"       \n",
            " [247] \"smoothly\"         \"scrapy\"           \"and\"             \n",
            " [250] \"beautiful\"        \"soup\"             \"are\"             \n",
            " [253] \"among\"            \"the\"              \"widely\"          \n",
            " [256] \"used\"             \"frameworks\"       \"based\"           \n",
            " [259] \"on\"               \"python\"           \"that\"            \n",
            " [262] \"makes\"            \"scraping\"         \"using\"           \n",
            " [265] \"this\"             \"language\"         \"such\"            \n",
            " [268] \"an\"               \"easy\"             \"route\"           \n",
            " [271] \"to\"               \"take\"             \"a\"               \n",
            " [274] \"brief\"            \"list\"             \"of\"              \n",
            " [277] \"python\"           \"libraries\"        \"used\"            \n",
            " [280] \"for\"              \"web\"              \"scraping\"        \n",
            " [283] \"let’s\"            \"see\"              \"the\"             \n",
            " [286] \"web\"              \"scraping\"         \"libraries\"       \n",
            " [289] \"in\"               \"python\"           \"requests\"        \n",
            " [292] \"http\"             \"for\"              \"humans\"          \n",
            " [295] \"library\"          \"for\"              \"web\"             \n",
            " [298] \"scraping\"         \"it\"               \"is\"              \n",
            " [301] \"used\"             \"for\"              \"making\"          \n",
            " [304] \"various\"          \"types\"            \"of\"              \n",
            " [307] \"http\"             \"requests\"         \"like\"            \n",
            " [310] \"get\"              \"post\"             \"etc\"             \n",
            " [313] \"it\"               \"is\"               \"the\"             \n",
            " [316] \"most\"             \"basic\"            \"yet\"             \n",
            " [319] \"the\"              \"most\"             \"essential\"       \n",
            " [322] \"of\"               \"all\"              \"libraries\"       \n",
            " [325] \"lxml\"             \"library\"          \"for\"             \n",
            " [328] \"web\"              \"scraping\"         \"lxml\"            \n",
            " [331] \"library\"          \"provides\"         \"super\"           \n",
            " [334] \"fast\"             \"and\"              \"high\"            \n",
            " [337] \"performance\"      \"parsing\"          \"of\"              \n",
            " [340] \"html\"             \"and\"              \"xml\"             \n",
            " [343] \"content\"          \"from\"             \"websites\"        \n",
            " [346] \"if\"               \"you\"              \"are\"             \n",
            " [349] \"planning\"         \"to\"               \"scrape\"          \n",
            " [352] \"large\"            \"datasets\"         \"this\"            \n",
            " [355] \"is\"               \"the\"              \"one\"             \n",
            " [358] \"you\"              \"should\"           \"go\"              \n",
            " [361] \"for\"              \"beautiful\"        \"soup\"            \n",
            " [364] \"library\"          \"for\"              \"web\"             \n",
            " [367] \"scraping\"         \"its\"              \"work\"            \n",
            " [370] \"involves\"         \"creating\"         \"a\"               \n",
            " [373] \"parse\"            \"tree\"             \"for\"             \n",
            " [376] \"parsing\"          \"content\"          \"a\"               \n",
            " [379] \"perfect\"          \"starting\"         \"library\"         \n",
            " [382] \"for\"              \"beginners\"        \"and\"             \n",
            " [385] \"very\"             \"easy\"             \"to\"              \n",
            " [388] \"work\"             \"with\"             \"selenium\"        \n",
            " [391] \"library\"          \"for\"              \"web\"             \n",
            " [394] \"scraping\"         \"originally\"       \"made\"            \n",
            " [397] \"for\"              \"automated\"        \"testing\"         \n",
            " [400] \"of\"               \"web\"              \"applications\"    \n",
            " [403] \"this\"             \"library\"          \"overcomes\"       \n",
            " [406] \"the\"              \"issue\"            \"all\"             \n",
            " [409] \"the\"              \"above\"            \"libraries\"       \n",
            " [412] \"face\"             \"i.e\"              \"scraping\"        \n",
            " [415] \"content\"          \"from\"             \"dynamically\"     \n",
            " [418] \"populated\"        \"websites\"         \"this\"            \n",
            " [421] \"makes\"            \"it\"               \"slower\"          \n",
            " [424] \"and\"              \"not\"              \"suitable\"        \n",
            " [427] \"for\"              \"industry\"         \"level\"           \n",
            " [430] \"projects\"         \"scrapy\"           \"for\"             \n",
            " [433] \"web\"              \"scraping\"         \"the\"             \n",
            " [436] \"boss\"             \"of\"               \"all\"             \n",
            " [439] \"libraries\"        \"an\"               \"entire\"          \n",
            " [442] \"web\"              \"scraping\"         \"framework\"       \n",
            " [445] \"which\"            \"is\"               \"asynchronous\"    \n",
            " [448] \"in\"               \"its\"              \"usage\"           \n",
            " [451] \"this\"             \"makes\"            \"it\"              \n",
            " [454] \"blazing\"          \"fast\"             \"and\"             \n",
            " [457] \"increases\"        \"efficiency\"       \"practical\"       \n",
            " [460] \"implementation\"   \"scraping\"         \"wikipedia\"       \n",
            " [463] \"steps\"            \"of\"               \"web\"             \n",
            " [466] \"scraping\"         \"step\"             \"1\"               \n",
            " [469] \"how\"              \"to\"               \"use\"             \n",
            " [472] \"python\"           \"for\"              \"web\"             \n",
            " [475] \"scraping\"         \"we\"               \"need\"            \n",
            " [478] \"python\"           \"ide\"              \"and\"             \n",
            " [481] \"should\"           \"be\"               \"familiar\"        \n",
            " [484] \"with\"             \"the\"              \"use\"             \n",
            " [487] \"of\"               \"it\"               \"virtualenv\"      \n",
            " [490] \"is\"               \"a\"                \"tool\"            \n",
            " [493] \"to\"               \"create\"           \"isolated\"        \n",
            " [496] \"python\"           \"environments\"     \"with\"            \n",
            " [499] \"the\"              \"help\"             \"of\"              \n",
            " [502] \"virtualenv\"       \"we\"               \"can\"             \n",
            " [505] \"create\"           \"a\"                \"folder\"          \n",
            " [508] \"that\"             \"contains\"         \"all\"             \n",
            " [511] \"necessary\"        \"executables\"      \"to\"              \n",
            " [514] \"use\"              \"the\"              \"packages\"        \n",
            " [517] \"that\"             \"our\"              \"python\"          \n",
            " [520] \"project\"          \"requires\"         \"here\"            \n",
            " [523] \"we\"               \"can\"              \"add\"             \n",
            " [526] \"and\"              \"modify\"           \"python\"          \n",
            " [529] \"modules\"          \"without\"          \"affecting\"       \n",
            " [532] \"any\"              \"global\"           \"installation\"    \n",
            " [535] \"we\"               \"need\"             \"to\"              \n",
            " [538] \"install\"          \"various\"          \"python\"          \n",
            " [541] \"modules\"          \"and\"              \"libraries\"       \n",
            " [544] \"using\"            \"the\"              \"pip\"             \n",
            " [547] \"command\"          \"for\"              \"our\"             \n",
            " [550] \"purpose\"          \"but\"              \"we\"              \n",
            " [553] \"should\"           \"always\"           \"keep\"            \n",
            " [556] \"in\"               \"mind\"             \"that\"            \n",
            " [559] \"whether\"          \"the\"              \"website\"         \n",
            " [562] \"we\"               \"are\"              \"scraping\"        \n",
            " [565] \"is\"               \"legal\"            \"or\"              \n",
            " [568] \"not\"              \"requirements\"     \"requests\"        \n",
            " [571] \"it\"               \"is\"               \"an\"              \n",
            " [574] \"efficient\"        \"http\"             \"library\"         \n",
            " [577] \"used\"             \"for\"              \"accessing\"       \n",
            " [580] \"web\"              \"pages\"            \"urlib3\"          \n",
            " [583] \"it\"               \"is\"               \"used\"            \n",
            " [586] \"for\"              \"retrieving\"       \"data\"            \n",
            " [589] \"from\"             \"urls\"             \"selenium\"        \n",
            " [592] \"it\"               \"is\"               \"an\"              \n",
            " [595] \"open\"             \"source\"           \"automated\"       \n",
            " [598] \"testing\"          \"suite\"            \"for\"             \n",
            " [601] \"web\"              \"applications\"     \"across\"          \n",
            " [604] \"different\"        \"browsers\"         \"and\"             \n",
            " [607] \"platforms\"        \"installation\"     \"pip\"             \n",
            " [610] \"install\"          \"virtualenv\"       \"python\"          \n",
            " [613] \"m\"                \"pip\"              \"install\"         \n",
            " [616] \"selenium\"         \"python\"           \"m\"               \n",
            " [619] \"pip\"              \"install\"          \"requests\"        \n",
            " [622] \"python\"           \"m\"                \"pip\"             \n",
            " [625] \"install\"          \"urllib3\"          \"sample\"          \n",
            " [628] \"image\"            \"during\"           \"installing\"      \n",
            " [631] \"step\"             \"2\"                \"introduction\"    \n",
            " [634] \"to\"               \"requests\"         \"library\"         \n",
            " [637] \"here\"             \"we\"               \"will\"            \n",
            " [640] \"learn\"            \"various\"          \"python\"          \n",
            " [643] \"modules\"          \"to\"               \"fetch\"           \n",
            " [646] \"data\"             \"from\"             \"the\"             \n",
            " [649] \"web\"              \"the\"              \"python\"          \n",
            " [652] \"requests\"         \"library\"          \"is\"              \n",
            " [655] \"used\"             \"to\"               \"make\"            \n",
            " [658] \"download\"         \"the\"              \"webpage\"         \n",
            " [661] \"we\"               \"are\"              \"trying\"          \n",
            " [664] \"to\"               \"scrape\"           \"requirements\"    \n",
            " [667] \"python\"           \"ide\"              \"python\"          \n",
            " [670] \"modules\"          \"requests\"         \"library\"         \n",
            " [673] \"code\"             \"walk\"             \"through\"         \n",
            " [676] \"url\"              \"https\"            \"en.wikipedia.org\"\n",
            " [679] \"wiki\"             \"main_page\"        \"import\"          \n",
            " [682] \"required\"         \"modules\"          \"import\"          \n",
            " [685] \"requests\"         \"get\"              \"url\"             \n",
            " [688] \"page\"             \"requests.get\"     \"https\"           \n",
            " [691] \"en.wikipedia.org\" \"wiki\"             \"main_page\"       \n",
            " [694] \"display\"          \"status\"           \"code\"            \n",
            " [697] \"print\"            \"page.status_code\" \"display\"         \n",
            " [700] \"scraped\"          \"data\"             \"print\"           \n",
            " [703] \"page.content\"     \"output\"           \"the\"             \n",
            " [706] \"first\"            \"thing\"            \"we’ll\"           \n",
            " [709] \"need\"             \"to\"               \"do\"              \n",
            " [712] \"to\"               \"scrape\"           \"a\"               \n",
            " [715] \"web\"              \"page\"             \"is\"              \n",
            " [718] \"to\"               \"download\"         \"the\"             \n",
            " [721] \"page\"             \"we\"               \"can\"             \n",
            " [724] \"download\"         \"pages\"            \"using\"           \n",
            " [727] \"the\"              \"python\"           \"requests\"        \n",
            " [730] \"library\"          \"the\"              \"requests\"        \n",
            " [733] \"library\"          \"will\"             \"make\"            \n",
            " [736] \"a\"                \"get\"              \"request\"         \n",
            " [739] \"to\"               \"a\"                \"web\"             \n",
            " [742] \"server\"           \"which\"            \"will\"            \n",
            " [745] \"download\"         \"the\"              \"html\"            \n",
            " [748] \"contents\"         \"of\"               \"a\"               \n",
            " [751] \"given\"            \"web\"              \"page\"            \n",
            " [754] \"for\"              \"us\"               \"there\"           \n",
            " [757] \"are\"              \"several\"          \"types\"           \n",
            " [760] \"of\"               \"requests\"         \"we\"              \n",
            " [763] \"can\"              \"make\"             \"using\"           \n",
            " [766] \"requests\"         \"of\"               \"which\"           \n",
            " [769] \"get\"              \"is\"               \"just\"            \n",
            " [772] \"one\"              \"the\"              \"url\"             \n",
            " [775] \"of\"               \"our\"              \"sample\"          \n",
            " [778] \"website\"          \"is\"               \"https\"           \n",
            " [781] \"en.wikipedia.org\" \"wiki\"             \"main_page\"       \n",
            " [784] \"the\"              \"task\"             \"is\"              \n",
            " [787] \"to\"               \"download\"         \"it\"              \n",
            " [790] \"using\"            \"requests.get\"     \"method\"          \n",
            " [793] \"after\"            \"running\"          \"our\"             \n",
            " [796] \"request\"          \"we\"               \"get\"             \n",
            " [799] \"a\"                \"response\"         \"object\"          \n",
            " [802] \"this\"             \"object\"           \"has\"             \n",
            " [805] \"a\"                \"status_code\"      \"property\"        \n",
            " [808] \"which\"            \"indicates\"        \"if\"              \n",
            " [811] \"the\"              \"page\"             \"was\"             \n",
            " [814] \"downloaded\"       \"successfully\"     \"and\"             \n",
            " [817] \"a\"                \"content\"          \"property\"        \n",
            " [820] \"that\"             \"gives\"            \"the\"             \n",
            " [823] \"html\"             \"content\"          \"of\"              \n",
            " [826] \"the\"              \"webpage\"          \"as\"              \n",
            " [829] \"output\"           \"step\"             \"3\"               \n",
            " [832] \"introduction\"     \"to\"               \"beautiful\"       \n",
            " [835] \"soup\"             \"for\"              \"page\"            \n",
            " [838] \"parsing\"          \"we\"               \"have\"            \n",
            " [841] \"a\"                \"lot\"              \"of\"              \n",
            " [844] \"python\"           \"modules\"          \"for\"             \n",
            " [847] \"data\"             \"extraction\"       \"we\"              \n",
            " [850] \"are\"              \"going\"            \"to\"              \n",
            " [853] \"use\"              \"beautifulsoup\"    \"for\"             \n",
            " [856] \"our\"              \"purpose\"          \"beautifulsoup\"   \n",
            " [859] \"is\"               \"a\"                \"python\"          \n",
            " [862] \"library\"          \"for\"              \"pulling\"         \n",
            " [865] \"data\"             \"out\"              \"of\"              \n",
            " [868] \"html\"             \"and\"              \"xml\"             \n",
            " [871] \"files\"            \"it\"               \"needs\"           \n",
            " [874] \"an\"               \"input\"            \"document\"        \n",
            " [877] \"or\"               \"url\"              \"to\"              \n",
            " [880] \"create\"           \"a\"                \"soup\"            \n",
            " [883] \"object\"           \"as\"               \"it\"              \n",
            " [886] \"cannot\"           \"fetch\"            \"a\"               \n",
            " [889] \"web\"              \"page\"             \"by\"              \n",
            " [892] \"itself\"           \"we\"               \"have\"            \n",
            " [895] \"other\"            \"modules\"          \"such\"            \n",
            " [898] \"as\"               \"regular\"          \"expression\"      \n",
            " [901] \"lxml\"             \"for\"              \"the\"             \n",
            " [904] \"same\"             \"purpose\"          \"we\"              \n",
            " [907] \"then\"             \"process\"          \"the\"             \n",
            " [910] \"data\"             \"in\"               \"csv\"             \n",
            " [913] \"or\"               \"json\"             \"or\"              \n",
            " [916] \"mysql\"            \"format\"           \"requirements\"    \n",
            " [919] \"pythonide\"        \"python\"           \"modules\"         \n",
            " [922] \"beautiful\"        \"soup\"             \"library\"         \n",
            " [925] \"pip\"              \"install\"          \"bs4\"             \n",
            " [928] \"code\"             \"walk\"             \"through\"         \n",
            " [931] \"import\"           \"required\"         \"modules\"         \n",
            " [934] \"from\"             \"bs4\"              \"import\"          \n",
            " [937] \"beautifulsoup\"    \"import\"           \"requests\"        \n",
            " [940] \"get\"              \"url\"              \"page\"            \n",
            " [943] \"requests.get\"     \"https\"            \"en.wikipedia.org\"\n",
            " [946] \"wiki\"             \"main_page\"        \"scrape\"          \n",
            " [949] \"webpage\"          \"soup\"             \"beautifulsoup\"   \n",
            " [952] \"page.content\"     \"html.parser\"      \"display\"         \n",
            " [955] \"scraped\"          \"data\"             \"print\"           \n",
            " [958] \"soup.prettify\"    \"output\"           \"as\"              \n",
            " [961] \"you\"              \"can\"              \"see\"             \n",
            " [964] \"above\"            \"we\"               \"now\"             \n",
            " [967] \"have\"             \"downloaded\"       \"an\"              \n",
            " [970] \"html\"             \"document\"         \"we\"              \n",
            " [973] \"can\"              \"use\"              \"the\"             \n",
            " [976] \"beautifulsoup\"    \"library\"          \"to\"              \n",
            " [979] \"parse\"            \"this\"             \"document\"        \n",
            " [982] \"and\"              \"extract\"          \"the\"             \n",
            " [985] \"text\"             \"from\"             \"the\"             \n",
            " [988] \"p\"                \"tag\"              \"we\"              \n",
            " [991] \"first\"            \"have\"             \"to\"              \n",
            " [994] \"import\"           \"the\"              \"library\"         \n",
            " [997] \"and\"              \"create\"           \"an\"              \n",
            "[1000] \"instance\"         \"of\"               \"the\"             \n",
            "[1003] \"beautifulsoup\"    \"class\"            \"to\"              \n",
            "[1006] \"parse\"            \"our\"              \"document\"        \n",
            "[1009] \"we\"               \"can\"              \"now\"             \n",
            "[1012] \"print\"            \"out\"              \"the\"             \n",
            "[1015] \"html\"             \"content\"          \"of\"              \n",
            "[1018] \"the\"              \"page\"             \"formatted\"       \n",
            "[1021] \"nicely\"           \"using\"            \"the\"             \n",
            "[1024] \"prettify\"         \"method\"           \"on\"              \n",
            "[1027] \"the\"              \"beautifulsoup\"    \"object\"          \n",
            "[1030] \"as\"               \"all\"              \"the\"             \n",
            "[1033] \"tags\"             \"are\"              \"nested\"          \n",
            "[1036] \"we\"               \"can\"              \"move\"            \n",
            "[1039] \"through\"          \"the\"              \"structure\"       \n",
            "[1042] \"one\"              \"level\"            \"at\"              \n",
            "[1045] \"a\"                \"time\"             \"we\"              \n",
            "[1048] \"can\"              \"first\"            \"select\"          \n",
            "[1051] \"all\"              \"the\"              \"elements\"        \n",
            "[1054] \"at\"               \"the\"              \"top\"             \n",
            "[1057] \"level\"            \"of\"               \"the\"             \n",
            "[1060] \"page\"             \"using\"            \"the\"             \n",
            "[1063] \"children’s\"       \"property\"         \"of\"              \n",
            "[1066] \"soup\"             \"note\"             \"that\"            \n",
            "[1069] \"children\"         \"return\"           \"a\"               \n",
            "[1072] \"list\"             \"generator\"        \"so\"              \n",
            "[1075] \"we\"               \"need\"             \"to\"              \n",
            "[1078] \"call\"             \"the\"              \"list\"            \n",
            "[1081] \"function\"         \"on\"               \"it\"              \n",
            "[1084] \"step\"             \"4\"                \"digging\"         \n",
            "[1087] \"deep\"             \"into\"             \"beautiful\"       \n",
            "[1090] \"soup\"             \"further\"          \"three\"           \n",
            "[1093] \"features\"         \"that\"             \"make\"            \n",
            "[1096] \"beautiful\"        \"soup\"             \"so\"              \n",
            "[1099] \"powerful\"         \"beautiful\"        \"soup\"            \n",
            "[1102] \"provides\"         \"a\"                \"few\"             \n",
            "[1105] \"simple\"           \"methods\"          \"and\"             \n",
            "[1108] \"pythonic\"         \"idioms\"           \"for\"             \n",
            "[1111] \"navigating\"       \"searching\"        \"and\"             \n",
            "[1114] \"modifying\"        \"a\"                \"parse\"           \n",
            "[1117] \"tree\"             \"a\"                \"toolkit\"         \n",
            "[1120] \"for\"              \"dissecting\"       \"a\"               \n",
            "[1123] \"document\"         \"and\"              \"extracting\"      \n",
            "[1126] \"what\"             \"you\"              \"need\"            \n",
            "[1129] \"it\"               \"doesn’t\"          \"take\"            \n",
            "[1132] \"much\"             \"code\"             \"to\"              \n",
            "[1135] \"write\"            \"an\"               \"application\"     \n",
            "[1138] \"beautiful\"        \"soup\"             \"automatically\"   \n",
            "[1141] \"converts\"         \"incoming\"         \"documents\"       \n",
            "[1144] \"to\"               \"unicode\"          \"and\"             \n",
            "[1147] \"outgoing\"         \"documents\"        \"to\"              \n",
            "[1150] \"utf\"              \"8\"                \"you\"             \n",
            "[1153] \"don’t\"            \"have\"             \"to\"              \n",
            "[1156] \"think\"            \"about\"            \"encodings\"       \n",
            "[1159] \"unless\"           \"the\"              \"document\"        \n",
            "[1162] \"doesn’t\"          \"specify\"          \"an\"              \n",
            "[1165] \"encoding\"         \"and\"              \"beautiful\"       \n",
            "[1168] \"soup\"             \"can’t\"            \"detect\"          \n",
            "[1171] \"one\"              \"then\"             \"you\"             \n",
            "[1174] \"just\"             \"have\"             \"to\"              \n",
            "[1177] \"specify\"          \"the\"              \"original\"        \n",
            "[1180] \"encoding\"         \"beautiful\"        \"soup\"            \n",
            "[1183] \"sits\"             \"on\"               \"top\"             \n",
            "[1186] \"of\"               \"popular\"          \"python\"          \n",
            "[1189] \"parsers\"          \"like\"             \"lxml\"            \n",
            "[1192] \"and\"              \"html5lib\"         \"allowing\"        \n",
            "[1195] \"you\"              \"to\"               \"try\"             \n",
            "[1198] \"out\"              \"different\"        \"parsing\"         \n",
            "[1201] \"strategies\"       \"or\"               \"trade\"           \n",
            "[1204] \"speed\"            \"for\"              \"flexibility\"     \n",
            "[1207] \"then\"             \"we\"               \"have\"            \n",
            "[1210] \"to\"               \"just\"             \"process\"         \n",
            "[1213] \"our\"              \"data\"             \"in\"              \n",
            "[1216] \"a\"                \"proper\"           \"format\"          \n",
            "[1219] \"such\"             \"as\"               \"csv\"             \n",
            "[1222] \"or\"               \"json\"             \"or\"              \n",
            "[1225] \"mysql\"            \"requirements\"     \"pythonide\"       \n",
            "[1228] \"python\"           \"modules\"          \"beautiful\"       \n",
            "[1231] \"soup\"             \"library\"          \"code\"            \n",
            "[1234] \"walk\"             \"through\"          \"import\"          \n",
            "[1237] \"required\"         \"modules\"          \"from\"            \n",
            "[1240] \"bs4\"              \"import\"           \"beautifulsoup\"   \n",
            "[1243] \"import\"           \"requests\"         \"get\"             \n",
            "[1246] \"url\"              \"page\"             \"requests.get\"    \n",
            "[1249] \"https\"            \"en.wikipedia.org\" \"wiki\"            \n",
            "[1252] \"main_page\"        \"scrape\"           \"webpage\"         \n",
            "[1255] \"soup\"             \"beautifulsoup\"    \"page.content\"    \n",
            "[1258] \"html.parser\"      \"list\"             \"soup.children\"   \n",
            "[1261] \"find\"             \"all\"              \"occurrence\"      \n",
            "[1264] \"of\"               \"p\"                \"in\"              \n",
            "[1267] \"html\"             \"includes\"         \"html\"            \n",
            "[1270] \"tags\"             \"print\"            \"soup.find_all\"   \n",
            "[1273] \"p\"                \"print\"            \"return\"          \n",
            "[1276] \"only\"             \"text\"             \"does\"            \n",
            "[1279] \"not\"              \"include\"          \"html\"            \n",
            "[1282] \"tags\"             \"print\"            \"soup.find_all\"   \n",
            "[1285] \"p\"                \"0\"                \"get_text\"        \n",
            "[1288] \"output\"           \"what\"             \"we\"              \n",
            "[1291] \"did\"              \"above\"            \"was\"             \n",
            "[1294] \"useful\"           \"for\"              \"figuring\"        \n",
            "[1297] \"out\"              \"how\"              \"to\"              \n",
            "[1300] \"navigate\"         \"a\"                \"page\"            \n",
            "[1303] \"but\"              \"it\"               \"took\"            \n",
            "[1306] \"a\"                \"lot\"              \"of\"              \n",
            "[1309] \"commands\"         \"to\"               \"do\"              \n",
            "[1312] \"something\"        \"fairly\"           \"simple\"          \n",
            "[1315] \"if\"               \"we\"               \"want\"            \n",
            "[1318] \"to\"               \"extract\"          \"a\"               \n",
            "[1321] \"single\"           \"tag\"              \"we\"              \n",
            "[1324] \"can\"              \"instead\"          \"use\"             \n",
            "[1327] \"the\"              \"find_all\"         \"method\"          \n",
            "[1330] \"which\"            \"will\"             \"find\"            \n",
            "[1333] \"all\"              \"the\"              \"instances\"       \n",
            "[1336] \"of\"               \"a\"                \"tag\"             \n",
            "[1339] \"on\"               \"a\"                \"page\"            \n",
            "[1342] \"note\"             \"that\"             \"find_all\"        \n",
            "[1345] \"returns\"          \"a\"                \"list\"            \n",
            "[1348] \"so\"               \"we’ll\"            \"have\"            \n",
            "[1351] \"to\"               \"loop\"             \"through\"         \n",
            "[1354] \"or\"               \"use\"              \"list\"            \n",
            "[1357] \"indexing\"         \"to\"               \"extract\"         \n",
            "[1360] \"text\"             \"if\"               \"you\"             \n",
            "[1363] \"instead\"          \"only\"             \"want\"            \n",
            "[1366] \"to\"               \"find\"             \"the\"             \n",
            "[1369] \"first\"            \"instance\"         \"of\"              \n",
            "[1372] \"a\"                \"tag\"              \"you\"             \n",
            "[1375] \"can\"              \"use\"              \"the\"             \n",
            "[1378] \"find\"             \"method\"           \"which\"           \n",
            "[1381] \"will\"             \"return\"           \"a\"               \n",
            "[1384] \"single\"           \"beautifulsoup\"    \"object\"          \n",
            "[1387] \"step\"             \"5\"                \"exploring\"       \n",
            "[1390] \"page\"             \"structure\"        \"with\"            \n",
            "[1393] \"chrome\"           \"dev\"              \"tools\"           \n",
            "[1396] \"and\"              \"extracting\"       \"information\"     \n",
            "[1399] \"the\"              \"first\"            \"thing\"           \n",
            "[1402] \"we’ll\"            \"need\"             \"to\"              \n",
            "[1405] \"do\"               \"is\"               \"inspect\"         \n",
            "[1408] \"the\"              \"page\"             \"using\"           \n",
            "[1411] \"chrome\"           \"devtools\"         \"if\"              \n",
            "[1414] \"you’re\"           \"using\"            \"another\"         \n",
            "[1417] \"browser\"          \"firefox\"          \"and\"             \n",
            "[1420] \"safari\"           \"have\"             \"equivalents\"     \n",
            "[1423] \"it’s\"             \"recommended\"      \"to\"              \n",
            "[1426] \"use\"              \"chrome\"           \"though\"          \n",
            "[1429] \"you\"              \"can\"              \"start\"           \n",
            "[1432] \"the\"              \"developer\"        \"tools\"           \n",
            "[1435] \"in\"               \"chrome\"           \"by\"              \n",
            "[1438] \"clicking\"         \"view\"             \"developer\"       \n",
            "[1441] \"developer\"        \"tools\"            \"you\"             \n",
            "[1444] \"should\"           \"end\"              \"up\"              \n",
            "[1447] \"with\"             \"a\"                \"panel\"           \n",
            "[1450] \"at\"               \"the\"              \"bottom\"          \n",
            "[1453] \"of\"               \"the\"              \"browser\"         \n",
            "[1456] \"like\"             \"what\"             \"you\"             \n",
            "[1459] \"see\"              \"below\"            \"make\"            \n",
            "[1462] \"sure\"             \"the\"              \"elements\"        \n",
            "[1465] \"panel\"            \"is\"               \"highlighted\"     \n",
            "[1468] \"the\"              \"elements\"         \"panel\"           \n",
            "[1471] \"will\"             \"show\"             \"you\"             \n",
            "[1474] \"all\"              \"the\"              \"html\"            \n",
            "[1477] \"tags\"             \"on\"               \"the\"             \n",
            "[1480] \"page\"             \"and\"              \"let\"             \n",
            "[1483] \"you\"              \"navigate\"         \"through\"         \n",
            "[1486] \"them\"             \"it’s\"             \"a\"               \n",
            "[1489] \"really\"           \"handy\"            \"feature\"         \n",
            "[1492] \"by\"               \"right\"            \"clicking\"        \n",
            "[1495] \"on\"               \"the\"              \"page\"            \n",
            "[1498] \"near\"             \"where\"            \"it\"              \n",
            "[1501] \"says\"             \"extended\"         \"forecast\"        \n",
            "[1504] \"then\"             \"clicking\"         \"inspect\"         \n",
            "[1507] \"we’ll\"            \"open\"             \"up\"              \n",
            "[1510] \"the\"              \"tag\"              \"that\"            \n",
            "[1513] \"contains\"         \"the\"              \"text\"            \n",
            "[1516] \"extended\"         \"forecast\"         \"in\"              \n",
            "[1519] \"the\"              \"elements\"         \"panel\"           \n",
            "[1522] \"analyzing\"        \"by\"               \"chrome\"          \n",
            "[1525] \"dev\"              \"tools\"            \"code\"            \n",
            "[1528] \"walk\"             \"through\"          \"import\"          \n",
            "[1531] \"required\"         \"modules\"          \"from\"            \n",
            "[1534] \"bs4\"              \"import\"           \"beautifulsoup\"   \n",
            "[1537] \"import\"           \"requests\"         \"get\"             \n",
            "[1540] \"url\"              \"page\"             \"requests.get\"    \n",
            "[1543] \"https\"            \"en.wikipedia.org\" \"wiki\"            \n",
            "[1546] \"main_page\"        \"scrape\"           \"webpage\"         \n",
            "[1549] \"soup\"             \"beautifulsoup\"    \"page.content\"    \n",
            "[1552] \"html.parser\"      \"create\"           \"object\"          \n",
            "[1555] \"object\"           \"soup.find\"        \"id\"              \n",
            "[1558] \"mp\"               \"left\"             \"find\"            \n",
            "[1561] \"tags\"             \"items\"            \"object.find_all\" \n",
            "[1564] \"class_\"           \"mp\"               \"h2\"              \n",
            "[1567] \"result\"           \"items\"            \"0\"               \n",
            "[1570] \"display\"          \"tags\"             \"print\"           \n",
            "[1573] \"result.prettify\"  \"output\"           \"here\"            \n",
            "[1576] \"we\"               \"have\"             \"to\"              \n",
            "[1579] \"select\"           \"that\"             \"element\"         \n",
            "[1582] \"that\"             \"has\"              \"an\"              \n",
            "[1585] \"id\"               \"to\"               \"it\"              \n",
            "[1588] \"and\"              \"contains\"         \"children\"        \n",
            "[1591] \"having\"           \"the\"              \"same\"            \n",
            "[1594] \"class\"            \"for\"              \"example\"         \n",
            "[1597] \"the\"              \"element\"          \"with\"            \n",
            "[1600] \"id\"               \"mp\"               \"left\"            \n",
            "[1603] \"is\"               \"the\"              \"parent\"          \n",
            "[1606] \"element\"          \"and\"              \"its\"             \n",
            "[1609] \"nested\"           \"children\"         \"have\"            \n",
            "[1612] \"the\"              \"class\"            \"mp\"              \n",
            "[1615] \"h2\"               \"so\"               \"we\"              \n",
            "[1618] \"will\"             \"print\"            \"the\"             \n",
            "[1621] \"information\"      \"with\"             \"the\"             \n",
            "[1624] \"first\"            \"nested\"           \"child\"           \n",
            "[1627] \"and\"              \"prettify\"         \"it\"              \n",
            "[1630] \"using\"            \"the\"              \"prettify\"        \n",
            "[1633] \"function\"         \"conclusion\"       \"and\"             \n",
            "[1636] \"digging\"          \"deeper\"           \"into\"            \n",
            "[1639] \"web\"              \"scraping\"         \"we\"              \n",
            "[1642] \"learned\"          \"various\"          \"concepts\"        \n",
            "[1645] \"of\"               \"web\"              \"scraping\"        \n",
            "[1648] \"and\"              \"scraped\"          \"data\"            \n",
            "[1651] \"from\"             \"the\"              \"wikipedia\"       \n",
            "[1654] \"home\"             \"page\"             \"and\"             \n",
            "[1657] \"parsed\"           \"it\"               \"through\"         \n",
            "[1660] \"various\"          \"web\"              \"scraping\"        \n",
            "[1663] \"techniques\"       \"the\"              \"article\"         \n",
            "[1666] \"helped\"           \"us\"               \"in\"              \n",
            "[1669] \"getting\"          \"an\"               \"in\"              \n",
            "[1672] \"depth\"            \"idea\"             \"of\"              \n",
            "[1675] \"web\"              \"scraping\"         \"its\"             \n",
            "[1678] \"comparison\"       \"with\"             \"web\"             \n",
            "[1681] \"crawling\"         \"and\"              \"why\"             \n",
            "[1684] \"you\"              \"should\"           \"opt\"             \n",
            "[1687] \"for\"              \"web\"              \"scraping\"        \n",
            "[1690] \"we\"               \"also\"             \"learned\"         \n",
            "[1693] \"about\"            \"the\"              \"components\"      \n",
            "[1696] \"and\"              \"working\"          \"of\"              \n",
            "[1699] \"a\"                \"web\"              \"scraper\"         \n",
            "[1702] \"although\"         \"web\"              \"scraping\"        \n",
            "[1705] \"opens\"            \"up\"               \"many\"            \n",
            "[1708] \"doors\"            \"for\"              \"ethical\"         \n",
            "[1711] \"purposes\"         \"there\"            \"can\"             \n",
            "[1714] \"be\"               \"unintended\"       \"data\"            \n",
            "[1717] \"scraping\"         \"by\"               \"unethical\"       \n",
            "[1720] \"practitioners\"    \"which\"            \"creates\"         \n",
            "[1723] \"a\"                \"moral\"            \"hazard\"          \n",
            "[1726] \"to\"               \"many\"             \"companies\"       \n",
            "[1729] \"and\"              \"organizations\"    \"where\"           \n",
            "[1732] \"they\"             \"can\"              \"retrieve\"        \n",
            "[1735] \"the\"              \"data\"             \"easily\"          \n",
            "[1738] \"and\"              \"use\"              \"it\"              \n",
            "[1741] \"for\"              \"their\"            \"own\"             \n",
            "[1744] \"selfish\"          \"means\"            \"data\"            \n",
            "[1747] \"scraping\"         \"in\"               \"combination\"     \n",
            "[1750] \"with\"             \"big\"              \"data\"            \n",
            "[1753] \"can\"              \"provide\"          \"the\"             \n",
            "[1756] \"company’s\"        \"market\"           \"intelligence\"    \n",
            "[1759] \"and\"              \"help\"             \"them\"            \n",
            "[1762] \"identify\"         \"critical\"         \"trends\"          \n",
            "[1765] \"and\"              \"patterns\"         \"and\"             \n",
            "[1768] \"identify\"         \"the\"              \"best\"            \n",
            "[1771] \"opportunities\"    \"and\"              \"solutions\"       \n",
            "[1774] \"therefore\"        \"it’s\"             \"quite\"           \n",
            "[1777] \"accurate\"         \"to\"               \"predict\"         \n",
            "[1780] \"that\"             \"data\"             \"scraping\"        \n",
            "[1783] \"can\"              \"be\"               \"upgraded\"        \n",
            "[1786] \"to\"               \"the\"              \"better\"          \n",
            "[1789] \"soon\"             \"uses\"             \"of\"              \n",
            "[1792] \"web\"              \"scraping\"         \"don't\"           \n",
            "[1795] \"miss\"             \"your\"             \"chance\"          \n",
            "[1798] \"to\"               \"ride\"             \"the\"             \n",
            "[1801] \"wave\"             \"of\"               \"the\"             \n",
            "[1804] \"data\"             \"revolution\"       \"every\"           \n",
            "[1807] \"industry\"         \"is\"               \"scaling\"         \n",
            "[1810] \"new\"              \"heights\"          \"by\"              \n",
            "[1813] \"tapping\"          \"into\"             \"the\"             \n",
            "[1816] \"power\"            \"of\"               \"data\"            \n",
            "[1819] \"sharpen\"          \"your\"             \"skills\"          \n",
            "[1822] \"and\"              \"become\"           \"a\"               \n",
            "[1825] \"part\"             \"of\"               \"the\"             \n",
            "[1828] \"hottest\"          \"trend\"            \"in\"              \n",
            "[1831] \"the\"              \"21st\"             \"century\"         \n",
            "[1834] \"dive\"             \"into\"             \"the\"             \n",
            "[1837] \"future\"           \"of\"               \"technology\"      \n",
            "[1840] \"explore\"          \"the\"              \"complete\"        \n",
            "[1843] \"machine\"          \"learning\"         \"and\"             \n",
            "[1846] \"data\"             \"science\"          \"program\"         \n",
            "[1849] \"by\"               \"geeksforgeeks\"    \"and\"             \n",
            "[1852] \"stay\"             \"ahead\"            \"of\"              \n",
            "[1855] \"the\"              \"curve\"           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words <- stopwords(\"en\")\n",
        "filtered_tokens <- word_tokens[!(word_tokens %in% stop_words) & grepl(\"[a-zA-Z]\", word_tokens)]\n",
        "cat(\"Filtered Tokens (without stopwords and punctuations):\", filtered_tokens, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOMrXZ2Af1Rv",
        "outputId": "bc09a286-6dc8-4ae1-da74-0159cdc4be55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Tokens (without stopwords and punctuations): article learn various concepts web scraping get comfortable scraping various types websites data goal scrape data wikipedia home page parse various web scraping techniques getting familiar various web scraping techniques python modules web scraping processes data extraction data processing web scraping automatic process extracting information web article give depth idea web scraping comparison web crawling opt web scraping introduction web scraping python basically technique process large amounts data huge number websites passed web scraping software coded programming language result structured data extracted can saved locally devices preferably excel sheets json spreadsheets now don’t manually copy paste data websites scraper can perform task us couple seconds web scraping also known screen scraping web data extraction web harvesting etc process web scraping helps programmers write clear logical code small large scale projects python mostly known best web scraper language it’s like rounder can handle web crawling related processes smoothly scrapy beautiful soup among widely used frameworks based python makes scraping using language easy route take brief list python libraries used web scraping let’s see web scraping libraries python requests http humans library web scraping used making various types http requests like get post etc basic yet essential libraries lxml library web scraping lxml library provides super fast high performance parsing html xml content websites planning scrape large datasets one go beautiful soup library web scraping work involves creating parse tree parsing content perfect starting library beginners easy work selenium library web scraping originally made automated testing web applications library overcomes issue libraries face i.e scraping content dynamically populated websites makes slower suitable industry level projects scrapy web scraping boss libraries entire web scraping framework asynchronous usage makes blazing fast increases efficiency practical implementation scraping wikipedia steps web scraping step use python web scraping need python ide familiar use virtualenv tool create isolated python environments help virtualenv can create folder contains necessary executables use packages python project requires can add modify python modules without affecting global installation need install various python modules libraries using pip command purpose always keep mind whether website scraping legal requirements requests efficient http library used accessing web pages urlib3 used retrieving data urls selenium open source automated testing suite web applications across different browsers platforms installation pip install virtualenv python m pip install selenium python m pip install requests python m pip install urllib3 sample image installing step introduction requests library learn various python modules fetch data web python requests library used make download webpage trying scrape requirements python ide python modules requests library code walk url https en.wikipedia.org wiki main_page import required modules import requests get url page requests.get https en.wikipedia.org wiki main_page display status code print page.status_code display scraped data print page.content output first thing we’ll need scrape web page download page can download pages using python requests library requests library make get request web server download html contents given web page us several types requests can make using requests get just one url sample website https en.wikipedia.org wiki main_page task download using requests.get method running request get response object object status_code property indicates page downloaded successfully content property gives html content webpage output step introduction beautiful soup page parsing lot python modules data extraction going use beautifulsoup purpose beautifulsoup python library pulling data html xml files needs input document url create soup object fetch web page modules regular expression lxml purpose process data csv json mysql format requirements pythonide python modules beautiful soup library pip install bs4 code walk import required modules bs4 import beautifulsoup import requests get url page requests.get https en.wikipedia.org wiki main_page scrape webpage soup beautifulsoup page.content html.parser display scraped data print soup.prettify output can see now downloaded html document can use beautifulsoup library parse document extract text p tag first import library create instance beautifulsoup class parse document can now print html content page formatted nicely using prettify method beautifulsoup object tags nested can move structure one level time can first select elements top level page using children’s property soup note children return list generator need call list function step digging deep beautiful soup three features make beautiful soup powerful beautiful soup provides simple methods pythonic idioms navigating searching modifying parse tree toolkit dissecting document extracting need doesn’t take much code write application beautiful soup automatically converts incoming documents unicode outgoing documents utf don’t think encodings unless document doesn’t specify encoding beautiful soup can’t detect one just specify original encoding beautiful soup sits top popular python parsers like lxml html5lib allowing try different parsing strategies trade speed flexibility just process data proper format csv json mysql requirements pythonide python modules beautiful soup library code walk import required modules bs4 import beautifulsoup import requests get url page requests.get https en.wikipedia.org wiki main_page scrape webpage soup beautifulsoup page.content html.parser list soup.children find occurrence p html includes html tags print soup.find_all p print return text include html tags print soup.find_all p get_text output useful figuring navigate page took lot commands something fairly simple want extract single tag can instead use find_all method find instances tag page note find_all returns list we’ll loop use list indexing extract text instead want find first instance tag can use find method return single beautifulsoup object step exploring page structure chrome dev tools extracting information first thing we’ll need inspect page using chrome devtools you’re using another browser firefox safari equivalents it’s recommended use chrome though can start developer tools chrome clicking view developer developer tools end panel bottom browser like see make sure elements panel highlighted elements panel show html tags page let navigate it’s really handy feature right clicking page near says extended forecast clicking inspect we’ll open tag contains text extended forecast elements panel analyzing chrome dev tools code walk import required modules bs4 import beautifulsoup import requests get url page requests.get https en.wikipedia.org wiki main_page scrape webpage soup beautifulsoup page.content html.parser create object object soup.find id mp left find tags items object.find_all class_ mp h2 result items display tags print result.prettify output select element id contains children class example element id mp left parent element nested children class mp h2 print information first nested child prettify using prettify function conclusion digging deeper web scraping learned various concepts web scraping scraped data wikipedia home page parsed various web scraping techniques article helped us getting depth idea web scraping comparison web crawling opt web scraping also learned components working web scraper although web scraping opens many doors ethical purposes can unintended data scraping unethical practitioners creates moral hazard many companies organizations can retrieve data easily use selfish means data scraping combination big data can provide company’s market intelligence help identify critical trends patterns identify best opportunities solutions therefore it’s quite accurate predict data scraping can upgraded better soon uses web scraping miss chance ride wave data revolution every industry scaling new heights tapping power data sharpen skills become part hottest trend 21st century dive future technology explore complete machine learning data science program geeksforgeeks stay ahead curve \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens <- unlist(tokenize_sentences(text))\n",
        "word_tokens <- unlist(tokenize_words(text))\n",
        "cat(\"Sentence Tokens:\", sent_tokens, \"\\n\")\n",
        "cat(\"Word Tokens:\", word_tokens, \"\\n\")\n",
        "# Frequency Distribution\n",
        "fdist <- table(unlist(filtered_tokens))\n",
        "print(head(sort(fdist, decreasing = TRUE), 15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GFdNCN0gDZo",
        "outputId": "e38e7ccf-c36c-4923-fd6d-ee73de9a1f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokens: In this article, you will learn various concepts of web scraping and get comfortable with scraping various types of websites and their data. The goal is to scrape data from the Wikipedia Home page and parse it through various web scraping techniques. You will be getting familiar with various web scraping techniques, python modules for web scraping, and processes of Data extraction and data processing. Web scraping is an automatic process of extracting information from the web. This article will give you an in-depth idea of web scraping, its comparison with web crawling, and why you should opt for web scraping. Introduction to Web scraping and Python It is basically a technique or a process in which large amounts of data from a huge number of websites is passed through a web scraping software coded in a programming language and as a result, structured data is extracted which can be saved locally in our devices preferably in Excel sheets, JSON or spreadsheets. Now, we don’t have to manually copy and paste data from websites but a scraper can perform that task for us in a couple of seconds. Web scraping is also known as Screen Scraping, Web Data Extraction, Web Harvesting, etc. Process of Web scraping  This helps programmers write clear, logical code for small and large-scale projects. Python is mostly known as the best web scraper language. It’s more like an all-rounder and can handle most of the web crawling related processes smoothly. Scrapy and Beautiful Soup are among the widely used frameworks based on Python that makes scraping using this language such an easy route to take. A brief list of Python libraries used for web scraping Let’s see the web scraping libraries in Python! Requests (HTTP for Humans) Library for Web Scraping – It is used for making various types of HTTP requests like GET, POST, etc. It is the most basic yet the most essential of all libraries. lxml Library for Web Scraping – lxml library provides super-fast and high-performance parsing of HTML and XML content from websites. If you are planning to scrape large datasets, this is the one you should go for. Beautiful Soup Library for Web Scraping – Its work involves creating a parse tree for parsing content. A perfect starting library for beginners and very easy to work with. Selenium Library for Web Scraping – Originally made for automated testing of web applications, this library overcomes the issue all the above libraries face i.e. scraping content from dynamically populated websites. This makes it slower and not suitable for industry-level projects. Scrapy for Web Scraping – The BOSS of all libraries, an entire web scraping framework which is asynchronous in its usage. This makes it blazing fast and increases efficiency. Practical Implementation – Scraping Wikipedia  Steps of web scraping  Step 1: How to use python for web scraping? We need python IDE and should be familiar with the use of it. Virtualenv is a tool to create isolated Python environments. With the help of virtualenv, we can create a folder that contains all necessary executables to use the packages that our Python project requires. Here we can add and modify python modules without affecting any global installation. We need to install various Python modules and libraries using the pip command for our purpose. But, we should always keep in mind that whether the website we are scraping is legal or not. Requirements:  Requests: It is an efficient HTTP library used for accessing web pages. Urlib3: It is used for retrieving data from URLs. Selenium: It is an open-source automated testing suite for web applications across different browsers and platforms. Installation:  pip install virtualenv python -m pip install selenium python -m pip install requests python -m pip install urllib3  Sample image during installing  Step 2: Introduction to Requests library Here, we will learn various python modules to fetch data from the web. The python requests library is used to make download the webpage we are trying to scrape. Requirements:  Python IDE Python Modules Requests library Code Walk-Through:  URL: https://en.wikipedia.org/wiki/Main_Page # import required modules import requests   # get URL page = requests.get(https://en.wikipedia.org/wiki/Main_Page)   # display status code print(page.status_code)   # display scraped data print(page.content) Output:    The first thing we’ll need to do to scrape a web page is to download the page. We can download pages using the Python requests library. The requests library will make a GET request to a web server, which will download the HTML contents of a given web page for us. There are several types of requests we can make using requests, of which GET is just one. The URL of our sample website is https://en.wikipedia.org/wiki/Main_Page. The task is to download it using requests.get() method. After running our request, we get a Response object. This object has a status_code property, which indicates if the page was downloaded successfully. And a content property that gives the HTML content of the webpage as output. Step 3: Introduction to Beautiful Soup for page parsing We have a lot of python modules for data extraction. We are going to use BeautifulSoup for our purpose. BeautifulSoup is a Python library for pulling data out of HTML and XML files. It needs an input (document or URL) to create a soup object as it cannot fetch a web page by itself. We have other modules such as regular expression, lxml for the same purpose. We then process the data in CSV or JSON or MySQL format. Requirements:  PythonIDE Python Modules Beautiful Soup library pip install bs4 Code Walk-Through:  # import required modules from bs4 import BeautifulSoup import requests   # get URL page = requests.get(https://en.wikipedia.org/wiki/Main_Page)   # scrape webpage soup = BeautifulSoup(page.content, 'html.parser')   # display scraped data print(soup.prettify()) Output:    As you can see above, we now have downloaded an HTML document. We can use the BeautifulSoup library to parse this document and extract the text from the p tag. We first have to import the library and create an instance of the BeautifulSoup class to parse our document. We can now print out the HTML content of the page, formatted nicely, using the prettify method on the BeautifulSoup object. As all the tags are nested, we can move through the structure one level at a time. We can first select all the elements at the top level of the page using the children’s property of soup. Note that children return a list generator, so we need to call the list function on it. Step 4: Digging deep into Beautiful Soup further Three features that make Beautiful Soup so powerful:  Beautiful Soup provides a few simple methods and Pythonic idioms for navigating, searching, and modifying a parse tree: a toolkit for dissecting a document and extracting what you need. It doesn’t take much code to write an application Beautiful Soup automatically converts incoming documents to Unicode and outgoing documents to UTF-8. You don’t have to think about encodings unless the document doesn’t specify an encoding and Beautiful Soup can’t detect one. Then you just have to specify the original encoding. Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, allowing you to try out different parsing strategies or trade speed for flexibility. Then we have to just process our data in a proper format such as CSV or JSON or MySQL. Requirements:  PythonIDE Python Modules Beautiful Soup library Code Walk-Through:  # import required modules from bs4 import BeautifulSoup import requests   # get URL page = requests.get(https://en.wikipedia.org/wiki/Main_Page)   # scrape webpage soup = BeautifulSoup(page.content, 'html.parser')   list(soup.children)   # find all occurrence of p in HTML # includes HTML tags print(soup.find_all('p'))   print('  ')   # return only text # does not include HTML tags print(soup.find_all('p')[0].get_text()) Output:    What we did above was useful for figuring out how to navigate a page, but it took a lot of commands to do something fairly simple. If we want to extract a single tag, we can instead use the find_all() method, which will find all the instances of a tag on a page. Note that find_all() returns a list, so we’ll have to loop through, or use list indexing, to extract text. If you instead only want to find the first instance of a tag, you can use the find method, which will return a single BeautifulSoup object. Step 5: Exploring page structure with Chrome Dev tools and extracting information The first thing we’ll need to do is inspect the page using Chrome Devtools. If you’re using another browser, Firefox and Safari have equivalents. It’s recommended to use Chrome though. You can start the developer tools in Chrome by clicking View -> Developer -> Developer Tools. You should end up with a panel at the bottom of the browser like what you see below. Make sure the Elements panel is highlighted. The elements panel will show you all the HTML tags on the page, and let you navigate through them. It’s a really handy feature! By right-clicking on the page near where it says Extended Forecast, then clicking Inspect, we’ll open up the tag that contains the text Extended Forecast in the elements panel. Analyzing by Chrome Dev tools  Code Walk-Through:  # import required modules from bs4 import BeautifulSoup import requests   # get URL page = requests.get(https://en.wikipedia.org/wiki/Main_Page)   # scrape webpage soup = BeautifulSoup(page.content, 'html.parser')   # create object object = soup.find(id=mp-left)   # find tags items = object.find_all(class_=mp-h2) result = items[0]   # display tags print(result.prettify()) Output:    Here we have to select that element that has an id to it and contains children having the same class. For example, the element with id mp-left is the parent element and its nested children have the class mp-h2. So we will print the information with the first nested child and prettify it using the prettify() function. Conclusion and Digging deeper into Web scraping We learned various concepts of web scraping and scraped data from the Wikipedia Home page and parsed it through various web scraping techniques. The article helped us in getting an in-depth idea of web scraping, its comparison with web crawling, and why you should opt for web scraping. We also learned about the components and working of a web scraper. Although web scraping opens up many doors for ethical purposes, there can be unintended data scraping by unethical practitioners which creates a moral hazard to many companies and organizations where they can retrieve the data easily and use it for their own selfish means. Data-scraping in combination with big data can provide the company’s market intelligence and help them identify critical trends and patterns and identify the best opportunities and solutions. Therefore, it’s quite accurate to predict that Data scraping can be upgraded to the better soon. Uses of Web scraping   Don't miss your chance to ride the wave of the data revolution! Every industry is scaling new heights by tapping into the power of data. Sharpen your skills and become a part of the hottest trend in the 21st century. Dive into the future of technology - explore the Complete Machine Learning and Data Science Program by GeeksforGeeks and stay ahead of the curve. \n",
            "Word Tokens: in this article you will learn various concepts of web scraping and get comfortable with scraping various types of websites and their data the goal is to scrape data from the wikipedia home page and parse it through various web scraping techniques you will be getting familiar with various web scraping techniques python modules for web scraping and processes of data extraction and data processing web scraping is an automatic process of extracting information from the web this article will give you an in depth idea of web scraping its comparison with web crawling and why you should opt for web scraping introduction to web scraping and python it is basically a technique or a process in which large amounts of data from a huge number of websites is passed through a web scraping software coded in a programming language and as a result structured data is extracted which can be saved locally in our devices preferably in excel sheets json or spreadsheets now we don’t have to manually copy and paste data from websites but a scraper can perform that task for us in a couple of seconds web scraping is also known as screen scraping web data extraction web harvesting etc process of web scraping this helps programmers write clear logical code for small and large scale projects python is mostly known as the best web scraper language it’s more like an all rounder and can handle most of the web crawling related processes smoothly scrapy and beautiful soup are among the widely used frameworks based on python that makes scraping using this language such an easy route to take a brief list of python libraries used for web scraping let’s see the web scraping libraries in python requests http for humans library for web scraping it is used for making various types of http requests like get post etc it is the most basic yet the most essential of all libraries lxml library for web scraping lxml library provides super fast and high performance parsing of html and xml content from websites if you are planning to scrape large datasets this is the one you should go for beautiful soup library for web scraping its work involves creating a parse tree for parsing content a perfect starting library for beginners and very easy to work with selenium library for web scraping originally made for automated testing of web applications this library overcomes the issue all the above libraries face i.e scraping content from dynamically populated websites this makes it slower and not suitable for industry level projects scrapy for web scraping the boss of all libraries an entire web scraping framework which is asynchronous in its usage this makes it blazing fast and increases efficiency practical implementation scraping wikipedia steps of web scraping step 1 how to use python for web scraping we need python ide and should be familiar with the use of it virtualenv is a tool to create isolated python environments with the help of virtualenv we can create a folder that contains all necessary executables to use the packages that our python project requires here we can add and modify python modules without affecting any global installation we need to install various python modules and libraries using the pip command for our purpose but we should always keep in mind that whether the website we are scraping is legal or not requirements requests it is an efficient http library used for accessing web pages urlib3 it is used for retrieving data from urls selenium it is an open source automated testing suite for web applications across different browsers and platforms installation pip install virtualenv python m pip install selenium python m pip install requests python m pip install urllib3 sample image during installing step 2 introduction to requests library here we will learn various python modules to fetch data from the web the python requests library is used to make download the webpage we are trying to scrape requirements python ide python modules requests library code walk through url https en.wikipedia.org wiki main_page import required modules import requests get url page requests.get https en.wikipedia.org wiki main_page display status code print page.status_code display scraped data print page.content output the first thing we’ll need to do to scrape a web page is to download the page we can download pages using the python requests library the requests library will make a get request to a web server which will download the html contents of a given web page for us there are several types of requests we can make using requests of which get is just one the url of our sample website is https en.wikipedia.org wiki main_page the task is to download it using requests.get method after running our request we get a response object this object has a status_code property which indicates if the page was downloaded successfully and a content property that gives the html content of the webpage as output step 3 introduction to beautiful soup for page parsing we have a lot of python modules for data extraction we are going to use beautifulsoup for our purpose beautifulsoup is a python library for pulling data out of html and xml files it needs an input document or url to create a soup object as it cannot fetch a web page by itself we have other modules such as regular expression lxml for the same purpose we then process the data in csv or json or mysql format requirements pythonide python modules beautiful soup library pip install bs4 code walk through import required modules from bs4 import beautifulsoup import requests get url page requests.get https en.wikipedia.org wiki main_page scrape webpage soup beautifulsoup page.content html.parser display scraped data print soup.prettify output as you can see above we now have downloaded an html document we can use the beautifulsoup library to parse this document and extract the text from the p tag we first have to import the library and create an instance of the beautifulsoup class to parse our document we can now print out the html content of the page formatted nicely using the prettify method on the beautifulsoup object as all the tags are nested we can move through the structure one level at a time we can first select all the elements at the top level of the page using the children’s property of soup note that children return a list generator so we need to call the list function on it step 4 digging deep into beautiful soup further three features that make beautiful soup so powerful beautiful soup provides a few simple methods and pythonic idioms for navigating searching and modifying a parse tree a toolkit for dissecting a document and extracting what you need it doesn’t take much code to write an application beautiful soup automatically converts incoming documents to unicode and outgoing documents to utf 8 you don’t have to think about encodings unless the document doesn’t specify an encoding and beautiful soup can’t detect one then you just have to specify the original encoding beautiful soup sits on top of popular python parsers like lxml and html5lib allowing you to try out different parsing strategies or trade speed for flexibility then we have to just process our data in a proper format such as csv or json or mysql requirements pythonide python modules beautiful soup library code walk through import required modules from bs4 import beautifulsoup import requests get url page requests.get https en.wikipedia.org wiki main_page scrape webpage soup beautifulsoup page.content html.parser list soup.children find all occurrence of p in html includes html tags print soup.find_all p print return only text does not include html tags print soup.find_all p 0 get_text output what we did above was useful for figuring out how to navigate a page but it took a lot of commands to do something fairly simple if we want to extract a single tag we can instead use the find_all method which will find all the instances of a tag on a page note that find_all returns a list so we’ll have to loop through or use list indexing to extract text if you instead only want to find the first instance of a tag you can use the find method which will return a single beautifulsoup object step 5 exploring page structure with chrome dev tools and extracting information the first thing we’ll need to do is inspect the page using chrome devtools if you’re using another browser firefox and safari have equivalents it’s recommended to use chrome though you can start the developer tools in chrome by clicking view developer developer tools you should end up with a panel at the bottom of the browser like what you see below make sure the elements panel is highlighted the elements panel will show you all the html tags on the page and let you navigate through them it’s a really handy feature by right clicking on the page near where it says extended forecast then clicking inspect we’ll open up the tag that contains the text extended forecast in the elements panel analyzing by chrome dev tools code walk through import required modules from bs4 import beautifulsoup import requests get url page requests.get https en.wikipedia.org wiki main_page scrape webpage soup beautifulsoup page.content html.parser create object object soup.find id mp left find tags items object.find_all class_ mp h2 result items 0 display tags print result.prettify output here we have to select that element that has an id to it and contains children having the same class for example the element with id mp left is the parent element and its nested children have the class mp h2 so we will print the information with the first nested child and prettify it using the prettify function conclusion and digging deeper into web scraping we learned various concepts of web scraping and scraped data from the wikipedia home page and parsed it through various web scraping techniques the article helped us in getting an in depth idea of web scraping its comparison with web crawling and why you should opt for web scraping we also learned about the components and working of a web scraper although web scraping opens up many doors for ethical purposes there can be unintended data scraping by unethical practitioners which creates a moral hazard to many companies and organizations where they can retrieve the data easily and use it for their own selfish means data scraping in combination with big data can provide the company’s market intelligence and help them identify critical trends and patterns and identify the best opportunities and solutions therefore it’s quite accurate to predict that data scraping can be upgraded to the better soon uses of web scraping don't miss your chance to ride the wave of the data revolution every industry is scaling new heights by tapping into the power of data sharpen your skills and become a part of the hottest trend in the 21st century dive into the future of technology explore the complete machine learning and data science program by geeksforgeeks and stay ahead of the curve \n",
            "\n",
            "          web      scraping          data        python          page \n",
            "           44            37            25            25            20 \n",
            "          can       library          soup      requests       modules \n",
            "           19            18            16            15            13 \n",
            "beautifulsoup        import     beautiful          html           use \n",
            "           12            12            11            10            10 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_tokens <- wordStem(filtered_tokens, language = \"en\")\n",
        "\n",
        "# Lemmatization\n",
        "lemmatized_text <- tolower(text)\n",
        "lemmatized_text <- wordStem(lemmatized_text, language = \"en\")\n",
        "cat(\"Stemmed Tokens:\", stemmed_tokens, \"\\n\")\n",
        "cat(\"Lemmatized Text:\", lemmatized_text, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzJ-fyZygKyn",
        "outputId": "8903d380-361a-4962-a538-66f067c730a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Tokens: articl learn various concept web scrape get comfort scrape various type websit data goal scrape data wikipedia home page pars various web scrape techniqu get familiar various web scrape techniqu python modul web scrape process data extract data process web scrape automat process extract inform web articl give depth idea web scrape comparison web crawl opt web scrape introduct web scrape python basic techniqu process larg amount data huge number websit pass web scrape softwar code program languag result structur data extract can save local devic prefer excel sheet json spreadsheet now don’t manual copi past data websit scraper can perform task us coupl second web scrape also known screen scrape web data extract web harvest etc process web scrape help programm write clear logic code small larg scale project python most known best web scraper languag it’ like rounder can handl web crawl relat process smooth scrapi beauti soup among wide use framework base python make scrape use languag easi rout take brief list python librari use web scrape let’ see web scrape librari python request http human librari web scrape use make various type http request like get post etc basic yet essenti librari lxml librari web scrape lxml librari provid super fast high perform pars html xml content websit plan scrape larg dataset one go beauti soup librari web scrape work involv creat pars tree pars content perfect start librari beginn easi work selenium librari web scrape origin made autom test web applic librari overcom issu librari face i.e scrape content dynam popul websit make slower suitabl industri level project scrapi web scrape boss librari entir web scrape framework asynchron usag make blaze fast increas effici practic implement scrape wikipedia step web scrape step use python web scrape need python ide familiar use virtualenv tool creat isol python environ help virtualenv can creat folder contain necessari execut use packag python project requir can add modifi python modul without affect global instal need instal various python modul librari use pip command purpos alway keep mind whether websit scrape legal requir request effici http librari use access web page urlib3 use retriev data url selenium open sourc autom test suit web applic across differ browser platform instal pip instal virtualenv python m pip instal selenium python m pip instal request python m pip instal urllib3 sampl imag instal step introduct request librari learn various python modul fetch data web python request librari use make download webpag tri scrape requir python ide python modul request librari code walk url https en.wikipedia.org wiki main_pag import requir modul import request get url page requests.get https en.wikipedia.org wiki main_pag display status code print page.status_cod display scrape data print page.cont output first thing we’ll need scrape web page download page can download page use python request librari request librari make get request web server download html content given web page us sever type request can make use request get just one url sampl websit https en.wikipedia.org wiki main_pag task download use requests.get method run request get respons object object status_cod properti indic page download success content properti give html content webpag output step introduct beauti soup page pars lot python modul data extract go use beautifulsoup purpos beautifulsoup python librari pull data html xml file need input document url creat soup object fetch web page modul regular express lxml purpos process data csv json mysql format requir pythonid python modul beauti soup librari pip instal bs4 code walk import requir modul bs4 import beautifulsoup import request get url page requests.get https en.wikipedia.org wiki main_pag scrape webpag soup beautifulsoup page.cont html.parser display scrape data print soup.prettifi output can see now download html document can use beautifulsoup librari pars document extract text p tag first import librari creat instanc beautifulsoup class pars document can now print html content page format nice use prettifi method beautifulsoup object tag nest can move structur one level time can first select element top level page use children’ properti soup note children return list generat need call list function step dig deep beauti soup three featur make beauti soup power beauti soup provid simpl method python idiom navig search modifi pars tree toolkit dissect document extract need doesn’t take much code write applic beauti soup automat convert incom document unicod outgo document utf don’t think encod unless document doesn’t specifi encod beauti soup can’t detect one just specifi origin encod beauti soup sit top popular python parser like lxml html5lib allow tri differ pars strategi trade speed flexibl just process data proper format csv json mysql requir pythonid python modul beauti soup librari code walk import requir modul bs4 import beautifulsoup import request get url page requests.get https en.wikipedia.org wiki main_pag scrape webpag soup beautifulsoup page.cont html.parser list soup.children find occurr p html includ html tag print soup.find_al p print return text includ html tag print soup.find_al p get_text output use figur navig page took lot command someth fair simpl want extract singl tag can instead use find_al method find instanc tag page note find_al return list we’ll loop use list index extract text instead want find first instanc tag can use find method return singl beautifulsoup object step explor page structur chrome dev tool extract inform first thing we’ll need inspect page use chrome devtool you’r use anoth browser firefox safari equival it’ recommend use chrome though can start develop tool chrome click view develop develop tool end panel bottom browser like see make sure element panel highlight element panel show html tag page let navig it’ realli handi featur right click page near say extend forecast click inspect we’ll open tag contain text extend forecast element panel analyz chrome dev tool code walk import requir modul bs4 import beautifulsoup import request get url page requests.get https en.wikipedia.org wiki main_pag scrape webpag soup beautifulsoup page.cont html.parser creat object object soup.find id mp left find tag item object.find_al class_ mp h2 result item display tag print result.prettifi output select element id contain children class exampl element id mp left parent element nest children class mp h2 print inform first nest child prettifi use prettifi function conclus dig deeper web scrape learn various concept web scrape scrape data wikipedia home page pars various web scrape techniqu articl help us get depth idea web scrape comparison web crawl opt web scrape also learn compon work web scraper although web scrape open mani door ethic purpos can unintend data scrape uneth practition creat moral hazard mani compani organ can retriev data easili use selfish mean data scrape combin big data can provid company’ market intellig help identifi critic trend pattern identifi best opportun solut therefor it’ quit accur predict data scrape can upgrad better soon use web scrape miss chanc ride wave data revolut everi industri scale new height tap power data sharpen skill becom part hottest trend 21st centuri dive futur technolog explor complet machin learn data scienc program geeksforgeek stay ahead curv \n",
            "Lemmatized Text: in this article, you will learn various concepts of web scraping and get comfortable with scraping various types of websites and their data. the goal is to scrape data from the wikipedia home page and parse it through various web scraping techniques. you will be getting familiar with various web scraping techniques, python modules for web scraping, and processes of data extraction and data processing. web scraping is an automatic process of extracting information from the web. this article will give you an in-depth idea of web scraping, its comparison with web crawling, and why you should opt for web scraping.\n",
            "\n",
            "introduction to web scraping and python\n",
            "it is basically a technique or a process in which large amounts of data from a huge number of websites is passed through a web scraping software coded in a programming language and as a result, structured data is extracted which can be saved locally in our devices preferably in excel sheets, json or spreadsheets. now, we don’t have to manually copy and paste data from websites but a scraper can perform that task for us in a couple of seconds. \n",
            "\n",
            "web scraping is also known as screen scraping, web data extraction, web harvesting, etc.\n",
            "\n",
            "\n",
            "process of web scraping\n",
            "\n",
            "this helps programmers write clear, logical code for small and large-scale projects. python is mostly known as the best web scraper language. it’s more like an all-rounder and can handle most of the web crawling related processes smoothly. scrapy and beautiful soup are among the widely used frameworks based on python that makes scraping using this language such an easy route to take.\n",
            "\n",
            "\n",
            "a brief list of python libraries used for web scraping\n",
            "let’s see the web scraping libraries in python!\n",
            "\n",
            "requests (http for humans) library for web scraping – it is used for making various types of http requests like get, post, etc. it is the most basic yet the most essential of all libraries.\n",
            "lxml library for web scraping – lxml library provides super-fast and high-performance parsing of html and xml content from websites. if you are planning to scrape large datasets, this is the one you should go for.\n",
            "beautiful soup library for web scraping – its work involves creating a parse tree for parsing content. a perfect starting library for beginners and very easy to work with.\n",
            "selenium library for web scraping – originally made for automated testing of web applications, this library overcomes the issue all the above libraries face i.e. scraping content from dynamically populated websites. this makes it slower and not suitable for industry-level projects.\n",
            "scrapy for web scraping – the boss of all libraries, an entire web scraping framework which is asynchronous in its usage. this makes it blazing fast and increases efficiency.\n",
            "practical implementation – scraping wikipedia\n",
            "\n",
            "steps of web scraping\n",
            "\n",
            "step 1: how to use python for web scraping?\n",
            "we need python ide and should be familiar with the use of it.\n",
            "virtualenv is a tool to create isolated python environments. with the help of virtualenv, we can create a folder that contains all necessary executables to use the packages that our python project requires. here we can add and modify python modules without affecting any global installation.\n",
            "we need to install various python modules and libraries using the pip command for our purpose. but, we should always keep in mind that whether the website we are scraping is legal or not.\n",
            "requirements:\n",
            "\n",
            "requests: it is an efficient http library used for accessing web pages.\n",
            "urlib3: it is used for retrieving data from urls.\n",
            "selenium: it is an open-source automated testing suite for web applications across different browsers and platforms.\n",
            "installation:\n",
            "\n",
            "pip install virtualenv\n",
            "python -m pip install selenium\n",
            "python -m pip install requests\n",
            "python -m pip install urllib3\n",
            "\n",
            "sample image during installing\n",
            "\n",
            "step 2: introduction to requests library\n",
            "here, we will learn various python modules to fetch data from the web.\n",
            "the python requests library is used to make download the webpage we are trying to scrape.\n",
            "requirements:\n",
            "\n",
            "python ide\n",
            "python modules\n",
            "requests library\n",
            "code walk-through:\n",
            "\n",
            "url: https://en.wikipedia.org/wiki/main_page\n",
            "# import required modules\n",
            "import requests\n",
            " \n",
            "# get url\n",
            "page = requests.get(https://en.wikipedia.org/wiki/main_page)\n",
            " \n",
            "# display status code\n",
            "print(page.status_code)\n",
            " \n",
            "# display scraped data\n",
            "print(page.content)\n",
            "output:\n",
            "\n",
            "\n",
            "\n",
            "the first thing we’ll need to do to scrape a web page is to download the page. we can download pages using the python requests library. the requests library will make a get request to a web server, which will download the html contents of a given web page for us. there are several types of requests we can make using requests, of which get is just one. the url of our sample website is https://en.wikipedia.org/wiki/main_page. the task is to download it using requests.get() method. after running our request, we get a response object. this object has a status_code property, which indicates if the page was downloaded successfully. and a content property that gives the html content of the webpage as output.  \n",
            "\n",
            "step 3: introduction to beautiful soup for page parsing\n",
            "we have a lot of python modules for data extraction. we are going to use beautifulsoup for our purpose.  \n",
            "\n",
            "beautifulsoup is a python library for pulling data out of html and xml files.\n",
            "it needs an input (document or url) to create a soup object as it cannot fetch a web page by itself.\n",
            "we have other modules such as regular expression, lxml for the same purpose.\n",
            "we then process the data in csv or json or mysql format.\n",
            "requirements:\n",
            "\n",
            "pythonide\n",
            "python modules\n",
            "beautiful soup library\n",
            "pip install bs4\n",
            "code walk-through:\n",
            "\n",
            "# import required modules\n",
            "from bs4 import beautifulsoup\n",
            "import requests\n",
            " \n",
            "# get url\n",
            "page = requests.get(https://en.wikipedia.org/wiki/main_page)\n",
            " \n",
            "# scrape webpage\n",
            "soup = beautifulsoup(page.content, 'html.parser')\n",
            " \n",
            "# display scraped data\n",
            "print(soup.prettify())\n",
            "output:\n",
            "\n",
            "\n",
            "\n",
            "as you can see above, we now have downloaded an html document. we can use the beautifulsoup library to parse this document and extract the text from the p tag. we first have to import the library and create an instance of the beautifulsoup class to parse our document. we can now print out the html content of the page, formatted nicely, using the prettify method on the beautifulsoup object. as all the tags are nested, we can move through the structure one level at a time. we can first select all the elements at the top level of the page using the children’s property of soup. note that children return a list generator, so we need to call the list function on it.\n",
            "\n",
            "step 4: digging deep into beautiful soup further\n",
            "three features that make beautiful soup so powerful:\n",
            "\n",
            "beautiful soup provides a few simple methods and pythonic idioms for navigating, searching, and modifying a parse tree: a toolkit for dissecting a document and extracting what you need. it doesn’t take much code to write an application\n",
            "beautiful soup automatically converts incoming documents to unicode and outgoing documents to utf-8. you don’t have to think about encodings unless the document doesn’t specify an encoding and beautiful soup can’t detect one. then you just have to specify the original encoding.\n",
            "beautiful soup sits on top of popular python parsers like lxml and html5lib, allowing you to try out different parsing strategies or trade speed for flexibility. then we have to just process our data in a proper format such as csv or json or mysql.\n",
            "requirements:\n",
            "\n",
            "pythonide\n",
            "python modules\n",
            "beautiful soup library\n",
            "code walk-through:\n",
            "\n",
            "# import required modules\n",
            "from bs4 import beautifulsoup\n",
            "import requests\n",
            " \n",
            "# get url\n",
            "page = requests.get(https://en.wikipedia.org/wiki/main_page)\n",
            " \n",
            "# scrape webpage\n",
            "soup = beautifulsoup(page.content, 'html.parser')\n",
            " \n",
            "list(soup.children)\n",
            " \n",
            "# find all occurrence of p in html\n",
            "# includes html tags\n",
            "print(soup.find_all('p'))\n",
            " \n",
            "print('\n",
            "\n",
            "')\n",
            " \n",
            "# return only text\n",
            "# does not include html tags\n",
            "print(soup.find_all('p')[0].get_text())\n",
            "output:\n",
            "\n",
            "\n",
            "\n",
            "what we did above was useful for figuring out how to navigate a page, but it took a lot of commands to do something fairly simple. if we want to extract a single tag, we can instead use the find_all() method, which will find all the instances of a tag on a page. note that find_all() returns a list, so we’ll have to loop through, or use list indexing, to extract text. if you instead only want to find the first instance of a tag, you can use the find method, which will return a single beautifulsoup object.\n",
            "\n",
            "step 5: exploring page structure with chrome dev tools and extracting information\n",
            "the first thing we’ll need to do is inspect the page using chrome devtools. if you’re using another browser, firefox and safari have equivalents. it’s recommended to use chrome though. \n",
            "\n",
            "you can start the developer tools in chrome by clicking view -> developer -> developer tools. you should end up with a panel at the bottom of the browser like what you see below. make sure the elements panel is highlighted. the elements panel will show you all the html tags on the page, and let you navigate through them. it’s a really handy feature! by right-clicking on the page near where it says extended forecast, then clicking inspect, we’ll open up the tag that contains the text extended forecast in the elements panel.\n",
            "\n",
            "\n",
            "analyzing by chrome dev tools\n",
            "\n",
            "code walk-through:\n",
            "\n",
            "# import required modules\n",
            "from bs4 import beautifulsoup\n",
            "import requests\n",
            " \n",
            "# get url\n",
            "page = requests.get(https://en.wikipedia.org/wiki/main_page)\n",
            " \n",
            "# scrape webpage\n",
            "soup = beautifulsoup(page.content, 'html.parser')\n",
            " \n",
            "# create object\n",
            "object = soup.find(id=mp-left)\n",
            " \n",
            "# find tags\n",
            "items = object.find_all(class_=mp-h2)\n",
            "result = items[0]\n",
            " \n",
            "# display tags\n",
            "print(result.prettify())\n",
            "output:\n",
            "\n",
            "\n",
            "\n",
            "here we have to select that element that has an id to it and contains children having the same class. for example, the element with id mp-left is the parent element and its nested children have the class mp-h2. so we will print the information with the first nested child and prettify it using the prettify() function.\n",
            "\n",
            "conclusion and digging deeper into web scraping\n",
            "we learned various concepts of web scraping and scraped data from the wikipedia home page and parsed it through various web scraping techniques. the article helped us in getting an in-depth idea of web scraping, its comparison with web crawling, and why you should opt for web scraping. we also learned about the components and working of a web scraper.\n",
            "\n",
            "although web scraping opens up many doors for ethical purposes, there can be unintended data scraping by unethical practitioners which creates a moral hazard to many companies and organizations where they can retrieve the data easily and use it for their own selfish means. data-scraping in combination with big data can provide the company’s market intelligence and help them identify critical trends and patterns and identify the best opportunities and solutions. therefore, it’s quite accurate to predict that data scraping can be upgraded to the better soon.\n",
            "\n",
            "\n",
            "uses of web scraping\n",
            "\n",
            "\n",
            "don't miss your chance to ride the wave of the data revolution! every industry is scaling new heights by tapping into the power of data. sharpen your skills and become a part of the hottest trend in the 21st century.\n",
            "\n",
            "dive into the future of technology - explore the complete machine learning and data science program by geeksforgeeks and stay ahead of the curve. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "url <- \"http://quotes.toscrape.com\"\n",
        "page <- read_html(url)\n",
        "quotes <- page %>% html_nodes(\".text\") %>% html_text()\n",
        "authors <- page %>% html_nodes(\".author\") %>% html_text()\n",
        "for (i in seq_along(quotes)) {\n",
        "  cat(\"Quote:\", quotes[i], \"\\n\")\n",
        "  cat(\"Author:\", authors[i], \"\\n\\n\")\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZquWQtfgO4p",
        "outputId": "dab2501f-f7ba-49f1-b272-1322234af5dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quote: “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” \n",
            "Author: Albert Einstein \n",
            "\n",
            "Quote: “It is our choices, Harry, that show what we truly are, far more than our abilities.” \n",
            "Author: J.K. Rowling \n",
            "\n",
            "Quote: “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.” \n",
            "Author: Albert Einstein \n",
            "\n",
            "Quote: “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.” \n",
            "Author: Jane Austen \n",
            "\n",
            "Quote: “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.” \n",
            "Author: Marilyn Monroe \n",
            "\n",
            "Quote: “Try not to become a man of success. Rather become a man of value.” \n",
            "Author: Albert Einstein \n",
            "\n",
            "Quote: “It is better to be hated for what you are than to be loved for what you are not.” \n",
            "Author: André Gide \n",
            "\n",
            "Quote: “I have not failed. I've just found 10,000 ways that won't work.” \n",
            "Author: Thomas A. Edison \n",
            "\n",
            "Quote: “A woman is like a tea bag; you never know how strong it is until it's in hot water.” \n",
            "Author: Eleanor Roosevelt \n",
            "\n",
            "Quote: “A day without sunshine is like, you know, night.” \n",
            "Author: Steve Martin \n",
            "\n"
          ]
        }
      ]
    }
  ]
}